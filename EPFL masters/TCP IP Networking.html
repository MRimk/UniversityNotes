<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>TCP IP Networking</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="css/pandoc.css" />
  <style>
    html {
      font-size: 100%;
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
    }

    body {
      color: #444;
      font-family: Georgia, Palatino, "Palatino Linotype", Times,
        "Times New Roman", serif;
      font-size: 12px;
      line-height: 1.7;
      padding: 1em;
      margin: auto;
      max-width: 42em;
      background: #fefefe;
    }

    a {
      color: #0645ad;
      text-decoration: none;
    }

    a:visited {
      color: #0b0080;
    }

    a:hover {
      color: #06e;
    }

    a:active {
      color: #faa700;
    }

    a:focus {
      outline: thin dotted;
    }

    *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    p {
      margin: 1em 0;
    }

    img {
      max-width: 100%;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      color: #111;
      line-height: 125%;
      margin-top: 2em;
      font-weight: normal;
    }

    h4,
    h5,
    h6 {
      font-weight: bold;
    }

    h1 {
      font-size: 2.5em;
    }

    h2 {
      font-size: 2em;
    }

    h3 {
      font-size: 1.5em;
    }

    h4 {
      font-size: 1.2em;
    }

    h5 {
      font-size: 1em;
    }

    h6 {
      font-size: 0.9em;
    }

    blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #eee solid;
    }

    hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 1em 0;
      padding: 0;
    }

    pre,
    code,
    kbd,
    samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: "courier new", monospace;
      font-size: 0.98em;
    }

    pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
    }

    b,
    strong {
      font-weight: bold;
    }

    dfn {
      font-style: italic;
    }

    ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
    }

    mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
    }

    sub,
    sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
    }

    sup {
      top: -0.5em;
    }

    sub {
      bottom: -0.25em;
    }

    ul,
    ol {
      margin: 1em 0;
      padding: 0 0 0 2em;
    }

    li p:last-child {
      margin-bottom: 0;
    }

    ul ul,
    ol ol {
      margin: 0.3em 0;
    }

    dl {
      margin-bottom: 1em;
    }

    dt {
      font-weight: bold;
      margin-bottom: 0.8em;
    }

    dd {
      margin: 0 0 0.8em 2em;
    }

    dd:last-child {
      margin-bottom: 0;
    }

    img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
    }

    figure {
      display: block;
      text-align: center;
      margin: 1em 0;
    }

    figure img {
      border: none;
      margin: 0 auto;
    }

    figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 0.8em;
    }

    table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
    }

    table th {
      padding: 0.2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
    }

    table td {
      padding: 0.2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
    }

    .author {
      font-size: 1.2em;
      text-align: center;
    }

    @media only screen and (min-width: 480px) {
      body {
        font-size: 14px;
      }
    }
    @media only screen and (min-width: 768px) {
      body {
        font-size: 16px;
      }
    }
    @media print {
      * {
        background: transparent !important;
        color: black !important;
        filter: none !important;
        -ms-filter: none !important;
      }

      body {
        font-size: 12pt;
        max-width: 100%;
      }

      a,
      a:visited {
        text-decoration: underline;
      }

      hr {
        height: 1px;
        border: 0;
        border-bottom: 1px solid black;
      }

      a[href]:after {
        content: " (" attr(href) ")";
      }

      abbr[title]:after {
        content: " (" attr(title) ")";
      }

      .ir a:after,
      a[href^="javascript:"]:after,
      a[href^="#"]:after {
        content: "";
      }

      pre,
      blockquote {
        border: 1px solid #999;
        padding-right: 1em;
        page-break-inside: avoid;
      }

      tr,
      img {
        page-break-inside: avoid;
      }

      img {
        max-width: 100% !important;
      }

      @page :left {
        margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
        margin: 15mm 10mm 15mm 20mm;
      }

      p,
      h2,
      h3 {
        orphans: 3;
        widows: 3;
      }

      h2,
      h3 {
        page-break-after: avoid;
      }
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/darkreader@4.7.15/darkreader.min.js"></script>
  <script>
    DarkReader.enable({
      brightness: 100,
      contrast: 90,
      sepia: 10,
    });
  </script>
  <link
    rel="icon"
    type="image/png"
    href="https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTJg97A-Sa8mxjkRCmjR51WjHATLvq2aF89Z1CprR2WcQ60qYZC"
  />
  <meta name="theme-color" content="#252525" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">TCP/IP Networking</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#layers" id="toc-layers">Layers</a>
<ul>
<li><a href="#application-layer" id="toc-application-layer">Application
layer</a></li>
<li><a href="#transport-layer" id="toc-transport-layer">Transport
layer</a></li>
<li><a href="#network-layer" id="toc-network-layer">Network
layer</a></li>
<li><a href="#data-link-layer-mac-layer"
id="toc-data-link-layer-mac-layer">Data link layer (MAC layer)</a></li>
<li><a href="#physical-layer" id="toc-physical-layer">Physical
layer</a></li>
<li><a href="#skipped-first-part-of-the-lecture"
id="toc-skipped-first-part-of-the-lecture">Skipped first part of the
lecture</a></li>
</ul></li>
<li><a href="#network-layer---middle"
id="toc-network-layer---middle">Network layer - middle</a>
<ul>
<li><a href="#ip-rule-1-structured-addresses-longest-prefix-match"
id="toc-ip-rule-1-structured-addresses-longest-prefix-match">IP Rule #1
= Structured addresses + Longest prefix match</a></li>
<li><a href="#ip-rule-2-dont-use-routers-inside-lansubnet"
id="toc-ip-rule-2-dont-use-routers-inside-lansubnet">IP Rule #2 = Don’t
use routers inside LAN/subnet</a></li>
<li><a href="#ipv4" id="toc-ipv4">IPv4</a></li>
<li><a href="#ipv6" id="toc-ipv6">IPv6</a></li>
<li><a href="#nat" id="toc-nat">NAT</a></li>
<li><a href="#mac-address-resolution"
id="toc-mac-address-resolution">MAC address resolution</a></li>
<li><a href="#hostinterface-conifguration"
id="toc-hostinterface-conifguration">Host/Interface
Conifguration</a></li>
<li><a
href="#there-is-other-stuff-in-slides-that-i-skipped---58-74-in-ip"
id="toc-there-is-other-stuff-in-slides-that-i-skipped---58-74-in-ip">there
is other stuff in slides that i skipped - 58-74 in ip</a></li>
</ul></li>
<li><a href="#mac" id="toc-mac">MAC</a>
<ul>
<li><a href="#medium-access-control"
id="toc-medium-access-control">Medium access control</a></li>
<li><a href="#mutual-exclusion" id="toc-mutual-exclusion">Mutual
exclusion</a></li>
<li><a href="#switched-ethernet" id="toc-switched-ethernet">Switched
ethernet</a></li>
<li><a href="#ethernet-frame-format"
id="toc-ethernet-frame-format">Ethernet frame format</a></li>
<li><a href="#virtual-lans" id="toc-virtual-lans">Virtual LANs</a></li>
<li><a href="#bridges" id="toc-bridges">Bridges</a></li>
<li><a href="#security-aspects" id="toc-security-aspects">Security
aspects</a></li>
</ul></li>
<li><a href="#tcp-and-udp" id="toc-tcp-and-udp">TCP and UDP</a>
<ul>
<li><a href="#udp" id="toc-udp">UDP</a></li>
<li><a href="#tcp" id="toc-tcp">TCP</a></li>
<li><a href="#tcp-connection-and-sockets"
id="toc-tcp-connection-and-sockets">TCP Connection and sockets</a></li>
<li><a href="#more-tcp-details" id="toc-more-tcp-details">More TCP
details</a></li>
<li><a href="#secure-transport" id="toc-secure-transport">Secure
Transport</a></li>
</ul></li>
<li><a href="#ip-multicast" id="toc-ip-multicast">IP Multicast</a>
<ul>
<li><a href="#ssm" id="toc-ssm">SSM</a></li>
<li><a href="#multicast-arp" id="toc-multicast-arp">Multicast
ARP</a></li>
<li><a href="#multicast-in-mac" id="toc-multicast-in-mac">Multicast in
MAC</a></li>
<li><a href="#security-of-ip-multicast"
id="toc-security-of-ip-multicast">Security of IP Multicast</a></li>
<li><a href="#multicast-in-practice"
id="toc-multicast-in-practice">Multicast in practice</a></li>
</ul></li>
<li><a href="#link-state-routing" id="toc-link-state-routing">Link state
routing</a>
<ul>
<li><a href="#ospf-open-shortest-path-first-with-single-area"
id="toc-ospf-open-shortest-path-first-with-single-area">OSPF (Open
Shortest Path First) with Single area</a></li>
<li><a href="#ospf-with-multiple-areas"
id="toc-ospf-with-multiple-areas">OSPF with multiple areas</a></li>
<li><a href="#other-uses-of-link-state-routing"
id="toc-other-uses-of-link-state-routing">Other uses of Link State
Routing</a></li>
<li><a href="#software-defined-networks"
id="toc-software-defined-networks">Software defined networks</a></li>
</ul></li>
<li><a href="#congestion-control-in-networks"
id="toc-congestion-control-in-networks">Congestion Control in
Networks</a>
<ul>
<li><a href="#congestion-collapse"
id="toc-congestion-collapse">Congestion Collapse</a></li>
<li><a href="#efficiency-vs-fairness"
id="toc-efficiency-vs-fairness">Efficiency vs fairness</a></li>
<li><a href="#additive-increase-multiplicative-decrease-aimd"
id="toc-additive-increase-multiplicative-decrease-aimd">Additive
increase multiplicative decrease (AIMD)</a></li>
<li><a href="#slow-start" id="toc-slow-start">Slow start</a></li>
</ul></li>
<li><a href="#congestion-control-implementation"
id="toc-congestion-control-implementation">Congestion control
implementation</a>
<ul>
<li><a href="#tcp-reno" id="toc-tcp-reno">TCP Reno</a></li>
<li><a
href="#tcp-cubic---improving-performance-in-long-fat-networks-lfns"
id="toc-tcp-cubic---improving-performance-in-long-fat-networks-lfns">TCP
Cubic - improving performance in Long Fat Networks (LFNs)</a></li>
<li><a href="#ecn-and-aqm-active-queue-management"
id="toc-ecn-and-aqm-active-queue-management">ECN and AQM (active queue
management)</a></li>
<li><a href="#data-centers-and-tcp" id="toc-data-centers-and-tcp">Data
centers and TCP</a></li>
<li><a href="#tcp-bbr" id="toc-tcp-bbr">TCP-BBR</a></li>
<li><a href="#per-class-queuing" id="toc-per-class-queuing">Per-class
queuing</a></li>
<li><a href="#future-of-cc" id="toc-future-of-cc">Future of cc</a></li>
</ul></li>
<li><a href="#bgp-border-gateway-protocol"
id="toc-bgp-border-gateway-protocol">BGP (Border Gateway Protocol)</a>
<ul>
<li><a href="#inter-domain-routing"
id="toc-inter-domain-routing">Inter-domain routing</a></li>
<li><a href="#how-it-works" id="toc-how-it-works">How it works</a></li>
</ul></li>
</ul>
</nav>
<!-- markdownlint-disable MD010 MD041 MD001 MD036 MD029-->
<h2 id="layers">Layers</h2>
<p>Layers are abstractions of services with specific interfaces on the
devices.</p>
<p>Layers (top to bottom):</p>
<ol type="1">
<li>Application (HTTP, FTP, email)</li>
<li>Transport (TCP, UDP)</li>
<li>Network (IP)</li>
<li>Data link (Ethernet)</li>
<li>Physical (fiber optics, wires)</li>
</ol>
<p>We need layers to organize the systems. It offers flexibility and
modularity.</p>
<p>Each layer is built on top of another and offers functionality to the
layer on top of it.</p>
<h3 id="application-layer">Application layer</h3>
<p>Creates a commnunication connection. Transfers files, etc.
(encryption)</p>
<h3 id="transport-layer">Transport layer</h3>
<p>Creates a virtual link. Uses ports.</p>
<h3 id="network-layer">Network layer</h3>
<p>Packet switching over many links</p>
<p>It is more efficient than message switchin because it reduces buffer
required in routers, and reduces end-to-end delay. This is because the
each device in the sequence needs to get the whole message from the
link.</p>
<p>Basic functions:</p>
<ul>
<li>Forwarding - when a packet arrives at a router’s input link, the
router moves the packet to the appropriate output link. It is based on
the packet header.</li>
<li>Routing - network layer determines the route/path. They run routing
protocols.</li>
</ul>
<p>Forwarding - most common protocol IP IP forwarding is based on the IP
addresses. It offers best-effort approach so there is no guaranteed
delivery. Packets could be delayed, dropped, or reordered - the flow can
take different routes/paths.</p>
<p>In the LAN all device IP addresses have same prefix (common
part).</p>
<p>In IPv4 it is 32bit addresses. In IPv6 it is 128bit addresses and
uses hex notation. They are incompatible, since IPv6 has different
headers.</p>
<p>IP subnets - LAN All machines have to have same prefix. IP subnet
prefix is specified using a subnet mask - if it is 16bit subnet mask,
then the last 16 digits are free to choose.</p>
<h3 id="data-link-layer-mac-layer">Data link layer (MAC layer)</h3>
<p>Is responsible for moving data from one node to an adjacent node over
a <strong>single</strong> communication link (wired or wireless)..</p>
<p>Services provided depend on the physical link.</p>
<p>Possible functions/services included:</p>
<ul>
<li>error detection and correction</li>
<li>reliable delivery</li>
<li>collistion avoidance</li>
<li>flow control</li>
<li>link access and multiplexing for the transmission medium</li>
</ul>
<p>This layer uses MAC addresses (48bits) which are set by the
manufacturer.</p>
<p>The packets are frames that are delivered to anyone that has access
to the link and only the one that it is addressed to takes the
frame.</p>
<p>Routers vs switches</p>
<p>Router = a system (or program) that forwards packets based on IP
addresses Switches = a system (or program) that forwards packets based
on the MAC addresses LANs are interconnected by routers and there every
machine in LAN has to know IP address of the 1-hop router (default
gateway)</p>
<h3 id="physical-layer">Physical layer</h3>
<p>It transforms bits and bytes to the waves. Does all the encoding and
decoding.</p>
<p>Bit rate is bits per second. Bandwith is width of the frequency range
that can be used ofr transmission over the channel.</p>
<p>There are limits to some channels (e.g. Shannon’s law)</p>
<h3 id="skipped-first-part-of-the-lecture">Skipped first part of the
lecture</h3>
<h2 id="network-layer---middle">Network layer - middle</h2>
<h3 id="ip-rule-1-structured-addresses-longest-prefix-match">IP Rule #1
= Structured addresses + Longest prefix match</h3>
<p>goal of IP is to connect all systems using IP addresses</p>
<p>Every network interface has a structured IP address that is prefix +
suffix.</p>
<p>Router has a forwarding table that links prefixes to output</p>
<h3 id="ip-rule-2-dont-use-routers-inside-lansubnet">IP Rule #2 = Don’t
use routers inside LAN/subnet</h3>
<p>Implication:</p>
<ul>
<li>between LANs/subnets use routers, inside each subnet do not</li>
<li>hosts in same subnet must have same subnet mask and same subnet
prefix</li>
</ul>
<h3 id="ipv4">IPv4</h3>
<p>32 bits usually writen in dotted decimal notation. Unequely
identifies one interface in the internet (in principle)</p>
<h4 id="special-addresses">Special addresses</h4>
<table>
<colgroup>
<col style="width: 30%" />
<col style="width: 69%" />
</colgroup>
<thead>
<tr class="header">
<th>address</th>
<th>meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.0.0.0</td>
<td>absence of address</td>
</tr>
<tr class="even">
<td>127.0.0/24 for example 127.0.0.1</td>
<td>this host (loopback address)</td>
</tr>
<tr class="odd">
<td>10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16</td>
<td>private networks (e.g. at home) used by anyone, but cannot be used
on the public Internet</td>
</tr>
<tr class="even">
<td>100.64/10</td>
<td>private addresses used only by Internet Service Providers
(ISPs)—Carrier Grade NAT addresses</td>
</tr>
<tr class="odd">
<td>192.88.99/24</td>
<td>IPv6-to-IPv4 relay routers</td>
</tr>
<tr class="even">
<td>169.254.0.0/16</td>
<td>link local address (can be used only between systems on same
LAN)</td>
</tr>
<tr class="odd">
<td>224/4</td>
<td>multicast</td>
</tr>
<tr class="even">
<td>240/4</td>
<td>reserved until recently</td>
</tr>
<tr class="odd">
<td>255.255.255.255/32</td>
<td>link local (LAN) broadcast</td>
</tr>
</tbody>
</table>
<h3 id="ipv6">IPv6</h3>
<p>Why new version - IPv4 address space was too small What does IPv6 do:
same thing as IPv4, but with more address space but is not backwards
compatible</p>
<p>Forwarding tables work essentially the same with prefixes. Except it
uses local IP address with interface number separated byt %</p>
<p>For every IPv6 interface there has to be a global IP address and
local IP address.</p>
<p>Compression rules for IPv6 addresses:</p>
<ul>
<li>uses hex digits in hextets (4 hex digits)</li>
<li>hextets separated by :</li>
<li>leading zeroes in a hextet are omitted</li>
<li>:: replaces any number of 0s in more than one hextet; appears at
most once in address</li>
</ul>
<p>Only one block 2000/3 is allocated for global unicast addresses.</p>
<h3 id="nat">NAT</h3>
<p>Internet service provider gives one IP address, but if you have n
devices at home you need more than one IP address.</p>
<p>NAT is motivated to not run out of the IP addresses by creating local
network addresses. This applies to VMs and a single host.</p>
<p><strong>Goal of NAT:</strong> allow n &gt; 1 devices to use one
single IP address. It is a middle box that deviates from the TCP/IP arch
- it violates:</p>
<ul>
<li>the IP principle that addresses should identify hosts uniquely</li>
<li>layering</li>
</ul>
<h4 id="what-does-it-do">What does it do?</h4>
<p>It translates internal IP addresses and port numbers to NAT IP
address and NAT port numbers. From outside, one sees only NAT IP address
(public) and NAT port</p>
<p>NAT forwarding is based on <strong>exact matching</strong> in NAT
table. Implemented by iptables in Linux; ports are UDP or TCP.</p>
<p>NAT because of this reduces the amount of processes possible to run
on a machine, but we have 65000 available port numbers. And adds
additional delay because the packets are processed - transport and
network layer headers edited.</p>
<p>There could be nested NATs.</p>
<p>Internal addresses in IPv4 are typically private addresses.</p>
<h4 id="how-does-nat-maintain-nat-table">How does NAT maintain NAT
table?</h4>
<p>It creates entry on-the-fly when cliend on internal network contacts
server on external network. NAT chooses a NAT port that does not create
collision in the table.</p>
<h4 id="servers-behind-nat">Servers behind NAT</h4>
<p>Assume A has a server on tcp port 5000.</p>
<p>Problem: Automatic operation automatic operation of NAT requires for
the server to start the communication which does not happen.</p>
<p>Solution: manual configuaration of port forwarding in NAT. A still
needs to find out its NAT address to advertise to other devices. A
discovers its NAT IP address with STUN server or UPnP (it is unsafe and
we shouldn’t use it).</p>
<p>This provides protection to home network: a server port number can
only be accessed if explicitly configured, while servers on the internet
are exposed in general to attacks and need to be actively protected.</p>
<p>NAT table port entries are allocated randomly (pseudo randomly), and
the entries are not there forever.</p>
<h4 id="nats-and-ipv6-v1">NATs and IPv6, v1</h4>
<p>NAT was developed for IPv4, motivated by the lack of IPv4</p>
<p>With IPv6, home routers often do not use NAT because provider
typically allocates a block of IPv6 addresses, not just one as with
IPv4</p>
<p>With IPv6 the home router provides protection by acting as a
filtering router - allows communication from outside only if initiated
from inside.</p>
<h4 id="nats-and-ipv6-v2">NATs and IPv6, v2</h4>
<p>There is a system to still use IPv6</p>
<p>Assume local network receives only one IPv6 address, not entire
prefix. Solution: use NAT with link local IPv6 addresses on internal
network. Local network should be restricted to one LAN (only one
subnet)</p>
<p>this is used by the VirtualBox(“NAT network”)</p>
<h4 id="carrier-grade-nats">Carrier-grade NATs</h4>
<p>“Carrier-grade” NAT shares p external NAT addresses with n &gt; p
internal hosts. So there are multiple external interfaces.</p>
<p>Example is VPN access of EPFL. Some users might be connected with the
same address, or some might be different.</p>
<p>These are NATs behind NATs: A is 192.168.178.34 at home, as
10.252.13.211 in EPFL VPN and as 128.178.15.x in the public internet</p>
<p>Some internet service providers do the same in order to reduce the
number of IPv4 addresses allocated to end-users. They use the block
100.64/10 instead of 10/8</p>
<h4 id="more-on-nats">More on NATs</h4>
<p>Mapping (internal addr, internal port) -&gt; (NAT addr, NAT port) is
independent of the external corrsepondent. If this mapping is constant,
then <strong>full cone NAT</strong> can be used to support servers
behind NAT. (servers use STUN servers to get their publicly seen IP
address)</p>
<p>Not all NATs are full cone.</p>
<p>There is a <strong>symmetric</strong> NAT that has the mapping
(internal addr and port, external (someone outside) addr and port) -&gt;
(NAT addr, NAT port). So the mapping learnt by one external
correstpondent S cannot be used or guessed by another S’</p>
<p>ICMP packets don’t have a port number. Some NATs don’t support ICMP,
but many do. Those are smart NATs that manipulate <em>ICMP echo request
identifier</em> instead of the port number.</p>
<h3 id="mac-address-resolution">MAC address resolution</h3>
<p>WHY? And IP machine A has a packet to send to a next-hop B (could be
a final destination or next-hop router). A knows B’s IP address, and A
must find B’s MAC address.</p>
<p>HOW? Broadcast or multicast a packet to LAN asking “who has the IP of
B?” All hosts that have IP address of B respond with their MAC
address.</p>
<h4 id="mac-address-resolution-with-ipv6-ndp">MAC address resolution
with IPv6 (NDP)</h4>
<ol type="1">
<li>A sends a Neighbour Solicitation (NS) packet using the Neighbour
Discovery Protocol (NDP) with question “who has IP address B”
<ol type="1">
<li>The dest IP address of the NS packet is a special multicast address
(solicited Node Multicast Address) = last 24 bits are copied by IP’s
address</li>
</ol></li>
<li>B responds with Neighbour Advertisement (NA) packet, giving its MAC
address. This NA packet is sent by B to A</li>
<li>A reads NA, stores MAC address in neighbour cache (also called ARP
table). This entry expires after a timer declared by OS.</li>
</ol>
<p>NA, NS packets are carried as ICMPv6 packets - next-header = 58
(0x3a), inside IPv6 packets.</p>
<p>The convention in IPv6 is not to use broadcast.</p>
<p>The solicited node multicast address: last 24bits are left for the
identifier (reuses the last 24 bits of the IP address), and we reser 104
bits for the multicast. This is because these nodes are in the same
LAN</p>
<p>The more specific the question is the better for the network.</p>
<h4 id="mac-address-resolution-with-ipv4-arp">MAC address resolution
with IPv4 (ARP)</h4>
<p>ARP request/ARP reply instead of NS/NA packets</p>
<p>Theses are MAC frames where Ethernet = ARP (86dd)</p>
<p>ARP request is broadcast to all nodes in LAN</p>
<p>ARP is another protocol that is in-between MAC and Network layers. In
its header there is a Protocol field that shows which protocol initiated
the request, and in this case it would be IP.</p>
<h4 id="security-issues-with-arpndp">Security issues with ARP/NDP</h4>
<p>ARP requests/replies may be falsified (ARP spoofing) Atacker will
capture all packets intended to B. This is the way to do MITM attack in
LAN.</p>
<p>Prevention: This is done only in big enterprise networks. using smart
switches - they remember association the IP to MAC addresses. This is
called <strong>DHCP snooping</strong>, where DHCP is used to
automatically configure the IP address at system startup.</p>
<p><strong>Dynamic ARP inspeciton</strong> - switch filters all ARP (or
NDP) traffic and allows only valid answers - removes broadcasts (IPv4)
and multicasts (IPv6)</p>
<h4 id="secure-ndp">Secure NDP</h4>
<p>Make NDP spoofing impossible</p>
<p>How? Assymetric crypto:</p>
<ul>
<li>Host B has a pub/priv key par P/p</li>
<li>B uses CGA( cryptographically generated address) = secure hash of P
and IPv6 address prefix (and other fields such as counters) - this binds
the IP adddress to P</li>
<li>NA message sent in response to A contains a signature computed with
p</li>
<li>A can verify signature using P</li>
<li>only the owner of p (secret) can send a valid NA</li>
</ul>
<p>Some necessary things: they need to have strong has function and
Resource Public Key Infrastructure (RPKI) (similar to CA).</p>
<h3 id="hostinterface-conifguration">Host/Interface Conifguration</h3>
<p>IP can be configured manually or automatically:</p>
<ul>
<li>IP address of interface</li>
<li>Mask of this interface</li>
<li>IP address of default router</li>
<li>IP address of DNS server</li>
</ul>
<p>Some protocols: DHCP for IPv4 and IPv6, SLAAC for stateless IPv6</p>
<h4 id="dhcp">DHCP</h4>
<p>Server in LAN, where all the information info is kept.</p>
<p>Problem: host cannot contact the DHCP server since it does not know
of <strong>any</strong> IP address initially. Solution: broadcast in
IPv4 or multicast in IPv6 in LAN to discover DHCP server Details:</p>
<ul>
<li>either there is DHCP in LAN</li>
<li>there isn’t a DHCP in LAN and router relays the message to external
server</li>
<li>DHCP uses two phase commit with acks to avoid inconsistent
reservations</li>
<li>DHCP server suses limited lifetime allocations - DHCP lease.</li>
</ul>
<h4 id="slaac-stateless-address-autoconfiguration">SLAAC (Stateless
Address Autoconfiguration)</h4>
<p>It is a protocol designed to avoid configuring DHCP serverse and/pr
obtain a configuration automatically even if there is no DHCP
server.</p>
<p>How it works:</p>
<ol type="1">
<li>how auto-configures a link local address with a 64-bit prefix
(fe80::/64) + a 64-bit host address part obtained by one of the
following: (manually configured, derived from MAC address, randomly
assigned and teporary, randomly assigned but same in same subnet,
cryptographically generated address (CGA) - hash of pub key or host +
subnet)</li>
<li>host performs address duplication test by sending a mylticast packet
to the solicited node multicast addess with the same 24 last bits as its
own address</li>
<li>host tries to also obtain globally valid address by obtaining
network prefix from routers if any presend.</li>
</ol>
<p>It does not provide DNS information.</p>
<h3
id="there-is-other-stuff-in-slides-that-i-skipped---58-74-in-ip">there
is other stuff in slides that i skipped - 58-74 in ip</h3>
<h2 id="mac">MAC</h2>
<h3 id="medium-access-control">Medium access control</h3>
<p>exists so that sharing a cable is possible and using a shared
wireless radio link</p>
<p>If there is a shared medium, there are collisions.</p>
<p>Solutions: Mutual exclusion protocol + distributed Joint decoding –
used in cellular networks</p>
<h3 id="mutual-exclusion">Mutual exclusion</h3>
<p>Deterministic - static partitioning on time or frequency to avoid
collisions (TDMA, FDMA) and works for only few users</p>
<p>other deterministic - every host takes a turn and passes a token to
next host</p>
<p>Random access protocols that allow collisions but detect if they
occur (retrasnmissions at <em>random</em> time)</p>
<h4 id="aloha">ALOHA</h4>
<p>Collisions occur when two packet transmissions overlap and if a
packet is lost - then the source has to retransmit (no retransmission
strategy is defined here)</p>
<p>There is no feedback to the source in case of collision</p>
<p>Max utilization is only 18% which is small. This is assuming ideal
retransmission policy</p>
<h4 id="csma-carrier-sense-multiple-access">CSMA (carrier sense multiple
access)</h4>
<p>assumes single transitive channel (everyone can hear everyone).</p>
<p>improves efficiency from ALOHA by listening to the channel before
transmitting</p>
<p>It avoids many collisions but not all because of propagation delays -
if two stations sense the free medium, and then have to backoff, it can
again start transmittting.</p>
<p>CSMA works well only if the transmission time is much larger than
propagation, namely bandwidth-delay product &lt;&lt; frame size</p>
<p>In order to avoid repeated collisions there is a random backoff.</p>
<h4 id="csmacd-collision-detection">CSMA/CD (Collision detection)</h4>
<p>When the collision is found (transmitting and started receiving), jam
signal is transmitted. Then a random backoff</p>
<p>Acks are not necessary because absence of collision means that the
fram could be retransmitted</p>
<p>Random backoff increases exponentially if repeated collisions
occur</p>
<p>Minimum frame size is necessary to guarantee collision detection
-&gt; CSMA/CD uses min frame siOld-style Ethernet was shared medium
(either used coax cables or hubs with twisted-pair coppze 64B</p>
<h4 id="csmaca---wifi">CSMA/CA - WiFi</h4>
<p>Acks are used to detect collisions (by abscence)</p>
<p>Carrier sensing is used but collision detection does not always work
(exposed terminal problem)</p>
<h3 id="switched-ethernet">Switched ethernet</h3>
<p>It is based on switches = beidges</p>
<p>Switches forward frames based on MAC addresses and they have queuing
system (frame buffers)</p>
<p>Switches use full-duplex cables which means frames flow
simultaneously in both directions without having collisions.</p>
<p>Ethernet is transparent protocol and since there are no collisions,
CSMA/CD is desabled by default</p>
<h4 id="forwarding-frames">Forwarding frames</h4>
<p>Exact match forarding algorithm:</p>
<ul>
<li>listen to all traffic on all ports</li>
<li>for each frame - read the destination MAC and obtain the destination
porrt (if dest port == origin port, no need to forward)</li>
<li>if dest address is not in the table - broadcast to all ports except
origin</li>
</ul>
<p>Smarter switches handle multicast addresses separately</p>
<p>Populating:</p>
<ul>
<li>self-learning from source MAC address</li>
<li>learnt addresses time out if not re-learnt after “ageing time”</li>
</ul>
<p>different from IP routers that use routing algorithms</p>
<p>This populating does not always work - if there are loops in the
topology</p>
<h4 id="spanning-tree-protocol-stp">Spanning Tree Protocol (STP)</h4>
<p>Forces the active topology to be a tree that spans all switches by
deactivating some links</p>
<p>Adapts to link failures and additions whenever needed</p>
<p>How?:</p>
<ol type="1">
<li>Switches elect one root switch - switch with smallest label ID</li>
<li>Only links that are along the shortest path to root switch become
active - spanning tree = set of shortest paths to root switch</li>
<li>all switches monitor whether the root is reachable, and if not
re-computation of a new spanning tree</li>
</ol>
<p>It is distributed algorithm Each link between switches has a
(configurable) cost Shortest paths are identified by using a variant of
the Bellman-Ford algorithm</p>
<p><strong>Side-effect</strong> - all frames go through the spanning
tree, direct link between two non-root switches may not be used even if
it is optimal</p>
<p>It is less efficient than the shortest path Some more sophisticated
switches implement Shortest path bridging instead of STP</p>
<h3 id="ethernet-frame-format">Ethernet frame format</h3>
<p>Has error detectio with Frame Check Sequence. Uses CRC 32bits If
frame fails the check, it is dropped.</p>
<h4 id="mac-unicast">MAC Unicast</h4>
<p>MAC address - 48 bits - unique worldwide (adpter ID)</p>
<p>In shared-medium LAN - all stations read all frames but keep only if
destination address matches In switched Ethernet - switches forward only
to ports that need it</p>
<h4 id="mac-broadcast">MAC Broadcast</h4>
<p>In shared-medium LAN all machines receive the packet and don’t
discard it In switched ethernet - broadcast frames are sent on all nodes
and ports on the spanning tree</p>
<h4 id="mac-multicast">MAC Multicast</h4>
<p>MAC addresses with 8th bit == 1 are multicast addresses</p>
<p>makes sense only in switched Ethernet - ethernet adapter discards
multicast packets unless host subscribes to address non-smart switches
broadcast such frames smar switches send only to relevant nodes</p>
<h3 id="virtual-lans">Virtual LANs</h3>
<p>Invented to have more traffic isolation to make more efficient use of
switches to manage users</p>
<p>Goal: decouple who belongs to which LAN from their physical
location</p>
<p>They are handled as if they are physically separate</p>
<p>How does it work?:</p>
<ul>
<li>configure which switch port belongs to which VLAN</li>
<li>switch handles ports of different VLANs as separate, non
communicating worlds</li>
<li>switches are interconnected via <strong>trunk</strong> ports that
use VLAN tags in an ehternet’s extended header in order to correctly
allocate frames to VLANs</li>
</ul>
<h3 id="bridges">Bridges</h3>
<p>switches that are used between different medium access technologies
(e.g. WiFi and ethernet)</p>
<p><strong>Wifi access point</strong> is a bridge example. It consists
of wifi base station and a switch with an ehernet backend (called the
Distribution System)</p>
<h3 id="security-aspects">Security aspects</h3>
<p>MAC addresses are sent in the clear, so there are possible
attacks:</p>
<ul>
<li>eavesdropping</li>
<li>free riding</li>
<li>impersonation</li>
</ul>
<p>Solutions (MACSEC):</p>
<ul>
<li>Access control - requires user to show credentials before allowing
access to the network
<ul>
<li>share secret (E.g. Wifi WPA-Personal) - same password for all
users</li>
<li>per-user authentication (e.g. wifi WPA-Enterprise) - user has a
personal password</li>
</ul></li>
<li>Authentication - every MAC frame is signed using crypto and numbered
- prevents free riding and impersonation</li>
<li>Encryption - MAC frame payload is encrypted (not MAC address) -
prevents eavesdropping</li>
</ul>
<h2 id="tcp-and-udp">TCP and UDP</h2>
<p>Transport layer makes the network services available to programs and
is in end-systems only</p>
<h3 id="udp">UDP</h3>
<p>uses port numbers and the server’s port numbers must be well-known to
clients</p>
<p>src and dest port numbers are inside transport-layer header</p>
<p><strong>Server</strong> - the role of a program that waits for
requests to come (abstraction in this context)</p>
<h4 id="udp-is-message-oriented">UDP is message-oriented</h4>
<p>UDP delivers the exact message or nothing</p>
<p>one message, up to 65535 bytes</p>
<p>consecutive messages may arrive out of order messages may be lost</p>
<p>If a UDP message is larger than the maximum size for the IP layer
(MTU) then fragmentation is done -this is not visible to the application
layer</p>
<h4 id="socket-library">Socket library</h4>
<p>there are IPv4 and IPv6 sockets, so to get what we <em>can</em> have
we do <code>socket.getaddrinfo()</code></p>
<p>This does not affect UDPv6 - UDP and TCP are not affected by IP
layer</p>
<p>IPv6 socket can be dual-stack - (on some dual-stack machine) IPv6
socket can be bound to both IPv6 and IPv4 addresses of the local host
This is achieved by mapping correspondents’ IPv4 to IPv6 addresses using
the IPv4-mapped IPv6 address format - last 32 bits are of IPv4</p>
<h4 id="socket-from-operating-system-perspective">Socket from Operating
system perspective</h4>
<p>Socket is just 2 buffers - one for sending and one for receiving.
Sending buffer is necessary because if there is a backoff, the
information needs to be stored somewhere Receive buffer is necessary
because we could be receiving more data than the application can read.
But there could be a buffer overflow - UDP does not do anything about
this.</p>
<p>At sending side OS sends the UDP datagram ASAP</p>
<p>At receiving side OS reassembles UDP packets (if needed) and keeps
them in buffer.</p>
<h3 id="tcp">TCP</h3>
<p>Packets could be lost because of buffer overflow, physical layer
errors, or reordered because of different paths</p>
<p>UDP does nothing about that TCP does that at transport layer</p>
<p>TCP guarantees that the data is delivered in order and without
loss</p>
<p>TCP does not do data fragmentation, it makes packets of the required
MTU size</p>
<h4 id="tcp-delivery-guarantee">TCP delivery guarantee</h4>
<p>Sender sends packet with seq a:b, receiver sends back ack with b. Ack
is a cumulative ack which means that it has received everything up to
that ack. There are also selective acks (sack) - that received a packet
of x:y, such that retransmission would not include that one.</p>
<p>TCP receiver uses a <strong>receive buffer</strong> =
<em>re-sequencing buffer</em> to store incoming packets before
delivering them to application This is because: Application might not be
able to take in the data pakcets might have arrived out-of-order but
kept invisible to application</p>
<p><strong>Duplicate acks</strong> - acknowledgement with the same ack
number as before (could have a <code>sack</code> in addition)</p>
<h4 id="sliding-window">Sliding window</h4>
<p>the receive buffer may overflow if one piece of data “hangs”
(myltiple losses affect the same packet, so there are multiple
out-of-order packets fill the buffer) The sliding window limits the
number of data “on the fly” - not yet acknowledged</p>
<p>How does it work: window size - 4000B, each segment - 1000B Only seq
numbers that are in the window may be sent lower window edge = smallest
non acknowledge sequence number upper window edge = lower edge + window
size</p>
<p>Fixed size window cannot prevent receive-buffer overflow, because the
receiver application might not be fast enough to read the data.</p>
<h4 id="flow-control">Flow control</h4>
<p>Adaptive window size is sent from the receiver to the sender to show
how much space is currently in the receive buffer. Sender adapts
source’s sending rate to the receiver’s buffer.</p>
<p>it’s not equal to congestion control.</p>
<p><em>What is a problem when a 0 window is sent:</em> We need to make
sure that the sender is later unblocked. This can be done by sending the
same ack but with different window. But this new ack can be lost. So TCP
allows sender to send 1 byte to check whether the windown has changed
(like probing)</p>
<p>What is the minnimum window size required for sending at the maximum
possible rate: RTT * link capacity (bits/second)</p>
<h3 id="tcp-connection-and-sockets">TCP Connection and sockets</h3>
<p>I know SYN sequence and FIN sequence</p>
<h4 id="sockets">Sockets</h4>
<p>Difference from UDP - they need to open and close the connection</p>
<p>TCP connection is identified by src IP, src port, dest IP, dest
port</p>
<p>From OS POV the buffers are re-sequencing buffers.</p>
<h4 id="mss-and-segmentation">MSS and segmentation</h4>
<p>TCP avoids to segments its data at IP layer so makes segments into
maximum segment size (MSS).</p>
<p>Default values are:</p>
<ul>
<li>536 bytes for IPv4 operation</li>
<li>1220 bytes for IPv6 operation</li>
</ul>
<p>Otherwise negotionated in Options header field during connection
setup</p>
<p>TCP offers streaming service, which is not great for connections that
do not immediately fill up the TCP block (HTTP/2, streaming video,
etc)</p>
<h3 id="more-tcp-details">More TCP details</h3>
<p>Corner cases - application writes 1 byte into the socket - should TCP
send a packet or wait for more bytes to be written? (This is an overhead
because header is 20 bytes). Also, should it only send in when the MSS
is full? <strong>Nagle’s algorithm</strong> prevents sending many small
packets. This overhead makes TCP suffer only in WAN because LANs are
fast. When we receive an ack (get RTT), then send all the data. If the
RTT is small (network fast), the overhead does not make big impact.</p>
<p>How to avoid silly window-increase advertisements by 1 byte?</p>
<p>Window field is 16bits, hence the max throughput for RTT=1msec is
approx. 524Mbps - can we increase this? <strong>yes</strong>, use
<em>scaling factor</em> fof the window during connection setup</p>
<h4 id="tcp-loss-detection">TCP loss detection</h4>
<p><strong>timer - retransmission timeouts (RTO)</strong> - when one
timer expires, it is interpreted as a severe loss in the channel
(nothing can be delivered in the channel anymore). Then all timers are
reset, all un-acked data is marked as needing retransmission.</p>
<p><strong>duplicate ACK</strong> - a TCP packet where the ACK value
repeats a previously received ACK value. Means that the daat is out of
order.</p>
<h5 id="round-trip-time-rtt-estimation">Round trip time (RTT)
estimation</h5>
<p>RTO must be set at a value larger than RTT, because otherwise we
flood the network. How to estimate RTT - moving average with the last
measured RTT, smoother RTT and RTT variability metric.</p>
<p>RTO increases depending on the variability of RTT which is always
absolute value. Therefore it can be quite inaccurate at sometimes. So,
it could be better to look more at duplicate acks rather than wait for a
complete timeout.</p>
<h4 id="fast-retransmit">Fast Retransmit</h4>
<p>Instead of waiting for one duplicate ACK, we wait for <code>n</code>
duplicate ACKs, and then declare loss.</p>
<p>However, it fails when one of the last segments of an application
layer block is lost, fast retransmit does not detect it. Also, it may
often fail due to packet re-ordering. It does not detect bursts of loss,
if (forward or reverse) channel is broken, and isolated/single packets
that are lost are not detected.</p>
<p>2 counter measures for the retransmissions that were not lost but
just reordered:</p>
<ul>
<li>IP layer <strong>per-flow load balancing</strong></li>
<li><strong>RACK (recent ACK)</strong> instead of duplicate ACKs - it
decides that packet p is lost if another out-of-order packet is acked
and p has not been ACKed after the estimated RTT + configrable
reordering (time) window. Bases retransmissions on timers not seq
nums</li>
</ul>
<h4 id="syn-cookies-specific-initial-seq-numbers">SYN Cookies (=
specific initial SEQ numbers)</h4>
<p>To mitigate the impact of SYN flood attack - lots of bogus SYN
packets from (spoofed) source addresses sent to a server.</p>
<p>When server receives a SYN packet it allocates some space for the
socket and enters SYN state. To control this, there was a limit for the
sockets in SYN state, which allows the SYN flood attack, since server
would not have more space for new requests.</p>
<p>So instead of creating the SYN state, we create SYN cookie, which is
a sequence number. SYN Cookie = (5 bits of a slow timer) mod 32 || (3
bits) MSS encoded in SYN || (24 bits) crypto hash of secret server key,
timestamp and client IP address and port number, the server IP address
and port number.</p>
<p>This does not completely diminish the threat of DoS attack, by
attacker sending ack=y+1 However, now client should have the same amount
of memory for states and the server needs to have to ack these
syn-acks.</p>
<p>With SYN Cookies it takes more time for server to send back the
SYN-ACK due to the computation required for the cryptographic hash. So
any damage that could happen from the attack is the loss of computation
for the hashes.</p>
<p>Also, this does not stop the DDoS</p>
<h4 id="tcp-fast-open-fto">TCP Fast Open (FTO)</h4>
<p>Avoid 3-way handshake when opening repeated connections.</p>
<p>In the first SYN-ACK TCP client receives inside TCP options and
caches a cookie that contains <strong>authentication tag t =
MAC(k,c)</strong> (message authentication code) computer by server key
with secret key k and client IP address c.</p>
<p>In the next connection client can send data in SYN packet. When
receiving SYN and tag t, sever already knows that this client is a real
one that has connected before. And server can send data already in
SYN-ACK.</p>
<h3 id="secure-transport">Secure Transport</h3>
<p>TCP is not secure unless we use another sublayer on top - TLS.</p>
<p>TLS adds to TCP:</p>
<ul>
<li>Confidentiality - data is encrypted with symmetric encryption, which
are created on the fly for this session (using privkeys)</li>
<li>Authentication - data is protected against forgery, and identity of
end-system us authenticated.</li>
</ul>
<p>TLS before 1.3 used RSA key exchange with CA signed certificates.</p>
<p>A digital certificate contains a public key of the server and the
identity of the server. The public key of the the CA could be included
in the certificate but it could have been tampered with so we should not
use it.</p>
<h5 id="tls-1.3">TLS 1.3</h5>
<p>Does not support RSA key exchange.</p>
<p>In principle, it needs 1-RTT handshake before sending message.</p>
<p>Communicating parties agree on cryptographic suites, and exchange
crypto parameters to exchange session keys.</p>
<h5 id="tls-sockets">TLS sockets</h5>
<p>are transformetd TCP sockets, which wrap the sockets with necessary
crypto parameters after SYN sequence - server/client hello.</p>
<p>2 RTTs are necessary for the data transfer (from TCP perspective). 1
RTT from TCP handshake, and 1 RTT from TLS handshake.</p>
<h2 id="ip-multicast">IP Multicast</h2>
<p>SLAAC uses the multicast to find the prefix of the network by sending
the messages to nearby routers.</p>
<p>Multicast is used to send to a group of destinations. (E.g. for the
streaming the same stream on several devices)</p>
<p>In multicast, there is a multiplication of the packets which means
that using TCP on top of multicast would not make sense because of the
sequence numbers.</p>
<p>Multicast is done through specific address spaces - 223.0.0.0/4 and
ff00::/8.</p>
<p>An IP multicast address is used to identify a group:</p>
<ul>
<li>Any source multicast (ASM): the group is identified by the multicast
address, any source can send to this group</li>
<li>Source specific multicast (SSM): the group is defined by (s, m)
where m is multicast address and s is the source address. Only s can
send to this group. By default 232.0.0.0/8 and ff3x::/96 are SSM
addresses</li>
</ul>
<h3 id="ssm">SSM</h3>
<p>destinations subscribe via IGMP (internet group management protocol
in IPv4) or MLD (Multicast Listener Discovery in IPv6), send join
messages to their gateway routers. These routers will keep this
information in their cache, and also will notify other routers along the
path to the source about dest joining the group. routers either build
distribution tree via a <strong>multicast routing protocol</strong>
(PIM) or use tunnels (BIER)</p>
<p>If the clients are not subscribed to the group, the packet sent by
the source will be dropped by the router.</p>
<p>source simply sends <strong>UDP</strong> packets to multiast address
m <strong>packet multiplication</strong> is done by routers at the IP
layer.</p>
<h4 id="pim---protocol-independent-multicast">PIM - Protocol Independent
Multicast</h4>
<p>most widespread multicast routing protocol, which supports ASM and
SSM.</p>
<p>two versions:</p>
<ul>
<li>PIM-DM (Dense mode) - uses broadcast and therefore can be only used
in small, controlled networks</li>
<li>PIM-SM (Sparse mode) - more reasonavle and is used for e.g. TV
distribution. It uses reverse path forwarding - when ar outer needs to
add a receiver, it sends a PIM/JOIN router message towards the source,
using unicast routing - which creates the distribution tree <em>on the
fly</em>.</li>
</ul>
<p>It is independent of the underlying protocol which populates the
routing tables (manual but could also be automatic, e.g. OSPF).</p>
<p><strong>Per-flow state</strong>: router holds multicast state
information:</p>
<ul>
<li>(s,m) or (*,m) - id of the group</li>
<li>valid incoming interfaces - for security</li>
<li>outgoing interfacses - the routing info</li>
<li>other information required by multicast routing protocol</li>
</ul>
<p>This per-flow (per-group) state cannot be aggregated based on the
prefix - this causes scalability issues. Therefore this creates stress
on backbone routers.</p>
<h4 id="bier---bit-index-explicit-replication">BIER - Bit Index Explicit
Replication</h4>
<p>Alternative to PIM, to not have to apply exact match</p>
<p>BIER is aided by a centralized entity - multicast flow overlay (it
can be video distribution control servers or Multicast VPN or SDN) - it
essentially works like a DNS which relates clients to groups.</p>
<p>So when the router gets BIER join message, it notifies the central
entity. The same goes for routing of the packet - router asks central
router who is a member of this group, and they get the edge routers who
to send to (because the amount of edge routers is less than amount of
clients). Source, when it sends a packet, appends the BIER header with
the list of destinations (edge routers) to the IP header.</p>
<p><em>Edge router</em> - last router before the LAN</p>
<p><strong>Packet forwarding</strong>: for every destination BFER, BIER
router pre-computes )based on the IP forwarding table a “forwarding bit
mask” that indicates the set of destination BFERs that are reached bu
the same next-hop.</p>
<p>Algorithm: Router sends a packet to 1st destination in the
destination set S; packet has destination set = <span
class="math inline">S \cap S_1</span> where <span
class="math inline">S_1</span> is the forwarding bit mask of 1st
destination. Then, if <span class="math inline">S \backslash S_1 \ne
\empty</span>, duplicate the packet but with destination <span
class="math inline">S \backslash S_1</span> and goto 1; else break.</p>
<p>The goal is to find how many times I have to duplicate the packet on
the same path. I only need to duplicate the packet only if I send to
different paths.</p>
<p>BFERs - set of destinations is aencoded using a bitstring (for easier
computations - intersection becomes logical and, difference becomes
logical and with logical not)</p>
<p>Example with 5 possible BFERs: Destination BFERs = {1,3,4} -&gt; 0
1101 Destiantion BFERs = {3,4} -&gt; 0 1100 Destination BFERs = {1}
-&gt; 0 0001</p>
<p>If there are x edge routers, there will be x bits in hte
bitstring.</p>
<p>There is no per-flow state kept at the routers, but there is Bier
Index Forwarding Table (derived from router’s unicast IP forwarding
table), which is <strong>static</strong>.</p>
<h3 id="multicast-arp">Multicast ARP</h3>
<p>There is no multicast MAC address is algorithmically derived from
multicast IP address. IPv6: 33-33-XX-XX-XX-XX (last 32 bits from IP
address) IPv4: 01-00-5e-YX-XX-XX (last 23 bits from IP address, 1st bit
of Y hextet is 0)</p>
<p>Multicast address depends only on multicast address m, not on source
address s, even if m is an SSM address. Several multicast IP addresses
may yield the same MAC adddres, so there could be collisions and packets
may arrive there even if not inteded - then the OS would drop the
packet.</p>
<h3 id="multicast-in-mac">Multicast in MAC</h3>
<p>non-smart switches forward the packet to all destinations.</p>
<p>smart switches look into IGMP/MLD packets and remember the
subscribers, and deliver only to intended recipients. They do not
distinguish between SSM and ASM.</p>
<h3 id="security-of-ip-multicast">Security of IP Multicast</h3>
<p>IP multicast with or without BIER makes life easier for attackers
(e.g. DoS, witty worm). To mitigate - control with access control in
access lists.</p>
<p>SSM is safer because routers can discard unwanted sources.</p>
<p>IGMP/MLD are not secured and vulnerable to similar probles as
ARP/NDP.</p>
<p>Therefore multicast-capable networks must deploy extensive
<strong>filtering</strong> and <strong>monitoring</strong></p>
<h3 id="multicast-in-practice">Multicast in practice</h3>
<p>Multicast is used in:</p>
<ul>
<li>EPFL and other academic networks (PIM-SM)</li>
<li>Data Center Virtualization Services (BIER)</li>
<li>Internet TV distribution (PIM-SM/BIER)</li>
<li>TV, sensor streaming, time sync, large videoconferences, etc.</li>
<li>industrial networks - smart grids, factory automation</li>
</ul>
<p>Works only with UDP</p>
<h2 id="link-state-routing">Link state routing</h2>
<p>Routing is at the Control plane Forwarding is at the Data plane.</p>
<p>Forawrding tables can be set manually but it is time-consuming and
error-prone</p>
<p>A routing protocol or algorithm allows routers to compute
automatically their forwarding tables, and resides in the control
plane.</p>
<p>It depends on scope:</p>
<ul>
<li>Interior - intra-domain routing (OSPF)</li>
<li>Exterior - inter-domain routing (BGP)</li>
</ul>
<h4 id="taxonomy-of-routing-protocols">Taxonomy of routing
protocols</h4>
<p><strong>Link State algorithms</strong>:</p>
<ul>
<li>all routers maintain a map of the entire topology (obtained by
gossiping with other routers). Every link has a cost</li>
<li>routers compute shortest paths based on their maps to determine next
hops (Dijkstra)</li>
<li>it is typically used for intra-domain routing (OSPF, IS-IS) and
advanced bridging methods (TRILL, SPB Shortest Path Bridging)</li>
</ul>
<p><strong>Path vector</strong>: every router knows only its neighbours
and explicit paths to all destinations. It is used for inter-domain
routing</p>
<p><strong>Distance vector</strong> (e.g. RIP - used for small
networks):</p>
<ul>
<li>there is no global map</li>
<li>initially, every router knows only about neighbours</li>
<li>then each router informs its neighbors about its estimated distances
and learns new destinations and updates its vector of estimated
distances to all destinations with the next hop (Bellman-Ford
algorithm)</li>
<li>it converges to optimal paths</li>
<li>If a link fails, it takes time to make updates</li>
</ul>
<p><strong>Source routing</strong> - “strict”</p>
<ul>
<li>Paths computed by the source and put into packet headers</li>
<li>The path is the sequence of all intermediate hops</li>
<li>With IPv6, routing header is an extension header - contains
intermediate hops and ultimate destination. When present, Destination
Address is next intermediate hop.</li>
<li>Used in ad-hoc networks (DSR). And if you want to get a path to a
destination, you flood the “explorer” packets in the network</li>
</ul>
<p><strong>Source routing</strong> - “loose” specify some intermediate
hops (the path to that intermediate hop is computed with other
protocol). Reasons why it exists - it is the filtering router, or
conducts packet inspection</p>
<p><strong>Segment routing</strong> - does source routing but also
applies a function (screening or traffic separation). Used in data
centers.</p>
<h3 id="ospf-open-shortest-path-first-with-single-area">OSPF (Open
Shortest Path First) with Single area</h3>
<p>Every router has:</p>
<ul>
<li>interface database (physical connecitions - learnt by
configuration)</li>
<li>adjacency database (neighbors’ states - learnt by <em>hello</em>
prootcol)</li>
<li>link state database (network map (list of links) - learnt by
flooding)</li>
</ul>
<p><em>Hello</em> protocol: ping-style, used to discover neighboring
routers, and to detect failures (e.g. if neighbor did not respond after
3 times it is considered “dead”)</p>
<h4 id="link-state-database-and-lsas">Link state database and LSAs</h4>
<p>Routers <strong>synchronize</strong> their link state databases when
they become neighbors: if one router is new and copies what the other
already knows otherwise, they merge/concatenate their databases</p>
<p>After synchronization, a router sends and accepts <strong>link state
advertisements (LSAs)</strong>:</p>
<ul>
<li>every router sends one LSA describing its attached networks and
neighboring routers</li>
<li>LSAs are flooded to the entire area and stored by all routers in
their link state database</li>
<li>LSAs contain a <strong>sequence number</strong> and
<strong>age</strong> - only messages with new sequence number are
accepted and re-flooded to all neighbors. (sequence number prevents
loops, age field is used to periodically resend LSA and to flush invalid
LSAs)</li>
</ul>
<p>There is also a network LSA: it exists on ethernet topology with more
than one routers, and it has a <strong>Designated Router</strong>. One
of the ways to create a topology for this case is to create a mesh (but
this complicates Dijkstra), so routers choose one Designated Router
which creates the mapping. (risk - DR may fail all together - then they
would need to rechoose DR again - detected by a missing “network LSA”
part)</p>
<h4 id="topology-graph">Topology graph</h4>
<p>the link state database descibes an oriended graph with outgoing edge
cost = cost given in LSA.</p>
<p>Every router and every Ethernet network corresponds to one node in
the graph (cost from network node to router node is 0 by default)</p>
<p>OSPF packets are sent directly over <strong>IP</strong> (OSPF
protocol = 89) Reliable transmission is managed by OSPF with OSPF
<strong>acks and timers</strong></p>
<p>OSPFv2 supports IPv4 only OSPFv3 supports IPv6 and dual-stack
networks</p>
<h4 id="path-computation-uses-dijkstras-algorithm">Path computation uses
Dijkstra’s algorithm</h4>
<p>Performed at every router (based on link state database)</p>
<p>Router computes one or several shortest paths to every destination
from self.</p>
<p>Paths are computed independently at every node because it computes
shortest paths starting from itself, and synchronization of databases
guarantees no persistent loops.</p>
<p>Dijkstra’s algorithm builds a tree of shortest paths from this node
to all nodes. It adds one node at a time to the working set, by picking
the node that is closest.</p>
<p>If possible, there are multiple paths kept to the destination for
redundancy</p>
<p>After performing Dijkstra, router keeps <strong>routing
table</strong> which stores the next-hop and the distance to every
destination. This is built from the predecessor set of the first
hop.</p>
<p>To optimize the computation:</p>
<ul>
<li>stub networks are removed before applying Dijkstra</li>
<li>then, Dijkstra is run and the routing table contains costs and next
hop to routers</li>
<li>then, stub networks are added to the routing table one by one, using
the information on how to reach the routers that lead to the stub
networks.</li>
</ul>
<h4 id="equal-cost-multipath">Equal cost multipath</h4>
<p>How should you forward paths? Use all the paths with equal
probability because then there is load balancing. But because it may
cause packer reordering, it’s better to have <strong>per-flow load
balancing</strong> which would be implemented with a hash function
applied on the flow identifier (source and destination IP and port
tuple)</p>
<h4 id="changes-to-topology">Changes to topology</h4>
<p>Links fail or routers reboot - changes to topology</p>
<p>the routers detect failures through:</p>
<ul>
<li>OSPF hello protocol</li>
<li>Bidirectional Forwarding Detection (BFD) protocol - hello protocol
at the Ethernet level (directly - because there might be no power on the
cable)</li>
</ul>
<p>If a router detects a change in the sate of a link or a neighboring
router:</p>
<ol type="1">
<li>it floods a new LSA - neighbors propagate the change to the entire
OSPF area</li>
<li>all routers update their link-state databse, recompute Dijkstra and
routing tables with the new LSA</li>
</ol>
<h4 id="security-of-ospf">Security of OSPF</h4>
<p>Attacks: send invalid routing information -&gt; disrupt network
operation send forged routing information -&gt; change network paths DoS
attack</p>
<p>OSPF security protects against invalid and forged inforamtion with
<strong>authentication</strong></p>
<p>OSPF Type 3 authentication: Secred shared keys - because it is under
the same domain. Message is appended with MAC (message authentication
code) - Crypto sequence number (in cleartext so that neighbor could also
compute the hash and used to avoid replay attacks), and a digest.</p>
<h3 id="ospf-with-multiple-areas">OSPF with multiple areas</h3>
<p>LSA flooding does not scale in very large networks</p>
<p>OSPF uses multiple areas and hierarchy of two routing levels: a
backbone area (area 0) or several non-backbone areas</p>
<p>All inter-area traffic goes through backbone area 0</p>
<h4 id="principles-of-ospf-multi-area-operation">Principles of OSPF
multi-area operation</h4>
<ol type="1">
<li>inside one area, link state is used. One Link Stae Database per
area</li>
<li>Area <strong>border routers</strong> belong to both areas and have 2
link state databases (for local area and for area 0)</li>
<li>A border router injects <strong>aggregated distance
information</strong> (using summary LSA) learnt from one area into other
area</li>
</ol>
<p>All routers in area 0 compute their distances to networks outside the
area using Bellman-Ford formula: <span class="math display">d(self, n1)
= \min\limits_{\text{BR} \in \text{Area0}} \{d(self, \text{BR}) +
d(\text{BR}, n1)\}</span></p>
<h3 id="other-uses-of-link-state-routing">Other uses of Link State
Routing</h3>
<p>Links tate routing (OSPF or IS-IS) provides a complete view of area
to every node. This can provide advanced functions:</p>
<ul>
<li>multi-class routing - compute different routes for different types
of services</li>
<li>explicit routes (with source routing) - an edge router computes the
entire path, and writes it in the packet header. This avoids transiend
loops/supports fast re-route after failre. Used in deterministic
networks</li>
</ul>
<h4 id="use---bridge-vlans-across-a-campus">Use - bridge VLANs across a
campus</h4>
<p>Routers can hear on the MAC layer and forward the MAC frames from one
to the other.</p>
<p>This can be implemented by routers overhearing what VLAN is active
(tunnels - MAC in IP) on any oftheir ports and put this information in
the link state database. (Cisco TRILL protocol)</p>
<p>This does not require to connect all of these routers to be connected
by switches. Trunk architecture requires a cable to connect all of
them.</p>
<h3 id="software-defined-networks">Software defined networks</h3>
<p>To get more control than just matching destination address with the
longest prefix match, e.g.: handle mission critical traffic high
priority, ban non-HTTP traffic, send suspicious/DoS traffic to a machine
that does deep packet inspection</p>
<h4 id="how-sdn-works">How SDN works</h4>
<ul>
<li><strong>Deep packet inspection (DPI)</strong> - look not only at IP
headers, but also payload</li>
<li><strong>Per-flow forwarding</strong> - when a packet is to be
forwarded, the router:
<ul>
<li>looks for a rule match in the list of ordered per-flow forarding
rules (also called <em>flow table</em>)</li>
<li>if one or several matches exist, follow the rule with the highest
priority</li>
<li>if no rule matches, go to the IP table to match on longest
prefix</li>
</ul></li>
</ul>
<p>(same can be done in switches)</p>
<h2 id="congestion-control-in-networks">Congestion Control in
Networks</h2>
<h3 id="congestion-collapse">Congestion Collapse</h3>
<pre class="mermaid"><code>graph TD;
S1 --&gt; |C1 = 100Kb/s| R1
S2 --&gt; |C2 = 1000Kb/s| R1
R1 --&gt; |C3 = 110Kb/s| R2
R2 --&gt; |C4 = 100Kb/s| D1
R2 --&gt; |C5 = 10Kb/s| D2</code></pre>
<p>Network may lose some packets and assume greedy sources (send as much
as they want) assume loss is proportional to submitted traffic and links
can be fully utilized</p>
<p>So in this case <strong>S1–D1</strong> rate is 10Kb/s</p>
<p>This is because:</p>
<ul>
<li>Ratio of traffic that survives at R1–R2 is <span
class="math inline">\frac{110}{1000+100} = 10\%</span></li>
<li>Ratio of traffic that survives at R2–D2 is 100%</li>
<li>Ratio of traffic that survives at R2–D3 is <span
class="math inline">\frac{10}{100} = 10\%</span></li>
</ul>
<p>Therefore <strong>Greedy sources may be inefficient</strong></p>
<p>Better allocation is: S1 sending 100Kb/s and S2 sending 10Kb/s
<strong>Problem</strong> - S2 sent too much and did not know about
it</p>
<h4 id="how-much-can-node-i-send-to-its-destination">How much can node
<em>i</em> send to its destination?</h4>
<pre class="mermaid"><code>graph TB
    IN[source i] --&gt; |λ| A
    A((node i)) --- |link i -- λ`| B((node i+1))
    B --- |link i+1 -- λ``| C((C))
    C --&gt; |λ``| OUT[Dest]
    C --- D((D))
    D --- E((E))
    E --- F((F))
    F --- |link i-1| A</code></pre>
<p>Source <em>i</em> uses two links, all of same capacity c at every
node there is a source - all sources at same rate assume any loss is
proportional to submitted traffic and links can be fully utilized</p>
<p>IF <span class="math inline">\lambda &lt; \frac{c}{2}</span> there is
no loss (in this model) and <span class="math inline">\lambda&#39;&#39;
= \lambda</span></p>
<p>IF <span class="math inline">\lambda &gt; \frac{c}{2}</span> there is
some loss (in this model) Ratio that survives at one node is <span
class="math inline">\frac{c}{\lambda + \lambda&#39;}</span> (capacity /
submitted (incoming) traffic) Therefore: <span
class="math inline">\lambda&#39; = \frac{c}{\lambda +
\lambda&#39;}\lambda</span> <span class="math inline">\lambda&#39;&#39;
= \frac{c}{\lambda + \lambda&#39;}\lambda&#39;</span></p>
<p>By solving these, for <span class="math inline">\lambda &gt;
\frac{c}{2}</span> we obtain: <span
class="math display">\lambda&#39;&#39; = c - \frac{\lambda}{2}(-1 +
\sqrt{1+\frac{4c}{\lambda}})</span></p>
<p>For <strong>large</strong> orffered traffic <span
class="math inline">\lambda</span>, the limit of useful work is 0 =&gt;
<strong>congestion collapse</strong></p>
<blockquote>
<p><strong>Congestion collapse</strong> takes place as the offered load
increases, the total throughput decreases</p>
</blockquote>
<p>Sources should limit their rates to adapt it to the network
condition, otherwise inefficiency or congestion collapse may occur</p>
<h3 id="efficiency-vs-fairness">Efficiency vs fairness</h3>
<p>A network should be organize so as to aboid inefficiency However,
being maximally efficient may be a problem</p>
<pre class="mermaid"><code>graph TB
    A -- c=10Mb/s --- B -- c=10Mb/s--- C
    x0((x0 in)) --&gt; A
    C --&gt;|1 flow| x0out((x0 out))
    x1((x1 in)) --&gt; A
    B --&gt;|1 flow| x1out((x1 out))
    x2((x2 in)) --&gt; B
    C --&gt; |9 flows| x2out((x2 out))</code></pre>
<p>This graph’s maximum aggregate throughput is 20Mb/s</p>
<p>Calculation: Total throughput is <span class="math inline">\theta =
x_0 + x_1 + 9x_2</span> Maximize <span class="math inline">\theta = x_0
+ x_1 + 9x_2</span>, where <span class="math inline">x_0 + x_1 \le
10</span> and <span class="math inline">x_0 + 9x_2 \le 10</span>, and
<span class="math inline">x_0, x_1, x_2 \ge 10</span> <span
class="math inline">\theta = 20</span></p>
<p>The value of x0 when maximum throughput is 0, and x1 = 10, and x2 =
10/9</p>
<h4 id="pareto-efficiency">Pareto Efficiency</h4>
<p>A feasible allocation of rates <span
class="math inline">\overrightarrow{x}</span> is called
<strong>Pareto-efficient</strong> iff increasing the rate of a flow must
be at the expense of decreasing the rate of some other flow:</p>
<p>i.e. <span class="math inline">\overrightarrow{x}</span> is
Pareto-efficient iff: for any other feasible <span
class="math inline">\overrightarrow{x}&#39;, \exist i: x_i&#39;&gt;x_i
\rightarrow \exist j: x_j&#39; &lt; x_j</span></p>
<p>or in other words: every flow has a <strong>bottleneck</strong> link
(i.e. for every flow there exists a link, used by, which is saturated,
i.e. the constraint of which is satisfied with equality)</p>
<p>Allocation is called <strong>not Pareto-efficient</strong> iff it can
be improved unilaterally.</p>
<p>The example is Pareto-efficient because every flow has a bottleneck
and cannot be increased unilaterally (the throughput maximizing
allocation is always Pareto-efficient)</p>
<p>Maximal efficiency means Pareto efficiency. MAximizing total
throughput is Pareto effiient, but means shutting down flow; this is at
the expense of <strong>fairness</strong></p>
<h4 id="egalitarianism">Egalitarianism</h4>
<p>Egalitarianism is not Pareto-efficient It allocaties as much as
possible but same to all.</p>
<p>It is inefficient since we could give more to one flow without
hurting anyone.</p>
<p>E.g. (example above) x0 = 1, x1 = 9, x2 = 1 is Pareto-efficient
(Every resource has a bottlenect) and is “fair” since it gives to every
one at least as much as egalitarianism.</p>
<p>This is <strong>max-min fair</strong> allocation</p>
<h4 id="max-min-fairness">Max-Min fairness</h4>
<p>We say that a feasible allocation <span
class="math inline">\overrightarrow{x}</span> is <strong>max-min
fair</strong> iff for any other feasible allocation <span
class="math inline">\overrightarrow{x}&#39;, \exist i: x_i&#39;&gt;x_i
\rightarrow \exist j: x_j \le x_i</span></p>
<p>Intuition - for every flow <em>i</em>, increasing its rate must force
the rate of some other (not richer) flow <em>j</em> to decrease</p>
<h5 id="properties-of-max-min-fairness">Properties of max-min
fairness</h5>
<p>Given a set of constraints for the rates:</p>
<ul>
<li>if it exists, the max-min fair allocation is unique</li>
<li>there exists one max-min fair allocation, if the set of feasible
allocations is convex (this is the case for networks)</li>
<li>the max-min fair allocation is Pareto-efficient</li>
</ul>
<p>For a set of feasible rates as in our case (sum of the rates on every
link is upper bouded), the max-min fair allocation is obtained by
<strong>water-filling</strong>:</p>
<p><code>{r, eval = FALSE} mark all flows as non frozen do   increase the rate of all non frozen flows to the largest possible common value   mark flows that use a saturated link as frozen until all flows are frozen</code></p>
<p>Example:</p>
<ul>
<li>Step 1:
<ol type="1">
<li>maximize t such that x0 = x1 = x2 = t and all constraints are
satisfied; we find t = 1, hence x0 = x1 = x2 = 1</li>
<li>link 2 is saturated, is used by flows 0 and 2 =&gt; mark flows 0 and
2 as <strong>frozen</strong></li>
</ol></li>
<li>Step 2:
<ol type="1">
<li>maximize t such that x1 = t, with x0 = 1 and x2 = 1 and all
constraints are satisfied; we find t = 9, hence x1 = 9</li>
<li>link 1 is saturated, is used by sources 0 and 1 =&gt; mark flow 1 as
frozen. All flows are frozen, STOP</li>
</ol></li>
</ul>
<p>The max-min fair allocation is x0 = x2 = 1, x1 = 9</p>
<h4 id="proportional-fairness">Proportional Fairness</h4>
<p>A feasible allocation <span
class="math inline">\overrightarrow{x}</span> is <strong>proportionally
fair</strong> iff <span class="math inline">\overrightarrow{x} &gt;
0</span> and for any other <span
class="math inline">\overrightarrow{x}&#39;, \sum_i
\frac{x_i&#39;-x_i}{x_i} \le 0</span></p>
<p>Intuition: an allocation is proportionally fair if for any other
allocation, the total rate of change or relative change <span
class="math inline">\sum_i \frac{\delta x_i}{x_i} \le 0</span></p>
<p>An allocation is not proportionally fair iff there is some other
allocation where the relative change is &gt; 0</p>
<p>The effects of it: sum of all rates of changes Relative changes
matter, not absolute</p>
<h5 id="properties-of-proportional-fairness">Properties of Proportional
fairness</h5>
<ol type="1">
<li>A proportionally fair allocation is Pareto-efficient</li>
<li>Given a set of constraints for the rates that is convex - the
proportionally fair allocation exists and is unique</li>
<li>It is obtained by maximizing <span
class="math inline">J(overrightarrow{x}) = \sum_i \log x_i</span> over
all feasible allocations</li>
</ol>
<h4 id="utility-fairness">Utility fairness</h4>
<p>One can interpret proportional fairness as the allocation that
<strong>maximizes a global utility</strong> <span
class="math inline">\sum_i U_i(x_i) \text{with} U_i(x_i) = \log
x_i</span></p>
<p>If we take some other utility funciton we have <strong>utility
fairness</strong> It can be shown that max-min fairness is the limit of
unitility fairness when the utility function fonverges to a step
function (but max-min fairness cannot be expressed exactly as a utility
fairness)</p>
<h3 id="additive-increase-multiplicative-decrease-aimd">Additive
increase multiplicative decrease (AIMD)</h3>
<p>How congestion control can be implemented:</p>
<ul>
<li>Explicit (rate based) - tell every host how fast it can send (MPLS
networks and Cellular networks)</li>
<li>Hop by hop = backpressure - STOP/GO signals sent upstream (Gigabit
LAN switches)</li>
<li>Fair Queueing per Flow - one queue per flow/per user, served round
robin (Cellular networks, industrial networks, in-vehicle networks)</li>
<li>End-to-end - hosts “taste the water” and increase or decrease their
sending rate using a host congestion control algorithm (Internet)</li>
</ul>
<h4 id="simple-network-model---decnet">Simple network model -
Decnet</h4>
<p>One bit is used called <strong>congestion avoidance bit</strong>,
which is reset by source and set by routers if it is observed that the
flow is causing overload.</p>
<p>Network sends a one-bit feedback <span class="math inline">y(t) = 0
\text{if} \sum_i x_i(t) \le c</span> and <span class="math inline">y(t)
= 1 \text{if} \sum_i x_i(t) &gt; c</span></p>
<p>Sources reduce rate <span class="math inline">x_i(t+1) \text{if} y(t)
= 1</span>, increase otherwise</p>
<p>What increase/decrease we should pick?</p>
<h5 id="linear-laws">Linear laws</h5>
<p>Consider linear laws: <span class="math inline">\text{if} y(t) = 1
\text{then} x_i(t+1) = u_1 \dot x_i(t) + v_i</span> <span
class="math inline">\text{if} y(t) = 0 \text{then} x_i(t+1) = u_0 \dot
x_i(t) + v_0</span></p>
<p>We want to decrease when y(t) = 1, so <span class="math inline">u_1
\le 1</span> (multiplicative decrease factor) and <span
class="math inline">v_1 \le 0</span> (additive decrease term) and at
least one inequality must be strict</p>
<p>We want to increase when y(t) = 0, so <span class="math inline">u_1
\ge 1</span> (multiplicative increase factor) and <span
class="math inline">v_1 \ge 0</span> (additive increase term) and at
least one inequality must be strict</p>
<p><strong>Analysis</strong>: We want to achieve efficiency and fairness
WE could target either max-min fair or proportionally fair allocations
(in the example with 1 link they are the same)</p>
<p>Impact of each of the four coefficients:</p>
<ol type="1">
<li><em>Additive decrease</em> worsens fairness (goes away from x1 = x2)
and should be avoided =&gt; decrease should be mutiplicative</li>
<li><em>Additive increase</em> is the only move that increases fairness
and should be therefore included =&gt; increase should be additive</li>
</ol>
<p><strong>Why AIMD</strong> Among linear controls, only additive
increase - multiplicative decrease tends to bring the allocation towards
fairness and efficienty</p>
<p>This was first implemented in the internet after the first congestion
collapses</p>
<h3 id="slow-start">Slow start</h3>
<p>AIMD convergence can be accelerated when the initial conditions are
very different Slow start is an additional method, added to AIMD Used at
the beginning of connection and at losses detected by a timeout</p>
<ol type="1">
<li><strong>Increase the rate multiplicatively</strong> until a target
rate is reached or negative feedback is received.</li>
<li>Apply multiplicative decrease to target rate if negative feedback is
received.</li>
<li>Exit slow start when the target rate is reached</li>
</ol>
<h2 id="congestion-control-implementation">Congestion control
implementation</h2>
<p>TCP is used to avoid congestion in the internet. At first it was
without cc. After congestion collapses, it was added there.</p>
<p>TCP sources adjust its window to the congestion status of the
Internet (AIMD, slow startm congestion avoidance), which avoids
congestion collapse and ensures some fairness. TCP sources interpret
<strong>losses</strong> as a <strong>negative feedback</strong>
(timeouts and dup acks are the losses)</p>
<p>UDP sources have to implement their own congestion control, e.g. some
UDP sources imitate TCP - “TCP friendly”, or some UDP sources
(e.g. QUIC) implement same code as TCP cc.</p>
<p>TCP versions: Reno - selective acks Cubic (widespread today in Linux
servers) Data center TCP BBR</p>
<h3 id="tcp-reno">TCP Reno</h3>
<p>uses AIMD and Slow start</p>
<p>TCP adjusts windw size based on the approximation rate <span
class="math inline">\frac{W}{RTT}</span></p>
<p>W = min (cwnd, offeredWindow) offeredWindow = window obtained by
TCP’s window field (advertizement) cwnd = controlled by TCP congestion
control</p>
<p>Negative feedback = loss positive feedback = ACK received</p>
<p>increase ~= additive (~=+1 MSS per RTT), multiplicative decrease (u =
0.5)</p>
<p>Slow start with increase factor w = 2 per RTT (approx)</p>
<p>loss detected by timeout -&gt; slow start Loss detected by fast
retransmit -&gt; fast recovery</p>
<h4 id="approximating-multiplicative-increase-slow-start">Approximating
multiplicative increase (slow start)</h4>
<p>for the initial slow start, the target window (for the target rate)
is ssthresh (default - 64KB)</p>
<p>for every non duplicate ack received during slow start -&gt; cwnd =
cwnd + MSS (in bytes)</p>
<p>if cwnd <span class="math inline">\ge</span> ssthresh, then go to
congestion avoidance</p>
<h4 id="approximating-aimd">Approximating AIMD</h4>
<p><strong>multiplicative decrease</strong> (after loss is detect -
negative feedback) ssthresh = 0.5 x cwnd cwnd = 1 MSS (when timeout) or
something else (e.g. fast retransmit)</p>
<p><strong>additive increase</strong> (“congestion avoidance” phase) for
every ack received - cwnd = cwnd + MSS x MSS / cwnd if we counted in
packets, this would be cwnd += 1/cwnd</p>
<p>this is slightly less than additive increase (because this is the
approximation using ack counting) other implementations exists - for
example, wait until the cwnd bytes are acked and then increment cwnd by
1 MSS</p>
<h4 id="aimd-and-slow-start-over-time">AIMD and slow start over
time</h4>
<p>target window of slow start is called ssthresh there is a slow start
phase initially and after every packet loss detected by timeout</p>
<p>ssthresh drops by half when loss is detected.</p>
<h4 id="fast-recovery">Fast recovery</h4>
<p>Slow start is used when we assume that the network condition is new
or abruptly changing (i.e. at beginning and after loss detected by
timeout)</p>
<p>In all other packet loss detection events, slow start is not used,
but fast recovery is used instead</p>
<p>Problem: the formula <span class="math inline">\text{rate} \approx
\frac{W}{RTT}</span> is not true when there is a single isolated packet
loss - sliding window operation may even stop sending if the first
packet of a batch is lost</p>
<p>With <strong>fast recovery</strong>: target window is halved:
ssthresh = 0.5 x cwnd (this prevents the source to send until the loss
is repaired) but cwnd is allowed to increase beyond the target windw
until the loss is repaired - it is increased by the value of allowable
dup acks</p>
<h5 id="fast-recovery-details">Fast recovery details</h5>
<p>when loss is detected by 3 dup ACKS: ssthresh = 0.5 x current-swnd
ssthresh = max (ssthresh, 2x MSS) cwnd = ssthresh + 3 x MSS (exponential
increase) cwnd = min (cwnd, 64K)</p>
<p>For each <strong>duplicate ACK</strong> received: cwnd = cwnd + MSS
(exp. increase) cwnd = min (cwnd, 64K)</p>
<p>If loss is repaired: cwnd = ssthresh goto: congestion avoidance</p>
<p>else (timeout): goto slow start</p>
<h4 id="fairness-of-tcp-reno">Fairness of TCP Reno</h4>
<p>For long lived flows, the rates obtained with TCP Reno are as if they
were distributed according to utility fairness.</p>
<p>For <strong>flows that have same RTT</strong>, the fairness of TCP is
between max-min fairness and proportional fairness, closer to
proportional fairness. I.e. reaches close to theoretical AIMD</p>
<p>Utility function is a decreasing funciton of RTT. This means that
<strong>flows that have higher RTT have a smaller utility</strong>.
Therefore in utility maximization, the flows with high RTT will
lose.</p>
<p>This is called RTT Bias of TCP Reno.</p>
<p>A flow that uses many hops obtains less rate because of two combined
factors:</p>
<ol type="1">
<li>if this flow goes toer many congested links, it uses more resources.
The mechanic of TCP Reno that is close to proportional fairness leads to
this source having less rate - which is desirable in view of the theory
of fairness.</li>
<li>If this flow has simply a larger RTT, then things are different. The
mechanics of additive increase leads to this source having less rate -
this is undesired bias in the design of TCP Reno.</li>
</ol>
<p>additive increase is one packet per RTT (instead of constand time
interval)</p>
<h4 id="tcp-reno-loss-throughput-formula">TCP Reno Loss-throughput
formula</h4>
<p>Assuming large TCP flow size. Assume we observe that, in average a
fraction q of packets is lost (or marked with ECN)</p>
<p>The throughput is close to <span class="math inline">\theta =
\frac{MSS 1.22}{RTT \sqrt{q}}</span></p>
<p>Formula assumes:</p>
<ul>
<li>transmission time is negligible compared to RTT</li>
<li>losses are rare and occur periodically</li>
<li>time spent in Slow Start and Fast Recovery is neglogigle</li>
</ul>
<h4 id="congestion-control-in-udp-applications">Congestion control in
UDP Applications</h4>
<p>UDP applications that can adapt their rate have to implement
congestion control</p>
<p>One method is to use the <strong>congestion control module</strong>
of TCP: e.g. QUIC, which is over UDP, uses Cubic’s cc (in original
version) or Reno’s cc (in standard version)</p>
<p>Another method method (e.g. for videoconferencing) is to control the
rate by computing the rate that TCP Reno would obtain. E.g. <strong>TFRC
(TCP-Friencly Rate Control)</strong> protocol:</p>
<ul>
<li>application adapts the sending rate (by modifying the coding rate
for audio and video)</li>
<li>feedback is received in form of count of lost packts, used by source
to estimate drop probability q</li>
<li>source sets rate to <span class="math inline">x = \frac{MSS
1.22}{RTT \sqrt{q}}</span> (TCP Reno loss throughput formula)</li>
</ul>
<h4 id="tcp-reno-shortcomings">TCP Reno shortcomings</h4>
<p><strong>RTT bias</strong> - not nice for users in remote places (New
Zealand)</p>
<p>Periodic losses must occur, not nice for application (e.g. video
streaming)</p>
<p>TCP controls the windown, not the rate. Large bursts typically occur
when packets are released by host following e.g. window increase - not
nice for queues in the internet, makes non smooth behaviour</p>
<p><strong>Self inflicted delay</strong> - if network buffers (in
routers and switches) are large, TCP first fills buffers before adapting
the rate. The RTT is increased unnecessarily. Buffers are constantly
full, which reduces their usefulness (<strong>bufferbload
syndrome</strong>) and increases delay for all users.
<strong>Interactive, short flows</strong> experience large latency when
buffers are large and full.</p>
<h3 id="tcp-cubic---improving-performance-in-long-fat-networks-lfns">TCP
Cubic - improving performance in Long Fat Networks (LFNs)</h3>
<p>LFN - long (large RTT value) and fat (huge transmission rates).
Mostly used in companies between data centers, e.g. in transatlantic
links.</p>
<p>In an LFN, additive increase can be too slow because it is 1 MSS per
round trip.</p>
<p>TCP Cubic modifies Congestion Control. To increase TCP rate faster on
LFNs.</p>
<p>TCP Cubic keeps the same slow start, congestion avoidance, fast
recovery phases as TCP Reno, but:</p>
<ul>
<li>During congestion avoidance the increase is not additive but
<strong>cubic</strong> (as independent of RTT)</li>
<li>Multiplicative decrease it x0.7 (decrease by 30%) (instead of
x0.5)</li>
</ul>
<p>Say the congestion avoidance in entered at time t0 = 0 and let <span
class="math inline">W_{max} = \text{value of cwnd, when loss is
detect}</span>. Let <span class="math inline">W(t) = W_{max} +
0.4(t-K)^3</span>, where K is such that <span class="math inline">W(0) =
0.7 W_{max}</span> Then the window increases like W(t) until a loss
occurs again.</p>
<p>Cubic increases window in concave way until reaches $ W_{max} $ then
increases in a convex way</p>
<p>Cubic’s window function is independent of RTT. It is faster when RTT
is large (long networks) but may be slower than Reno when RTT is small
(non-LFNs)</p>
<h4 id="cubic-window-increase">Cubic window increase</h4>
<p>Cubic is at least as fast as additive icrease with an additive
increase term <span class="math inline">r_{cubic}</span>: it was a
function for congestion window $ W<em>{CUBIC}(t) = {W(t),
W</em>{AIMD}(t)} $, where <span class="math inline">W_{AIMD}(t) = W(0) +
r_{cubic} \frac{t}{RTT}</span></p>
<p>So, when RTT or bandwidth-delay product is small, Cubic does the same
as a hypothetical Reno with additive increase <span
class="math inline">r_{cubic}</span> MSS per RTT (instead of 1) and
multiplicative decrease <span class="math inline">\beta_{cubic} =
0.7</span></p>
<p><strong>Cubic’s throughput <span class="math inline">\ge</span>
Reno’s throughput</strong> with equality when RTT or bandwidth-delay
produt is small</p>
<p>Cubic’s <strong>throughput formula</strong> is same as Reno for small
RTTs and small BW-delay products. A TCP Cubic connection gets more
throughput than TCP Reno when <strong>bit-rate and RTT are
large</strong></p>
<h3 id="ecn-and-aqm-active-queue-management">ECN and AQM (active queue
management)</h3>
<p>Using loss and congestion indication has major drawback -
<strong>self-inflicted delay</strong>: increased latencies and buffers
are not well utilized due to <strong>bufferbloat</strong></p>
<p>Initially all flows can increase their delivery rate until they hit
bottlenec link capacity. At that moment all flows send at maximum speed
but there is no queue. &lt;- this is the optimal operating point Since
no loss was detected, the flows are still increasing window size, and
then the queues form, which mean the RTT increases, queues overflow and
RTT reaches max. &lt;- this is the congestion control operating
point</p>
<h4 id="ecn">ECN</h4>
<p><strong>Excplicit Congestion Notification (ECN)</strong> aims at
avoiding these problems</p>
<p>It signals congestion without dropping packets</p>
<p>Router marks packet instead of dropping, then TCP destination echoes
the mark back to the source. At the source, TCP interprets a marked
packet aas if there would be a loss detected by fast retransmit.</p>
<h5 id="ecn-in-ip-and-tcp-headers">ECN in IP and TCP headers</h5>
<p>2 bits in IP header, so there are 4 possible indications:</p>
<ul>
<li>non ECN Capable (non ECT)</li>
<li>ECN capable ECT(0) and ECT(1)
<ul>
<li>historically used at random</li>
<li>today uesd to differentiate cc - TCP Cubic vs DCTCP</li>
</ul></li>
<li>ECN capable and congestion experienced (CE)</li>
<li><strong>if congested, router marks ECT(0) or ECT(1) packets,
discards non ECT packets</strong></li>
</ul>
<p>2 bits in TCP header:</p>
<ul>
<li>ECE is set by R to inform S of congestion</li>
<li>CWR (congestion window reduced) set by S to inform R that ECE was
received and R can stop sending ECE until receiver receives a TCP header
with CWR set</li>
<li>When receiving ECE, S reduces window only once per RTT. R sets ECE
in all TCP headers until CWR is received or until new CE packet
received.</li>
</ul>
<h4 id="red-random-early-detection">RED (Random Early Detection)</h4>
<p>It decides when to mark a packet with ECN, and more generally, avoids
buffer bloat syndrome</p>
<p>Queue estimates its average queue length (moving average) Incoming
packet is marked with probability given by RED curve - before threshold
min we don’t mark packets, between thershold min and max we mark packets
in relation to how much packets we have. At the full queue, all packets
are marked.</p>
<p>This is <strong>active queue management</strong> in contrast to “drop
a packet when queue is full = <strong>Tail drop</strong>”</p>
<h4 id="aqm">AQM</h4>
<p>AQM can also be applied even if ECN is not supported In such case,
e.g. with RED a packet is <strong>dropped</strong> with probability q
computer by the RED curve. – packet may be discarded even if there is
some space available</p>
<p>Expected benefit:</p>
<ul>
<li>avoid bufferbload - reduce latency</li>
<li>avoid irregular drop patterns</li>
</ul>
<h3 id="data-centers-and-tcp">Data centers and TCP</h3>
<p>Data centers:</p>
<ul>
<li>most traffic is TCP</li>
<li>very small latencies</li>
<li>lots of bandwidth</li>
<li>lots of traffic (internal traffic, external traffic, may short flows
with low latency requirements, some jumbo flows)</li>
</ul>
<p>We need ECN in these flows to avoid bufferbloat</p>
<h4 id="dctcp">DCTCP</h4>
<p>it improves jumbo flows when ECN is used</p>
<p>It avoids the brutal multiplicative decrease by t0% or 30%</p>
<p>TCP source estimates probabiltiy of congestion p from ECN echoes</p>
<ul>
<li>ECN echo is modified so that the proportion of CE marked acks ~= the
prob of congestion p</li>
<li>multiplicative decrease is <span class="math inline">\times
\beta_{DCTCP} = (1- \frac{p}{2})</span></li>
</ul>
<h3 id="tcp-bbr">TCP-BBR</h3>
<p>Main motivation: Bufferbloat syndrome and <strong>buffer drain
time</strong> = buffer capacity / link rate</p>
<p>We want to keep buffer drain time constant for fairness, even though
the technology increases - we have big buffers that are slow, or small
buffers that are fast.</p>
<p>When the buffer is big and slow -&gt; Bufferbloat unless ECN is
used</p>
<p>When the buffer is fast ( &lt;&lt; RTT) -&gt; impossible to react to
react correctly in RTT, and feedback control might not be accurate</p>
<p><strong>TCP-BBR</strong> avoids per packet feedback, target max
throughput with minimal delay</p>
<p>How:</p>
<ol type="1">
<li>estimates the bottlenecek and the min RTT separately</li>
<li>controls directly the rate (not the window) uusing pacing (= packet
spacing)</li>
<li>tries to keep amount of inflight data close to bottlenect bandwidth
x minRTT (optimal operating point)</li>
</ol>
<ul>
<li>It views the network as a single link (bottleneck link)</li>
<li>estimates min RTT by taking the min over the last 10s = RTprop</li>
<li>estimates bottleneck rate (bandwidth) - max of delivery rate over
last 10 RTTs, where delivery rate = amount of ACKed data per time
period</li>
<li>sends data at rate max of delivery x pacing gain. First send at 1.25
during one RTprop (to probe the bandwidth), then 0.75 during one RTprop
(to drain the queue), then 1 during 6 RTprops</li>
<li>If no new RTprop value in last 10s, the source enters ProbeRTT state
- send only 4 packets to drain any possible queue and get a real
estimateion of RTprop</li>
<li>for safety, max data in flight is limited to 2 x max delivery rate x
RTT estimateion (2 x bandwidth delay product) and by offered window</li>
<li>there is also a startup phase (like Cubic/Reno) with exponential
increase of rate</li>
<li><strong>no reaction</strong> to losses or ECN</li>
</ul>
<p>There is a reported improvement of throughput when using BBRv1</p>
<p>BBRv1 can be unfair:</p>
<ul>
<li>when there are different BBR flows of different RTTs and when BBR vs
other TCPs</li>
<li>in-flight cap is determinant, which means it it was not 2, it would
behave differently</li>
</ul>
<h3 id="per-class-queuing">Per-class queuing</h3>
<p>Router classify packets (using access list): each class is guaranteed
a queue and a height (specific rate); classes may exceed the guaranteed
rate by “borrowing” from other classes if there is spare capacity</p>
<p>this is implemented in routers with dedicated queues for every class
and scheduler such as Weighted Round Robin or Dficit Round Robin</p>
<p>It is used in enterprise or industrial networks to support non
congestion flows (e.g. real-time flows - sensors); provider networks to
sepatrte customers / isolate suspicious flows (network
virtualization)</p>
<h3 id="future-of-cc">Future of cc</h3>
<p>Past TCP version relied on loss or ECN. Some versions relied on delay
only (TCP Vegas) or use delay as well as loss (PCC).</p>
<p>CC today wants to also achieve “per-flow fairness”, but each flow may
use different cc algorithm:</p>
<ul>
<li>is fairness achieved? is every flow “TCP friendly”? (now BBR sends
more)</li>
<li>is the “flow” the right abstraction/fairness-actor? (should it be
user instead?)</li>
<li>what are the alternatives?</li>
</ul>
<p><strong>Traffic isolation</strong> (with per-class traffic shapers or
per-class queuing) is a possible future alternative. packet dropping/ECN
marking becomes a function of the traffic aggretate/class a packet
belongs to. In this, however, <strong>network neutrality</strong> (=
ISPs provide no competitive advantage to specific apps/services, either
through pricing or QoS) should be maintained.</p>
<h2 id="bgp-border-gateway-protocol">BGP (Border Gateway Protocol)</h2>
<p><strong>Domain</strong> - network under the same administrative
entity</p>
<h3 id="inter-domain-routing">Inter-domain routing</h3>
<p>Why inventer? - the internet is too large (cannot run dijkstra and
stuff) and heterogeneous (many domains) to be run by one routing
protocol</p>
<h4 id="ard-and-as">ARD and AS</h4>
<p>ARD - Autonomous Routing Domain = routing domain under one single
administration</p>
<p>AS - Autonomous System - ARD with a number</p>
<p>AS number is 32 bits denoted with dotted 16 bit integer notation</p>
<p>ARDs that do not need a number are typically served by one single ISP
(E.g. EPFL, since all external traffic goes via Switch)</p>
<h4 id="bgp-and-igp">BGP and IGP</h4>
<p>ARDs can be transit, stub, or multihomed. Only non stub domains need
an AS number</p>
<p>An IGP is used inside a domain, BGP is used between domains</p>
<h4 id="what-does-bgp-do">what does BGP do?</h4>
<p>BGP is a routing protocol between ARDs. It is used to compute paths
from one router in one ARD to any network prefix anywhere in the
world</p>
<p>BGP can handle both IPv4 and IPv6 addresses in a single process</p>
<p>Used routing protocols: Path vector, With policy</p>
<h4 id="path-vector-routing">Path Vector Routing</h4>
<p>It finds the best AS-level routes, in a sense that can be decided by
every ARD using their own criteria</p>
<p>How: AS-level route is where path is a sequence of AS numbers and
dest is an IP prefic.</p>
<p>Every AS appends its number to the path it exports; Every AS uses its
own rules for deciding which path is better (different policies)</p>
<h4 id="border-gateways-e--and-i-bgp">Border Gateways, e- and i-BGP</h4>
<p>A router that runs BGP is a <strong>BGP speaker</strong> - at the
boudary between 2 ARDs, there are 2 BGP speakers for each domain (they
are on the same link, so same subnet). Inside ARD there are usually
several BGP speakers</p>
<p>BGP speakers speak (over TCP connections):</p>
<ul>
<li>externally (e-BGP) - to advertise routes to neighbor domains</li>
<li>internally (i-BGP) - to exchange what they have learnt</li>
</ul>
<p>In i-BGP, peers:</p>
<ul>
<li>communicate via a mesh network (<strong>BGP mesh</strong>) - every
BGP router has a connection to every BGP router</li>
<li>do the same as in e-BGP but they <strong>don’t</strong>:
<ul>
<li>repeat the routes learnt from i-BGP</li>
<li>prepend own AS number over i-BGP</li>
<li>modify the NEXT-HOP of a route</li>
</ul></li>
<li>know about all inter-domain link subnets via IGP</li>
</ul>
<h4 id="policy-routing">Policy Routing</h4>
<p>Interconnection of ASs (= peering) is self-organized:</p>
<ul>
<li>point to point links between networks</li>
<li>interconnection points - all participants un a BGP router in the
same LAN. NAP (Network Access Point), MAE (Metropolitan Area Ethernet),
CIX, GIX, IXP, …</li>
</ul>
<p>Mainly 2 types of relations:</p>
<ul>
<li>customer-provided (hierarchy) - EPFL is customer os Switch</li>
<li>Shared Cost peer (same level) - Swisscome and Switch are peers. They
collaborate to serve their customers, typically without paying each
other</li>
<li>many others</li>
</ul>
<p><strong>Goal</strong>: implement these relations and business
agreements</p>
<p>If ISPs apply a rule that traffic is not propagated to other peers
and provided, then traffic cannot be transmitted.</p>
<p>Solution: internet backbone providers (called tier-1) must connect
all peers with each other and all ISPs need to be connected to
tier-1</p>
<h3 id="how-it-works">How it works</h3>
<p>BGP routers talk to each other over TCP connections</p>
<p>BGP messages: OPEN, NOTIFICATION (=RESET), KEEPALIVE, UPDATE</p>
<p>UPDATE messages contains modifications: a BGP router transmits only
modifications <strong>additions and withdrawals</strong></p>
<h4 id="bgp-router">BGP router</h4>
<ul>
<li>it receives and stores candidate routes from its BGP peers and from
itself</li>
<li>it applies the decision process to select at most one route per
destination prefix</li>
<li>it exports the selected routes to BGP neighbors, after applying
export policy rules and possibly aggregation</li>
</ul>
<p>(only routes learnt from e-BGP are sent to an i-BGP neighbor)</p>
<h4 id="routes">Routes</h4>
<p>tje records sent/received in BGP messages are called
<strong>routes</strong></p>
<p>Route is made of:</p>
<ul>
<li>destination (subnetwork prefix)</li>
<li>path to dest (AS-PATH or BGPsec_Path)</li>
<li>NEXT-JOP (set by e-BGP, left unchanged by i-BGP)</li>
<li>origin - route learnt from IGP, BGP, static</li>
<li>other attributes</li>
</ul>
<p>Routing Information Bases (RIB) stores routes and their
attributes</p>
<h4 id="decision-process">Decision process</h4>
<p>Decision process that decides which route is selected. At most one
best route to exactly the same prefix is chosen</p>
<p>A route can be selected only if its next-hop is reachable</p>
<p>Routes’ attributes are compared against each other using sequence of
criteria until only one route remains. Common example:</p>
<ol start="0" type="1">
<li>Highest weight (Cisco proprietary)</li>
<li>Highest LOCAL-PREF</li>
<li>Shortest AS-PATH</li>
<li>Lowest MED, if taken seriously by this nework</li>
<li>E-BGP &gt; I-BGP (external knowledge has priority)</li>
<li>Shortest path to NEXT-HOP, according to IGP</li>
<li>Lowest BGP id (if everything is the same, pick randomly - pick
lowest ID)</li>
</ol>
<p>The result of the decision process is stored in Adj-RIB-out (one per
BGP peer) and the router sends updates when Adj-RIB-out changes</p>
<p>Example process:</p>
<ol type="1">
<li>R1 receives announcement from R3 in different AS</li>
<li>It writes the address to Adj-RIB0in, and runs decision process,
which picks that one since it’s the only route</li>
<li>R1 puts the route in Adj-RIB-out and advertises it to peers R22 and
R21</li>
</ol>
<p>In parallel:</p>
<ol type="1">
<li>R22 advertizes its link to the same AS as R3, route through R4 to
R1.</li>
<li>R1 does not advertize this route to its peers because it has learnt
it through i-BGP, and does not advertize to R3 because it would create
AS-path loop</li>
</ol>
<p>In the decision process, if OSPF is used, the shortest path takes
into account the route cost (that is why it says “according to IGP”)</p>
<p><strong>Hot potato routing</strong> - routers advertise all the
prefixes that they know. Everything is just thrown to the other
domain.</p>
<p><strong>Cold potato routing</strong> - routers advertise only the
prefixes that they are directly attached to. Route through my own domain
and then jump to the other domain.</p>
<p>If both ISPs do hot potato routing, the routing in the global
internet may be asymmetric.</p>
<p><strong>How are routes originated (sourced)?</strong></p>
<ul>
<li>Static configuration: tell this BGP router which are the prefixes to
originate (“network” command in FRR)</li>
<li>Redistribute connected: tell this BGP router to originate all
prefixes that are on-link with this router (all routers in network may
run i-BGP, no need for IGP)</li>
<li>Redistribute from IGP: tell this BGP router to originate all
prefixes that IGP has learnt
<ul>
<li>Example: redistribute OSPF into BGP.</li>
<li>In BGP, such routes have attribute ORIGIN=IGP.</li>
<li>When originated, the BGP NEXT-HOP of a route is its <em>IGP
next-hop</em></li>
</ul></li>
</ul>
<h4 id="aggregation-of-routes">Aggregation (of routes)</h4>
<p>Routes usually overlap - expected to be frequent with IPv6 (switch
delegates prefixes by splitting in half), less with IPv4</p>
<p>Aggregation can reduce the number of routes in IP forwarding tables
and in BGP announcements (otherwise there will be hundreds of thousands
of entries or announcements)</p>
<p>AS can aggregate routes on the longest prefix</p>
<p>Overlapping prefixes are considered different, therefore if there is
/47 and /48, both will be kept</p>
<h4 id="routes-learnt-by-bgp-in-forwarding-tables">Routes learnt by BGP
in Forwarding Tables</h4>
<h5 id="redistribution-of-bgp-into-igp">Redistribution of BGP into
IGP</h5>
<p>routes learnt by BGP are apssed to IGP (e.g. OSPF)</p>
<p>Typically only routes learnt by e-BGP are redistributed (unless BGP
redistribute-internal is used)</p>
<p>IGP propagates the routes to all routers in domain</p>
<p>Works with OSPF, might not work with other IGPs (because the table
could become too large for IGP)</p>
<h5 id="injection-most-widely-used">Injection (most widely used)</h5>
<p>Routes learnt from BGP are directly written/copied into forwarding
router of this BGP router</p>
<p>Routing information is not propagated to other intro-domain routers,
so injeciton only helps the specific BGP router</p>
<p>Why? - IGP avoids dealing with large number of routing entries
(convergence issues with in path-vector algorithms such as RIP because
path-vectors become huge and are not scalable)</p>
<p>Typically used in Cisco routers and FRR</p>
<p>Since it is injected in the IP forwarding table, so it just puts the
IP in the table without corresponding interface, and there is no
association to the IGP router. This is solved with <strong>recursive
table lookup</strong>.</p>
<p><strong>Recursive table lookup</strong>:</p>
<p>Why? - BGP router injects a route into its forwarding table which
means it copies the BGP NEXT-HOP into the forwarding table’s next-hop.
Therefore, forwarding table indicates that “next-hop” is not on-link
(same subnet)</p>
<p>How? - to resolve the non on-link next-hop into an on-link next-hop
neighbor, a second lookup is done into the forwarding table (this can be
done in advance, not real-time, by preprocessing the routing table).</p>
<p>The recursive lookup after using injection cannot be done in the
routers that don’t run BGP, because they do not have any mapping for the
outside IP addresses.</p>
<p>This means all routers should run BGP (at least i-BGP) if we use
injection.</p>
<p>Problem:</p>
<ul>
<li>everyone is connected to everyone (TCP mesh), so this would be very
big</li>
<li>IGP would still be needed to discover paths to next-hops, but
handles only internal networks</li>
</ul>
<h5 id="alternative---bgp-with-source-routing">Alternative - BGP with
Source routing</h5>
<p>Routing table at R2 contains next-hop flag “insert next-hop as source
routing header” - we instruct the traffic in the IP header with the path
it should follow</p>
<p>And R1 forwards packet using source routing info, needs only small
routing table</p>
<p>This is implemented in SCION</p>
<h5 id="alternative---bgp-with-mpls">Alternative - BGP with MPLS</h5>
<p>Associate MPLS labels to exit points (kind of layer 2.5 protocol)</p>
<p>MPLS labels are similar to VLAN tags and are used by MPLS-capable
routers to forward the packet without looking at the IP header</p>
<h5 id="injection-conflicts">Injection conflicts</h5>
<p>Many routers use both injection and redistribution to OSPF</p>
<p>These conflicts are resolved by the <strong>administrative
distance</strong>. It is set inside the router and basically determines
the priority of routing protocols.</p>
<h4 id="other-route-attributes">Other route attributes</h4>
<h5 id="local-pref">LOCAL-PREF</h5>
<p>used inside an AS to express preference. Assigned by BGP router when
<em>receiving</em> route over E-BGP</p>
<p>Propagated without change over I-BGP, and not used over E-BGP</p>
<h5 id="weight">Weight</h5>
<p>This is route attribute given by Cisco or similar router</p>
<p>it remains local to this router (never propagated to other
routers)</p>
<h5 id="multi-exit-disc-med">MULTI-EXIT-DISC (MED)</h5>
<p>One AS connected to anohter over several links</p>
<p>AS y advertises its prefixes with different MEDs (low = preferred).
If AS x accepts to use MEDs put by AS y: traffic goes on preferred
link</p>
<p>So this could be used in Hot potato routing, as to say “take this
traffic and route it that way”, but MED can be ignored.</p>
<h5 id="convergence-of-bgp">Convergence of BGP</h5>
<p>BGP converges, but there acan be configuration with no equilibrium
(oscillations) or with multiple equillibria. Example: three domains that
advertises to the other one and this creates a loop; or there is an
advertisement that arrives faster than the other advertisement, and is
propagated, because of the AS-loop avoidance back advertisement is not
sent and then a long path is composed.</p>
<p>Nowadays, this is solved by the customer/peer/provider hierarchy and
policies.</p>
</body>
</html>
