<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Systems for data management and data science</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="css/pandoc.css" />
  <style>
    html {
      font-size: 100%;
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
    }

    body {
      color: #444;
      font-family: Georgia, Palatino, "Palatino Linotype", Times,
        "Times New Roman", serif;
      font-size: 12px;
      line-height: 1.7;
      padding: 1em;
      margin: auto;
      max-width: 42em;
      background: #fefefe;
    }

    a {
      color: #0645ad;
      text-decoration: none;
    }

    a:visited {
      color: #0b0080;
    }

    a:hover {
      color: #06e;
    }

    a:active {
      color: #faa700;
    }

    a:focus {
      outline: thin dotted;
    }

    *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    p {
      margin: 1em 0;
    }

    img {
      max-width: 100%;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      color: #111;
      line-height: 125%;
      margin-top: 2em;
      font-weight: normal;
    }

    h4,
    h5,
    h6 {
      font-weight: bold;
    }

    h1 {
      font-size: 2.5em;
    }

    h2 {
      font-size: 2em;
    }

    h3 {
      font-size: 1.5em;
    }

    h4 {
      font-size: 1.2em;
    }

    h5 {
      font-size: 1em;
    }

    h6 {
      font-size: 0.9em;
    }

    blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #eee solid;
    }

    hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 1em 0;
      padding: 0;
    }

    pre,
    code,
    kbd,
    samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: "courier new", monospace;
      font-size: 0.98em;
    }

    pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
    }

    b,
    strong {
      font-weight: bold;
    }

    dfn {
      font-style: italic;
    }

    ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
    }

    mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
    }

    sub,
    sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
    }

    sup {
      top: -0.5em;
    }

    sub {
      bottom: -0.25em;
    }

    ul,
    ol {
      margin: 1em 0;
      padding: 0 0 0 2em;
    }

    li p:last-child {
      margin-bottom: 0;
    }

    ul ul,
    ol ol {
      margin: 0.3em 0;
    }

    dl {
      margin-bottom: 1em;
    }

    dt {
      font-weight: bold;
      margin-bottom: 0.8em;
    }

    dd {
      margin: 0 0 0.8em 2em;
    }

    dd:last-child {
      margin-bottom: 0;
    }

    img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
    }

    figure {
      display: block;
      text-align: center;
      margin: 1em 0;
    }

    figure img {
      border: none;
      margin: 0 auto;
    }

    figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 0.8em;
    }

    table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
    }

    table th {
      padding: 0.2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
    }

    table td {
      padding: 0.2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
    }

    .author {
      font-size: 1.2em;
      text-align: center;
    }

    @media only screen and (min-width: 480px) {
      body {
        font-size: 14px;
      }
    }
    @media only screen and (min-width: 768px) {
      body {
        font-size: 16px;
      }
    }
    @media print {
      * {
        background: transparent !important;
        color: black !important;
        filter: none !important;
        -ms-filter: none !important;
      }

      body {
        font-size: 12pt;
        max-width: 100%;
      }

      a,
      a:visited {
        text-decoration: underline;
      }

      hr {
        height: 1px;
        border: 0;
        border-bottom: 1px solid black;
      }

      a[href]:after {
        content: " (" attr(href) ")";
      }

      abbr[title]:after {
        content: " (" attr(title) ")";
      }

      .ir a:after,
      a[href^="javascript:"]:after,
      a[href^="#"]:after {
        content: "";
      }

      pre,
      blockquote {
        border: 1px solid #999;
        padding-right: 1em;
        page-break-inside: avoid;
      }

      tr,
      img {
        page-break-inside: avoid;
      }

      img {
        max-width: 100% !important;
      }

      @page :left {
        margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
        margin: 15mm 10mm 15mm 20mm;
      }

      p,
      h2,
      h3 {
        orphans: 3;
        widows: 3;
      }

      h2,
      h3 {
        page-break-after: avoid;
      }
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/darkreader@4.7.15/darkreader.min.js"></script>
  <script>
    DarkReader.enable({
      brightness: 100,
      contrast: 90,
      sepia: 10,
    });
  </script>
  <link
    rel="icon"
    type="image/png"
    href="https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTJg97A-Sa8mxjkRCmjR51WjHATLvq2aF89Z1CprR2WcQ60qYZC"
  />
  <meta name="theme-color" content="#252525" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Systems for data management and data science</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#storage" id="toc-storage">Storage</a>
<ul>
<li><a href="#storage-hierarchy" id="toc-storage-hierarchy">Storage
hierarchy</a></li>
<li><a href="#file-storage" id="toc-file-storage">File storage</a></li>
<li><a href="#page-layout-for-relational-data"
id="toc-page-layout-for-relational-data">Page layout (for relational
data)</a></li>
<li><a href="#partition-attributes-across-pax"
id="toc-partition-attributes-across-pax">Partition Attributes Across
(PAX)</a></li>
</ul></li>
<li><a href="#query-execution-and-optimization"
id="toc-query-execution-and-optimization">Query execution and
optimization</a>
<ul>
<li><a href="#query-execution" id="toc-query-execution">Query
execution</a></li>
<li><a href="#query-optimization" id="toc-query-optimization">Query
optimization</a></li>
</ul></li>
<li><a href="#execution-models-for-distributed-computing"
id="toc-execution-models-for-distributed-computing">Execution models for
distributed computing</a>
<ul>
<li><a href="#big-data" id="toc-big-data">Big data</a></li>
<li><a href="#query-models" id="toc-query-models">Query models</a></li>
<li><a href="#mapreduce" id="toc-mapreduce">MapReduce</a></li>
<li><a href="#spark" id="toc-spark">Spark</a></li>
</ul></li>
<li><a href="#concurrency-control"
id="toc-concurrency-control">Concurrency control</a>
<ul>
<li><a href="#acid-transaction-schedules"
id="toc-acid-transaction-schedules">ACID &amp; Transaction
Schedules</a></li>
<li><a href="#pessimistic-concurrency-control-protocols"
id="toc-pessimistic-concurrency-control-protocols">Pessimistic
concurrency control protocols</a></li>
<li><a href="#optimistic-concurrency-control-protocols"
id="toc-optimistic-concurrency-control-protocols">Optimistic concurrency
control protocols</a></li>
<li><a href="#timestamp-based-cc"
id="toc-timestamp-based-cc">Timestamp-based CC</a></li>
<li><a href="#multiversion-cc" id="toc-multiversion-cc">Multiversion
CC</a></li>
<li><a href="#bottlenecks" id="toc-bottlenecks">Bottlenecks</a></li>
</ul></li>
</ul>
</nav>
<!-- markdownlint-disable MD010 MD041 MD001 MD036 MD029 MD034-->
<h2 id="storage">Storage</h2>
<h3 id="storage-hierarchy">Storage hierarchy</h3>
<p>Hierarchy (smaller and faster to bigger and slower): CPU registers
&lt; CPU Caches &lt; DRAM &lt; SSD &lt; HDD &lt; Network storage</p>
<p>Out-of-orderness is hard in processors because of the data
dependencies.</p>
<p>Hierarchy is a thing because of the locality - processors want to
reuse the program’s locality in the CPU registers, caches.</p>
<h4 id="non-volatile-memory-vs-solid-state-drive">Non-Volatile Memory vs
Solid-State Drive</h4>
<p>NVM:</p>
<p>Goals - data persists after power-cycle and to reduce
random/sequential access gap and no seek/ rotational delays</p>
<p>like DRAM, low latency loads and stores</p>
<p>like SSD, persistent writes and high density</p>
<p>byte-addressible</p>
<p>SSD:</p>
<p>it uses non-volatile flash chips and SSD controller (embedded
processor, which bridges flash chips to SSD IO interfaces)</p>
<p>block-addressible</p>
<h3 id="file-storage">File storage</h3>
<p>Files are made of pages (the communication DRAM to/from SSD), and in
pages there are fields that are individual informations.</p>
<p>The goal is to get the page such that it would favor locality (would
have more useful material in it).</p>
<h4 id="different-file-organizations">Different file organizations</h4>
<p>Heap files: best when typical access is a full file scan. Hard to
find a file. Simplest implementation is doubly-linked list.</p>
<p>Sorted files: Best for retrieval in an order, or for retrieving a
range. You have to choose a way to sort by.</p>
<p>Log-structured files: it works with an idea of immutability - fast to
insert/delete/update, but for reading file needs to be reconstructed
from logs.</p>
<h3 id="page-layout-for-relational-data">Page layout (for relational
data)</h3>
<h4 id="n-ary-storage-model-nsm">N-ary Storage Model (NSM)</h4>
<p>Taking every row and writing it out in the page. You assume that the
data will be needed in a row manner.</p>
<p>It has a page header, record headers (useful for variable size
records).</p>
<p>When the records are fixed-length, then it is easy to find n-th
record.</p>
<p>When the records are variable-length - it used to be separated by
special chars, but now it uses record headers with pointers.</p>
<p>And now variable-length records use slot array, which also points to
free space, such that the page can be reorganized to use more space
efficiently.</p>
<h4 id="decomposition-storage-model-dsm">Decomposition Storage Model
(DSM)</h4>
<p>Taking columns and put them in the pages.</p>
<p>Initial idea was to decompose all columns and store value of the
column + row ID (for reconstruction)</p>
<p>Pros: saves IO by bringing only relevant attributes (but there are a
lot of infrastucture for that) and very memory compressing columns is
typically easier.</p>
<p>Cons: Writes are more expensive, and need tuple reconstruction.</p>
<p>It is good for compression. Could be Run-length encoding (count the
value and store the count + value), Bit-vector encoding (translate value
into a bit in the bitstring), Partitioning - Dictionary (value -&gt;
number), Frequency partitioning (value -&gt; number only in the page,
where dictionaries are smaller).</p>
<h3 id="partition-attributes-across-pax">Partition Attributes Across
(PAX)</h3>
<p>Decompose a slotted-page internally in mini pages per attribute.</p>
<p>It is cache-friendly, compatible with slotted-pages, retains NSM IO
pattern, and brings only relevant attributes to the cache.</p>
<h2 id="query-execution-and-optimization">Query execution and
optimization</h2>
<h3 id="query-execution">Query execution</h3>
<p>The <strong>processing model</strong> of a DBMS defines how the
system executes a query plan</p>
<h4 id="extreme-1-iterator-model">Extreme 1: iterator model</h4>
<p>Each query operator implements its <strong>next</strong>
function.</p>
<p>On each invocation, the operator returns a single tuple, or empty.
Next recursively calls other operators’ next functions. This way it
passes the tuple through the pipeline and adds it to the query
return.</p>
<p>The DBMS traverses the tree. For each node that it visits, it has to
figure out what the operator needs to do. Same for expressions. This is
done for <strong>every single tuple</strong></p>
<p>Result:</p>
<ul>
<li>Many function calls - save/restore contents of CPU registers, and
force a new instruction stream into the pipeline (which is bad for
instruction cache)</li>
<li>Generic code - has to cover every table, datatype and query</li>
</ul>
<p>It’s like getting one beer at the time and storing it.</p>
<h4 id="extreme-2-block-oriented-model">Extreme 2: block-oriented
model</h4>
<p>Each operator processes its input all at once and emits its output
all at once The operator “materializes” its output as a single result.
Often bottom-up plan processing.</p>
<p>Naive solution for output materialization problem: process a filters
separately for columns and then join them.</p>
<p>Another version: add the filter as extra to the produced filter
result instead of joining them.</p>
<p>It can also use selection vector, which is a bitmap which then is
joined on</p>
<p><strong>Tuple materialization problem</strong> - when joining tables,
the columns can get shuffled, and it cannot use virtual ids and stiching
becomes random access.</p>
<p>Solutions for this:</p>
<ul>
<li>Stich columns before join</li>
<li>Sort lists of table ids before projection</li>
<li>Use order-preserving joins (jive-joins), but this is not always
applicable</li>
</ul>
<p>Pros of block oriented:</p>
<ul>
<li>no next() calls - no per-tuple overhead</li>
<li>typically combined with columnar storage</li>
<li>avoid interpretation when evaluating expressions (most of the
time)</li>
</ul>
<p>Con: ouput materialization is costly in terms of memory bandwidth</p>
<p>It’s like getting beers in full amount, e.g. 100 beers - heavy to
carry</p>
<h4 id="middle-ground-vectorized-iterator-model">Middle ground:
vectorized iterator model</h4>
<p>It’s like getting beers in crates - best of both worlds.</p>
<p>Operator emits vector of tuples instead of a single tuple. The size
of vector must fit in the CPU cache.</p>
<p>It is ideal for OLAP queries - Greatly reduces the number of
invocations per operator. Allows for operators to use vectorized (SIMD)
instructions to process batches of tuples</p>
<h3 id="query-optimization">Query optimization</h3>
<p>For a given query, find the execution plan with the lowest
“cost”.</p>
<p>It is the hardest DBMS component to design/implement correctly. No
optimizer truly produces the “optimal” plan, since it is expensive to
consider all plans (NP-complete), and impossible to get accurate cost of
a plan without executing it!</p>
<p>Optimizers make a huge difference in terms of: Performance,
Scalability, Resource utilization, Database capabilities</p>
<h4 id="multi-dimensional-decision-space">Multi-dimensional decision
space</h4>
<p>In what order to execute operations? (Particularly: relative order of
joins)</p>
<p>Which implementation is best for each operation? (E.g., hash joins,
nested loop joins, sort-merge joins…)</p>
<p>Which access methods to use? (E.g., scan, use of an index)</p>
<p>Suboptimal decisions can have a huge impact! e.g. use of one join
algorithm vs the other, or pushing down selections (that make indexes
useless)</p>
<h4 id="io-of-query-optimizer">IO of query optimizer</h4>
<p>Input - abstract syntax tree created from the query</p>
<p>Output - full physical plan translatable to code.</p>
<h4 id="classic-architecture">Classic architecture</h4>
<p>Cost estimation is used in logical-physical plan loop</p>
<pre class="mermaid"><code>graph TD;
User --SQL query--&gt; parser
parser --AST--&gt; A((Logical plan))
A((Logical plan)) --&gt; B((Physical plan))
B((Physical plan)) --&gt; A((Logical plan))
B((Physical plan)) --&gt; Result</code></pre>
<h4 id="relational-algebra-equivalences">Relational algebra
equivalences</h4>
<p>Key concept in optimization: <strong>Equivalences</strong>. Two
relational algebra <strong>expressions</strong> are said to be
equivalent if on every legal database instance, the two expressions
generate the same set of tuples.</p>
<p>Selections (WHERE clause in SQL) are cascading (s1 and s2 and … of R
=== s1(s2(…(R)))) and commutative (s1(s2(R))===s2(s1(R)))</p>
<p>Projections (SELECT clause in SQL) are cascading on the attributes:
<span class="math inline">\pi_{a_1}(R) \equiv
\pi_{a_1}(...(\pi_{a_n}(R)))</span>, where <span
class="math inline">a_1</span> is a subset of up to <span
class="math inline">a_n</span> projection.</p>
<p>These equivalences allow the push down of selections and projections
before the joins</p>
<p>Joins are commutative and associative. This allows us to choose
different join order.</p>
<h4 id="io-cost-example---naive-example">IO cost example - naive
example</h4>
<p>S: 16000 tuples = 320 pages. T: 256000 tuples = 5120 pages. C: 1600
tuples = 32 pages. Each student takes 16 courses. Each course has 160
students.</p>
<p>Super-Worst scenario / tuple-by-tuple it takes &gt; 500 years:
Cartesian product of fetching a page for each tuple (1 seek per tuple):
#tuples(C) * #tuples(S) * #tuples(T) = 1’600 * 16’000 * 256’000 =
6’553’600’000’000 I/Os. At 2.5ms per I/O -&gt; query takes 519.5
years</p>
<p>Not-Worst-But-Very-Bad scenario (page-by-page) it takes 36 hours:
Cartesian product reading pages at a time, not tuples (1 seek per page)
#pages(C) * #pages(S) * #pages(T) = 32 * 320 * 5120 = 52428800 I/Os
52428800 * 2.5ms = 131072 s -&gt; query takes 36 hours</p>
<h4 id="io-cost-example---educated-approach">IO cost example - educated
approach</h4>
<p>S: 16000 tuples = 320 pages. T: 256000 tuples = 5120 pages. C: 1600
tuples = 32 pages.</p>
<p>Use Block-nested loop joins instead of cross product and push down
projection - 18s</p>
<p>Push down selection and reorder joins - 1s</p>
<h4 id="simple-queries-straightforward-plan">Simple queries,
straightforward plan</h4>
<p>Query planning for OLTP queries is easy because they are
<strong>sargable</strong> (search argument able)</p>
<p>This means just picking the best index, joins are almost always on
foreign key relationships with a small cardinality and can be
implemented with simple heuristics</p>
<h4 id="heuristic-based-optimization">Heuristic-based optimization</h4>
<p>Static rules that transform logical operators into physical plan</p>
<ul>
<li>Perform most restrictive selections early</li>
<li>Perform all selections before joins</li>
<li>Predicate/Limit/Projection pushdowns</li>
<li>Join ordering based on cardinality</li>
</ul>
<p>Example INGRES and Oracle</p>
<p>INGRES has simple relational tables where it’s FK to FK relation.
Therefore it is possible for optimizer to split the query into two,
e.g.:</p>
<p>Goal: Retrieve the names of artists that appear on Joy’s mixtape</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">SELECT</span> ARTIST.NAME</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">FROM</span> ARTIST, APPEARS, ALBUM</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">WHERE</span> ARTIST.<span class="kw">ID</span><span class="op">=</span>APPEARS.ARTIST_ID</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="kw">AND</span> APPEARS.ALBUM_ID<span class="op">=</span>ALBUM.<span class="kw">ID</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="kw">AND</span> ALBUM.NAME<span class="op">=</span><span class="ot">&quot;Joy&#39;s Slag Remix&quot;</span></span></code></pre></div>
<p>Step 1: Decompose into single-variable queries</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">-- Q1</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">SELECT</span> ALBUM.<span class="kw">ID</span> <span class="kw">AS</span> ALBUM_ID <span class="kw">INTO</span> TEMP1</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">FROM</span> ALBUM</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">WHERE</span> ALBUM.NAME<span class="op">=</span><span class="ot">&quot;Joy&#39;s Slag Remix&quot;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">-- Q3</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="kw">SELECT</span> APPEARS.ARTIST_ID <span class="kw">INTO</span> TEMP2</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">FROM</span> APPEARS, TEMP1</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">WHERE</span> APPEARS.ALBUM_ID<span class="op">=</span>TEMP1.ALBUM_ID</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">-- Q4</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="kw">SELECT</span> ARTIST.NAME</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">FROM</span> ARTIST, TEMP2</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">WHERE</span> ARTIST.ARTIST_ID<span class="op">=</span>TEMP2.ARTIST_ID</span></code></pre></div>
<p>Step 2: Substitute the values from Q1→Q3→Q4</p>
<p>Advantages:</p>
<ul>
<li>Easy to implement and debug.</li>
<li>Works reasonably well and is fast for simple queries &amp; small
tables.</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Doesn’t <em>truly</em> handle joins.</li>
<li>Join ordering based only on cardinalities.</li>
<li>Naïve, nearly impossible to generate good plans when operators have
complex interdependencies.</li>
<li>Could get stuck at local minima/maxima</li>
</ul>
<h4 id="heuristics-cost-based-optimization">Heuristics + cost-based
optimization</h4>
<p>Use static rules to perform initial optimization. Then use dynamic
programming to determine best join order for tables.</p>
<h5 id="cost-estimation">Cost estimation</h5>
<p>Generate an estimate of the cost of executing a plan for the current
state of the database.</p>
<ul>
<li>Resource utilization (CPU, I/O, network)</li>
<li>Size of intermediate results</li>
<li>Choices of algorithms, access methods</li>
<li>Interactions with other work in DBMS</li>
<li>Data properties (skew, order, placement)</li>
</ul>
<p><strong>Selection without index unsorted</strong>. Cost will change
if. Records are sorted based on the condition attribute. We can utilize
an index to filter out some records. We need to materialize the output
result.</p>
<p><strong>Page-oriented loop join</strong>: For each tuple in the outer
relation R, we scan the entire inner relation S (but use page-loading).
I/O Cost: #pages of R + #pages of R * #pages of S.</p>
<p>How to choose the outer relation to minimize the cost? - Choose order
of R, S, so that #pages of R &lt; #pages of S and Order benefits cost if
tables are of different size</p>
<h5 id="selectivity-estimates">Selectivity estimates</h5>
<p>Estimating intermediary results of query</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> R <span class="kw">WHERE</span> r.age<span class="op">=</span><span class="dv">18</span></span></code></pre></div>
<p>First necessary to estimate cost of operations (e.g. join)</p>
<p>Crude estimation: selectivity = 1/#keys(R.age), estimated #results =
#Records(R)/#keys(R.age). Range queries: length of the range/length of
the domain. Free if there is an index. It is good estimate when values
are uniformly distributed.</p>
<p>Histograms: equi-width and equi-depth. It is higher cost to build and
maintain but higher accuracy.</p>
<h5 id="join-cardinality-estimates">Join cardinality estimates</h5>
<p>Important to reorder joins so that records are filtered as fast as
possible.</p>
<p>Selectivity = 1/max(#keys(R.sid), #keys(S.sid))</p>
<p>Cardinality estimate = #records(R) * #records(S) / max(#keys(R.sid),
#keys(S.sid))</p>
<h4 id="system-r-optimizer">System R Optimizer</h4>
<p>High level idea:</p>
<ul>
<li>Iterate over the possible plans</li>
<li>Estimate the cost of each plan</li>
<li>Return the cheapest to the user</li>
</ul>
<p>Essentially is programs that write other programs.</p>
<h5 id="abstract-steps">Abstract Steps</h5>
<p><strong>Step 1</strong>: break the query up into blocks and generate
the logical opereators for each block - this reduces complexity of each
plan.</p>
<p>Block definition: no nested queries, exactly one SELECT and FROM and
at most one WHERE, GROUPBY, HAVING</p>
<p><strong>Step 2</strong>: for each individual block: for each logical
operator, consider a set of physical operators and offered access paths.
Then iteraticely construct a “left-deep” tree that minimizes the
estimated amount of work to execute the plan. Join order is important
because it gets rid of the most amount of data. Left-join mostly offers
the best performance benefit because the rightmost file can be parsed
and immediately shown. It also offers dynamical programming due to the
fact that BNL can incrementally join together.</p>
<p>Access path - data scan.</p>
<h5 id="system-r-optimizer-steps">System R Optimizer Steps</h5>
<p><strong>Step 1</strong>: Choose the best access path to each
table</p>
<p><strong>Step 2</strong>: Enumerate all possible join orderings for
the tables</p>
<p><strong>Step 3</strong>: Determine the join ordering with the lowest
cost.</p>
<p>At every step only keep the lowest cost or most interesting
order.</p>
<p>If this was Naive - try all possible orders, it would be N! (for N
joins)</p>
<p><strong>Principle of optimality</strong> - the optimal plan for k
joins is produces by extending the optimal plan(s) for k-1 joins. This,
with dynamic programming, ends up being <span class="math inline">O(N
\times 2^^{N-1})</span></p>
<p>This is a very aggressive optimizer, meaning it leaves out some paths
that could be more efficient down the road, but it’s designed to be
faster.</p>
<h4 id="revisited-principle-of-optimality">Revisited principle of
optimality</h4>
<p>Principle of optimality may lead to suboptimal plans - e.g. order is
not considered -&gt; additional cost at the end (avoided by sort merge
join)</p>
<p><strong>Relaxed principle of optimality</strong> - aimed at what the
output is expected to be, e.g. for the ordered output - a plan is
compared with all other plans that produce the same order</p>
<h4 id="revisited-selectivity-estimates">Revisited selectivity
estimates</h4>
<p>if there is no index and no histogram or complex predicates, we
cannot estimate #Keys(R.age).</p>
<p>When everything else fails, revert to magic #Keys(R.age)=10.</p>
<h2 id="execution-models-for-distributed-computing">Execution models for
distributed computing</h2>
<h3 id="big-data">Big data</h3>
<p>The three (plus two) Vs: Big data is high <em>volume</em>, high
<em>velocity</em>, and/or high <em>variety</em> information assets that
require new forms of processing to enable enhanced decision making.</p>
<ul>
<li><em>Volume</em>: The quantity of generated and stored data.</li>
<li><em>Velocity</em>: The speed at which the data is generated and
processed.</li>
<li><em>Variety</em>: The type and nature of the data.</li>
<li><em>Variability</em>: Inconsistency of the data set.</li>
<li><em>Veracity</em>: The quality of captured data.</li>
</ul>
<h3 id="query-models">Query models</h3>
<ul>
<li>Shared-nothing model - Each machine does not share any resources
with any other machine. To communicate to another machine only through
network.</li>
<li>Shared-everything model - Each machine shares everything with other,
therefore all cpus can talk with each other, and access any memory</li>
<li>Shared-memory model - There is a unified memory space for all,
coherency is very easy, but there are problems.</li>
</ul>
<h4 id="shared-nothing-model-message-passing-model">Shared-nothing model
(message-passing model)</h4>
<p>No shared data, therefore we need declustering (spreading data
between disks).</p>
<p>Ways to do it:</p>
<ul>
<li>Attribute-less partitioning (random, round-robin)</li>
<li>Single Attribute Schemes (Hash declustering, Range declustering) -
like sorting</li>
<li>Multiple Attributes schemes possible (MAGIC, BERD etc)</li>
</ul>
<h5 id="hash-declustering">Hash declustering</h5>
<p>Essentially creates a skewed distribution.</p>
<p>Selections with equality predicates referencing the partitioning
attribute are directed to a single node. Therefore less queries are
made</p>
<p>Equality predicates referencing a non-partitioning attribute and
range predicates are directed to all nodes.</p>
<h5 id="range-declustering">Range declustering</h5>
<p>Partition depending on the range.</p>
<p>The more you know about your data or, better, the more you know about
your queries, the better is the distribution.</p>
<p>Equality and range predicates referencing the partitioning attribute
are directed to a subset of nodes.</p>
<p>Predicates referencing a non-partitioning attribute are directed to
all nodes.</p>
<h5 id="declustering-tradeoffs">Declustering tradeoffs</h5>
<p>Range selection predicate using a clustered B+-tree 0.01% selectivity
(result is 10 records). (B+-tree is the tree, where the attributes are
never interfering). The range declustering method is way better than
hash/random/round-robin methods.</p>
<p>If the selectivity goes up to 1% selectivity (result is 1000
records), then ranges drops very quickly, below hash/random/round-robin
methods.</p>
<p>This is because at low selectivity range was distributing the data
all over, so the specific records were found, but then
hash/random/round-robin kept the same spread.</p>
<h4 id="distributed-join">Distributed Join</h4>
<p>partition inputs to buckets, eahc bucket fits in join processors’
aggregate memory</p>
<p>Partition and join each bucket pair across join processors</p>
<h4 id="distributed-aggregation">Distributed Aggregation</h4>
<p>Compute aggregate locally for each node</p>
<p>redistribute by hashing group attribute and aggregate partial
results</p>
<h3 id="mapreduce">MapReduce</h3>
<p>MapReduce approach - code using functional model, hide complexity
behind a library.</p>
<p>It is simple distributed computation on a complex data.</p>
<p>e.g. convert all text to upper case:</p>
<p>Simple mapping:</p>
<ol type="1">
<li>split data file into splits (can be stored in different nodes)</li>
<li>apply map operation to each split</li>
<li>collect all outputs together to get the result</li>
</ol>
<p>MapReduce:</p>
<ol type="1">
<li>split data file into splits (can be stored in different nodes)</li>
<li>apply map operation to each split</li>
<li>use reducers to collect the data in smaller maps</li>
<li>collect all outputs together to get the result</li>
</ol>
<p>MapReduce is simple and scales very well. Problem is the amount of
reads and writes (which is because map and reduces are agnostic to each
other), and the problem is reducer waiting for mapper to finish.</p>
<h3 id="spark">Spark</h3>
<p>Goals:</p>
<ul>
<li>Improve expressiveness and extensibility of model</li>
<li>Make coding easier: strive for high-level code</li>
<li>Enable additional optimizations</li>
<li>Improve performance by better utilizing the hardware</li>
</ul>
<p>It implements very interesting abstractions that help maintain
MapReduce and improves some issues of it.</p>
<h4 id="resilient-distributed-datasets-rdd">Resilient Distributed
Datasets (RDD)</h4>
<p>Collection of elements that is distributed across the network and
it’s single.</p>
<p>It is immutable.</p>
<p>Distributed, fault-tolerant collections of elements that can be
operated in parallel</p>
<p>There is a lineage maintained, because when it is changed the history
can be kept due to its immutability.</p>
<p>Lazily evaluated.</p>
<p>RDDs contain: details about the data, leneage (history) information
to enable recreating a lost split of an RDD (dependencies from other
RDDs and functions/transformations)</p>
<p>Essentially it is dataflow programming.</p>
<h4 id="limitations-of-vanilla-spark">Limitations of vanilla Spark</h4>
<p>RDDs are schema-less, which makes it inefficient (same as accessing
raw text files), and expensive (high space overhead)</p>
<p>Spark has an extension which translates RDDs to data frames.</p>
<h2 id="concurrency-control">Concurrency control</h2>
<h3 id="acid-transaction-schedules">ACID &amp; Transaction
Schedules</h3>
<p><strong>Transaction (txn, or Xact)</strong> - sequence of actions
executed on a shared database to perform some higher-level function.
Basic unit of change in the DBMS.</p>
<p><strong>ACID</strong>:</p>
<ul>
<li><strong>Atomicity</strong> - Either all actions in the txn happen or
none happen</li>
<li><strong>Consistency</strong> - if each txn is consstent and the DB
starts consistent, it ends up consistent</li>
<li><strong>Isolation</strong> - Execution of one txn is isolated from
that of other txns</li>
<li><strong>Durability</strong> - if a txn commits, its effects
persist</li>
</ul>
<p>Txn could either commit after completing all its actions or abort
after executing some of its actions</p>
<p>All transactions are atomic.</p>
<p>Durability relies on logs.</p>
<p>Each transaction must leave the database in a consistent state</p>
<p>Users submit transactions, and expect isolation – each txn executed
by itself. <strong>Concurrency</strong> is very important for the
performance. Net effect identical to executing all txns one after the
other in some serial order.</p>
<p>For concurrency, DBMS uses schedules - a list of actions (reading,
writing, aborting or committing) from a set of txns.</p>
<h4 id="scheduling-transactions">Scheduling transactions</h4>
<ul>
<li><strong>Serial schedule</strong> - schedule that does not interleave
the actions of different transactions.</li>
<li><strong>Equivalent schedules</strong> - for any db state, the effect
(on the set of objects in the db) of executing the first schedule is
identical to the effect of executing the second schedule</li>
<li><strong>Serializable schedule</strong> - a schedule that is
equivalent to some serial execution of the txns.</li>
</ul>
<p>Anomalies with interleaved execution:</p>
<ul>
<li>Dirty reads - WR conflicts - reading uncommitted data</li>
<li>RW conflicts - unrepeatable reads</li>
<li>WW conflicts - overwriting uncommitted data</li>
</ul>
<h4 id="aborting-a-transaction">Aborting a transaction</h4>
<p>If txn is aborted, all its actions need to be undone. And due to
<strong>cascading aborts</strong> the dependent txns need to be aborted
(e.g. if Tj reads an object last written by Ti, Tj must be aborted as
well)</p>
<h4 id="precedence-graph">Precedence graph</h4>
<p>One node per txn, edge from Ti to Tj if Tj reads/writes an object
last read/written by Ti.</p>
<p><strong>Theorem</strong> - a schedule is conflict serializable iff
its dependency graph is acyclic.</p>
<p><strong>Conflict serializable</strong> - if schedule is conflict
equivalent to some serial schedule. I.e. they involve the same actions
of the same txns, every pair of conflicting actions is ordered the same
way -&gt; basically if we can turn the one into the other by swapping
non-conflicting adjacent actions</p>
<h3 id="pessimistic-concurrency-control-protocols">Pessimistic
concurrency control protocols</h3>
<h4 id="lock-based-concurrency-control">Lock-based concurrency
control</h4>
<p>There are 2 ways to prevent incosistencies. Preventing - lock
everything, or detection + correction - let it happen and then fix
everything if anyting goes wrong.</p>
<p>Locking protocol guarantees that schedule will be conflict
serializatble (correct) if it completes. And the question is when to
hold the lock.</p>
<p>Locking granularity can be anything: tables, indexes, pages,
records.</p>
<h5 id="two-pahse-locking-2pl-protocol">Two-pahse locking (2PL)
Protocol</h5>
<p>Rule 1: Shared and exclusive locking (corresponds to read/write
locks)</p>
<p>Rule 2: a transaction (txn) cannot request additional locks once it
releases any locks.</p>
<p>2PL allows only schedules who precedence graph is acyclic, therefore
it’s serializable</p>
<p>Strict 2PL only allows locking (meaning no unlocking), and unlocks
only when transaction is committed.</p>
<p>Deadlock - T1 is waiting for a lock which is held by T2, T2 is
waiting for T3, and T3 is waiting for T1. To get out of this everything
needs to be killed. Deadlock detection is very expensive, but there is
deadlock prevention algorithm</p>
<h3 id="optimistic-concurrency-control-protocols">Optimistic concurrency
control protocols</h3>
<p>No locking because conflicts are rare.</p>
<h4 id="kung-robinson-model">Kung-Robinson Model</h4>
<p><strong>Idea</strong>: Every txn is ordered by the exact time it
arrived to the system. While txn exectes, it collects its write set and
read set. After which there is a validation phase. Validation phase
checks that all conflicting actions occurred in the same order. Either
it gets validated and writes are commited to the storage, or invalidated
and not written.</p>
<p>This relies on the timestamps of the txns.</p>
<p>There are 4 cases for a txn that arrives for it to check previous
txns, For all i and j such that Ti &lt; Tj, check that Ti completes
before Tj begins.:</p>
<ul>
<li>that Ti already finished</li>
<li>that Ti writes before Tj writes
<ul>
<li>does Tj read dirty data? -&gt; to check, the Tj read set does not
intersect with write set of Ti</li>
</ul></li>
<li>that Ti reads before Tj reads
<ul>
<li>does Ti overwrite Tj’s writes? -&gt; to check, the Tj write set does
not intersect with write set of Ti (Tj’s one should persist)</li>
</ul></li>
</ul>
<h4 id="comments-on-validation">Comments on validation</h4>
<p>Validation is a critical section, and nothing else goes on
concurrently. BUT if the validation/write phase is long, then it is
major drawback.</p>
<p>Optimization for read-only txns: shorter critical section because
there is no Write phase.</p>
<h3 id="timestamp-based-cc">Timestamp-based CC</h3>
<p><strong>Continuous validation</strong> - not a distinct phase</p>
<p>Read and write timestamps per object, which means the validation
happens after each action. If the validation fails, we abort the
transaction</p>
<p>There are 4 actions to choose after the comparison of txn timestamp
with read/write timestamps of the objects: continue, abort, commit, skip
write</p>
<blockquote>
<p>When the validation fails, the new txn is created with a new
timestamp. Then validation is running again with newly completed
txns.</p>
</blockquote>
<p><strong>Idea:</strong> txn timestamp TS begin time</p>
<p><strong>Object</strong>: read-timestamp (RTS) and a write-timestamp
(WTS)</p>
<p>When txt T wants to <strong>READ</strong> object O:</p>
<ul>
<li>TS(T) &lt; WTS(O): violates timestamp order of T w.r.t. writer of O.
<ul>
<li>Abort T and restart it with a new, higher TS.</li>
</ul></li>
<li>TS(T) &gt;= WTS(O):
<ul>
<li>Allow T to read O.</li>
<li>Reset RTS(O) to max(RTS(O), TS(T))</li>
</ul></li>
<li>Change to RTS(O) on reads must be written in some persistent fashion
🡪 overhead.</li>
</ul>
<p>When txt T wants to <strong>WRITE</strong> object O:</p>
<ul>
<li>TS(T) &lt; RTS(O): violates timestamp order of T w.r.t. reader of O
🡪 abort and restart T.</li>
<li>TS(T) &lt; WTS(O) 🡪 violates timestamp order of T w.r.t. writer of
O. 🡪 ???
<ul>
<li>Thomas Write Rule: Outdated write 🡪 Safely ignore the write – it’s
as if the write happened before and was overwritten</li>
<li>need not restart T!</li>
<li>Allows some serializable schedules (correct) that are not conflict
serializable.</li>
</ul></li>
<li>Else, allow T to write O (and update WTS(O)).</li>
</ul>
<h3 id="multiversion-cc">Multiversion CC</h3>
<p>Recognising the fact that most transactions read all the time.</p>
<p>Goal: txn never waits on read</p>
<p><strong>Idea</strong>: Maintain several versions of each database
object (multi-version), each with a read and a write timestamp.
Transaction Ti reads the most recent version whose write timestamp
precedes TS(Ti).</p>
<h4 id="writer-txn">Writer txn</h4>
<p>To read an object, follow reader protocol</p>
<p>To write an object:</p>
<ul>
<li>finds newest version V</li>
<li>RTS(V) &gt; TS(T) - reject write</li>
<li>RTS(V) &lt;= TS(T) - T makes a copy CV of V, with a pointer to V,
with WTS(CV) = TS(T), RTS(CV) = TS(T) (write is buffered/locked until T
commits, other txns cannot read version CV, such that every txn’s effect
need to persist for the txns that follow)</li>
</ul>
<h3 id="bottlenecks">Bottlenecks</h3>
<p>lock thrashing - 2PL, strict 2PL</p>
<p>timestamp allocation - all T/O algorithms + deadlock prevention</p>
<p>memory allocation - MVCC, OCC</p>
<h4 id="improving-performance">Improving performance</h4>
<p><strong>Snapshot isolation</strong> - take the whole database
snapshot, and if no conflicting writes were made, take the whole
snapshot.</p>
<p>Snapshot isolation (SI) is the most popular isolation guarantee in
real DBMS.</p>
<ul>
<li>all txn reads will see a consistent snapshot of the database</li>
<li>the txn successfully commits only if no updates it has made conflict
with any concurrent updates made since that snapshot.</li>
</ul>
<p>SI does not guarantee serializability!</p>
</body>
</html>
