<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Decentralized-Systems-Engineering</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <style>
    html {
      font-size: 100%;
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
    }

    body {
      color: #444;
      font-family: Georgia, Palatino, "Palatino Linotype", Times,
        "Times New Roman", serif;
      font-size: 12px;
      line-height: 1.7;
      padding: 1em;
      margin: auto;
      max-width: 42em;
      background: #fefefe;
    }

    a {
      color: #0645ad;
      text-decoration: none;
    }

    a:visited {
      color: #0b0080;
    }

    a:hover {
      color: #06e;
    }

    a:active {
      color: #faa700;
    }

    a:focus {
      outline: thin dotted;
    }

    *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }

    a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }

    p {
      margin: 1em 0;
    }

    img {
      max-width: 100%;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      color: #111;
      line-height: 125%;
      margin-top: 2em;
      font-weight: normal;
    }

    h4,
    h5,
    h6 {
      font-weight: bold;
    }

    h1 {
      font-size: 2.5em;
    }

    h2 {
      font-size: 2em;
    }

    h3 {
      font-size: 1.5em;
    }

    h4 {
      font-size: 1.2em;
    }

    h5 {
      font-size: 1em;
    }

    h6 {
      font-size: 0.9em;
    }

    blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #eee solid;
    }

    hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 1em 0;
      padding: 0;
    }

    pre,
    code,
    kbd,
    samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: "courier new", monospace;
      font-size: 0.98em;
    }

    pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
    }

    b,
    strong {
      font-weight: bold;
    }

    dfn {
      font-style: italic;
    }

    ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
    }

    mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
    }

    sub,
    sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
    }

    sup {
      top: -0.5em;
    }

    sub {
      bottom: -0.25em;
    }

    ul,
    ol {
      margin: 1em 0;
      padding: 0 0 0 2em;
    }

    li p:last-child {
      margin-bottom: 0;
    }

    ul ul,
    ol ol {
      margin: 0.3em 0;
    }

    dl {
      margin-bottom: 1em;
    }

    dt {
      font-weight: bold;
      margin-bottom: 0.8em;
    }

    dd {
      margin: 0 0 0.8em 2em;
    }

    dd:last-child {
      margin-bottom: 0;
    }

    img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
    }

    figure {
      display: block;
      text-align: center;
      margin: 1em 0;
    }

    figure img {
      border: none;
      margin: 0 auto;
    }

    figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 0.8em;
    }

    table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
    }

    table th {
      padding: 0.2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
    }

    table td {
      padding: 0.2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
    }

    .author {
      font-size: 1.2em;
      text-align: center;
    }

    @media only screen and (min-width: 480px) {
      body {
        font-size: 14px;
      }
    }
    @media only screen and (min-width: 768px) {
      body {
        font-size: 16px;
      }
    }
    @media print {
      * {
        background: transparent !important;
        color: black !important;
        filter: none !important;
        -ms-filter: none !important;
      }

      body {
        font-size: 12pt;
        max-width: 100%;
      }

      a,
      a:visited {
        text-decoration: underline;
      }

      hr {
        height: 1px;
        border: 0;
        border-bottom: 1px solid black;
      }

      a[href]:after {
        content: " (" attr(href) ")";
      }

      abbr[title]:after {
        content: " (" attr(title) ")";
      }

      .ir a:after,
      a[href^="javascript:"]:after,
      a[href^="#"]:after {
        content: "";
      }

      pre,
      blockquote {
        border: 1px solid #999;
        padding-right: 1em;
        page-break-inside: avoid;
      }

      tr,
      img {
        page-break-inside: avoid;
      }

      img {
        max-width: 100% !important;
      }

      @page :left {
        margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
        margin: 15mm 10mm 15mm 20mm;
      }

      p,
      h2,
      h3 {
        orphans: 3;
        widows: 3;
      }

      h2,
      h3 {
        page-break-after: avoid;
      }
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/darkreader@4.7.15/darkreader.min.js"></script>
  <script>
    DarkReader.enable({
      brightness: 100,
      contrast: 90,
      sepia: 10,
    });
  </script>
  <link
    rel="icon"
    type="image/png"
    href="https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTJg97A-Sa8mxjkRCmjR51WjHATLvq2aF89Z1CprR2WcQ60qYZC"
  />
  <meta name="theme-color" content="#252525" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Decentralized Systems Engineering</h1>
</header>
<!-- markdownlint-disable MD010 MD041 MD001 MD036 MD029 MD034-->
<h2 data-number="0.1" id="definitions"><span
class="header-section-number">0.1</span> Definitions</h2>
<p><strong>Distributed system</strong> - system whose components are
located on different networked computers</p>
<p><strong>Decentralized system</strong> - system without a single
authority</p>
<h2 data-number="0.2" id="examples"><span
class="header-section-number">0.2</span> Examples</h2>
<p>Centralized distributed:</p>
<ul>
<li>Google</li>
<li>Netflix</li>
<li>Facebook</li>
</ul>
<p>Decentralized distributed:</p>
<ul>
<li>The internet</li>
<li>BitTorrent</li>
<li>Bitcoin</li>
<li>Tor, I2P</li>
<li>Email</li>
<li>Mastadon</li>
<li>Usenet (forums platform predating Internet)</li>
<li>Avionics, control systems in airplains</li>
<li>E-Voting</li>
</ul>
<h2 data-number="0.3" id="cap-theorem"><span
class="header-section-number">0.3</span> CAP theorem</h2>
<p>In distributed systems you can get <strong>Consistency</strong>
(Every read receives the most recent write or an error),
<strong>Availability</strong> (Every request receives a (non-error)
response, without the guarantee that it contains the most recent write),
<strong>Partition Tolerance</strong> (The system continues to operate
despite an arbitrary number of messages being dropped (or delayed) by
the network between nodes) - and you can only choose 2 of them because
it’s not perfect.</p>
<h2 data-number="0.4" id="why-build-theses-systems"><span
class="header-section-number">0.4</span> Why build theses systems</h2>
<p>Sometimes a basic requirement</p>
<p>Availability, reliability and safety</p>
<p>Lower resource usage (in specific scenarios - e.g. Windows
update)</p>
<p>Enabler for resilient ecosystems</p>
<p>Nature has shown they can work incredibly well.</p>
<h2 data-number="0.5" id="major-topics-and-applications"><span
class="header-section-number">0.5</span> Major topics and
applications</h2>
<p>Communication: messaging, chat, voice/video</p>
<p>Data: storing, sharing, searching and mining</p>
<p>Collaboration mechanism (google docs)</p>
<p>Social networking (mastadon)</p>
<p>Deliberation, e-voting, reputation (we also need to establish
fairness and correctness)</p>
<p>Blockchains, cryptocurrencies and smart contract systems</p>
<p>And more (decenctralized control systems, intelligent agents,
military and civilian ad-hoc networks (MANET, VANET, FANET, etc))</p>
<h2 data-number="0.6" id="recurrent-issues-and-themes"><span
class="header-section-number">0.6</span> Recurrent issues and
themes</h2>
<p>Identity (real, sybil) versus location</p>
<p>Information integrity and privacy</p>
<p>Behaviour accountability (moderation)</p>
<p>Denial-of-service attacks</p>
<p>Protocol efficiency, in the normal case and under load or attack</p>
<h2 data-number="0.7" id="why-we-might-prefer-centralized-systems"><span
class="header-section-number">0.7</span> Why we might prefer centralized
systems?</h2>
<ul>
<li><p>moderation</p></li>
<li><p>policy control (banks)</p></li>
<li><p>easier to develop, implement, maintain, deploy</p></li>
<li><p>access control</p></li>
<li><p>efficiency in communication, storage, computing</p></li>
<li><p>management of network, trust, control, visibility</p></li>
<li><p>concurrency</p></li>
<li><p>up to date data</p></li>
<li><p>Legal (accountability)</p></li>
<li><p>Simplicity in:</p>
<ul>
<li>engineering</li>
<li>management</li>
<li>security model</li>
<li>version management</li>
</ul></li>
<li><p>Performance / Efficiency</p></li>
<li><p>Cost</p></li>
</ul>
<h2 data-number="0.8" id="usenet-and-gossip"><span
class="header-section-number">0.8</span> Usenet and Gossip</h2>
<p><strong>Gossip idea</strong> - family of protocols that are also
called <em>epidemic</em> protocols. Information spread over other
devices.</p>
<h3 data-number="0.8.1" id="usenet"><span
class="header-section-number">0.8.1</span> Usenet</h3>
<p><strong>Usenet</strong> - User’s network; worldwide, distributed
discussion system (like reddit before reddit)</p>
<p>It had hierarchical organization of topics where it went from root to
other topics and into other topics like a tree (great renaming).</p>
<p>Context - early 1980s:</p>
<ul>
<li>Pre-Internet (1980)</li>
<li>Mainframes, then minicomputers but VERY expensive to own, so not
personal.</li>
<li>Intermittent, dial-up connections - so mainly over the phone, and
since it was over the voice frequencies so at best 56kbit/s (unless some
people were part of ARPANET)</li>
</ul>
<p>Early UUCP (Unix-to-Unix copy)/Usenet Map - it was quite small and
could be mapped easily.</p>
<p><strong>Why think of Usenet in 2023</strong>:</p>
<p>1980s computers are still relevant just they are way smaller today
(Embedded systems, IoT, Sensors)</p>
<p>1980s networks are still relevant - Low-Power Wide-Area Networks
(e.g. LoRaNET/LoRaWAN). They have limitations - [0.3, 50] kbit/s, 256
bytes/message, per-message pricing (~2CHF/MB)</p>
<p>Power and batteries are the limit of today’s systems so efficiency is
still relevant.</p>
<p>And there is churn - the change of systems while some are down
(e.g. change the batteries)</p>
<h4 data-number="0.8.1.1"
id="specifications---todo-take-from-slides"><span
class="header-section-number">0.8.1.1</span> Specifications - TODO: take
from slides</h4>
<ul>
<li>Worldwide, distributed discussion system</li>
<li>Hierarchical organization of topics / newsgroups</li>
<li>messages are (eventually) delivered</li>
<li>……</li>
</ul>
<p>Everything is public and virtually no encryption (since it was
considered US export, computing power and RSA was not invented until
1980s)</p>
<p><strong>Message format</strong>:</p>
<ul>
<li>Header
<ul>
<li>Sender - jerry@eagle.uucp (username at the node)</li>
<li>Path - cbosjd!mhuxj!mhuxt!eagle!jerry (this is so that you can send
a response)</li>
<li>Newsgroups - news.announce (multiple can be send)</li>
<li>Subject</li>
<li>Message-ID - <em>some unique identifier</em> (to identify whether I
already got this message)</li>
<li>Timestamp - …. (to know when it was sent)</li>
<li>Organization - AT&amp;T (sender’s organization)</li>
<li>Expiration time - …. (we don’t care about this message after this
date)</li>
<li><em>there are more optional fields</em></li>
</ul></li>
</ul>
<h4 data-number="0.8.1.2" id="message-transmission"><span
class="header-section-number">0.8.1.2</span> Message transmission</h4>
<p>Basic version could be <em>Naive Broadcast</em> - send to all known
nodes, and then receiver sends to all nodes except the sender. Problem
with this is exponential flooding of network with the same message, and
it is too costly to operate.</p>
<p>Ways to fix it: recognizing the message, converting the graph into
the tree (it is extremely hard to do because of churn and adaptiveness
to change, but possible - e.g. ethernet)</p>
<h4 data-number="0.8.1.3" id="recognizing-messages-with-ids"><span
class="header-section-number">0.8.1.3</span> Recognizing messages with
IDs</h4>
<p>One way to do it is to create <em>big random number</em>
(e.g. 256bits) - even though it is big number, there is no integrity
check or someone claiming that it is their number.</p>
<p>Another way is to <em>hash</em>. Problem with it is which parts of
the message to compute the hash on. If everything, the path could change
and the hash would not be correct. Also, hash usually is computed on
binary data so there needs to be a decision what to put in the skipped
places and then parsing harder because it would not be text.</p>
<p><strong>Usenet approach</strong> - &lt;sequence
number&gt;@&lt;node&gt;</p>
<p>How to detect / trace node misbehavior? Check the path. Misbehaving
node is always represented in the path. If I receive a message, e.g. the
path is E!MT!user, and then E!MV!user, both users see that the message
passed through E. Therefore, E cannot deny being involved.</p>
<h4 data-number="0.8.1.4" id="fixing-the-broadcast"><span
class="header-section-number">0.8.1.4</span> Fixing the broadcast</h4>
<p>if message is known - ignore else - send message to all peers except
sender.</p>
<p><strong>Limitations</strong>:</p>
<ul>
<li>well-connected nodes often receice the same message many times</li>
<li>what if someone fails? (memorize and retransmit)</li>
<li>do we need to send the whole message everytime? E.g. broadcasting
that i have a message by sending ID and then sending message on-demand
<ul>
<li>early Usenet (UUCP) it was not used - because broadcast was better
than few day delay</li>
<li>late Usenet (NNCP) - it was not affordable</li>
</ul></li>
</ul>
<p><strong>Solution</strong>: Compare sets of messages. A-&gt;B sends
“ihave id1, id2, …,” B-&gt;A sends “sendme id3, id4” <em>Problem</em> -
if they have long history of message exchange, then the ihave messages
will be long. <em>Solution</em> - A stores the history of messages sent
to B. (but what if the B is a new node, so then there is a tradeoff how
many messages to send, so then send some amount of the latest
messages)</p>
<h4 data-number="0.8.1.5" id="message-ids---trade-offs"><span
class="header-section-number">0.8.1.5</span> Message IDs - Trade
offs</h4>
<p>How long to store the message IDs?</p>
<p>What happens if …</p>
<ul>
<li>you store them forever? - storage space, loop around and not getting
new messages</li>
<li>you don’t store them long enough? - message could come back into
circulation and loop around if some nodes are slow.</li>
</ul>
<h4 data-number="0.8.1.6" id="life-of-usenet"><span
class="header-section-number">0.8.1.6</span> Life of Usenet</h4>
<p>Why was it so successful? It worked. Engineering simplicity.
Decentralized - anyone can set it up. It was seen as “democratizing” -
resistant to censorship.</p>
<p>What killed it (around 1995)? (didn’t kill it but) the data became
too heavy Number 1 reason - spam! Because there was no censorship, spam
was not stopped (first spam was “Global alert for all: Jesus is Coming
Soon”, and then people found a way to make money in it) Other causes -
better alternatives, slow evolution because it was decentralized.</p>
<h2 data-number="0.9" id="beyond-usenet-gossip-efficiency"><span
class="header-section-number">0.9</span> Beyond Usenet: Gossip
efficiency</h2>
<p>What if we wanted to further minimize traffic?</p>
<p>with ihave/sendme: pro - message content is only sent once per node,
con - we still need P2P communication broadcast</p>
<h3 data-number="0.9.1" id="improved-gossiping"><span
class="header-section-number">0.9.1</span> Improved Gossiping</h3>
<p>From people we can learn <strong>Rumour mongering</strong> - checking
whether a person knows the rumour or not.</p>
<p>Algorithm:</p>
<ul>
<li>when a message M is received</li>
<li>pick a random neighbor, send M</li>
<li>neighbor replies “new rumour?”</li>
<li>if new: repeat</li>
<li>else: flip_coin() (random)
<ul>
<li>if head: repeat</li>
<li>else: stop</li>
</ul></li>
</ul>
<p>(On average we will talk to only 2 neighbors because of geometric
progression expected value)</p>
<p>Problems: Rumour might die. Pros: very fast and spreads to
<em>most</em> nodes</p>
<h4 data-number="0.9.1.1"
id="how-to-make-sure-messages-reach-every-node"><span
class="header-section-number">0.9.1.1</span> How to make sure messages
reach every node?</h4>
<p>Using <strong>anti-entropy</strong> - pull-gossiping</p>
<p>Algorithm:</p>
<ul>
<li>Periodically (when timer fires):
<ul>
<li>pick random neighbor</li>
<li>send “anything new?”</li>
<li>reduce entropy (ihave/sendme)</li>
</ul></li>
</ul>
<p>Problems: could be a lot of traffic propagation could be extremely
slow because the rumour is new</p>
<p>Expected time to cover the whole network - 1 or 2 (timer) cycles.</p>
<p>In general: works slowly but ensure complete coverage, at O(n) per
period.</p>
<h4 data-number="0.9.1.2" id="gossip-quality-measures"><span
class="header-section-number">0.9.1.2</span> Gossip Quality
Measures</h4>
<p>Is your protocol any good? How can you tell?</p>
<ul>
<li>Traffic <span class="math inline">\frac{total\ traffic}{number\ of\
nodes}</span></li>
<li><span class="math inline">t_{avg}, t_{95}</span> average &amp; 95th
percentile time for rumour -&gt; node</li>
<li><span class="math inline">t_{last}</span> time for rumour -&gt; last
node</li>
<li>Resistance to churn</li>
<li>Residue - looking at the time t, what percentage of the nodes have
not seen the message.</li>
</ul>
<p>Broadcast: good in residue, bad in traffic, and good in time of
delivery. Rumour mongering: might not reach everyone, so quite bad in
that, good in average time and traffic, but residue is not always good.
Anti-entropu: good in residue, not great in traffic, bad at average time
but good at reaching the last node. So combination of anti-entropy and
rumour mongering works very well.</p>
<h4 data-number="0.9.1.3" id="how-can-we-delete-rumours"><span
class="header-section-number">0.9.1.3</span> How can we “delete”
rumours?</h4>
<p>Instead of propagating the data in the database, we want to delete
it.</p>
<p>To delete it, we can spread the rumour to delete it. But the problem
is that we keep the original rumour and the death certificate (“delete
this”) rumour. Also, rumour can get resurrected - because it is
decentralized system, so someone has to keep the death certificate
alive.</p>
<h4 data-number="0.9.1.4" id="few-applications-of-gossip"><span
class="header-section-number">0.9.1.4</span> Few applications of
Gossip</h4>
<p>Metadata propagation</p>
<p>Failure detection</p>
<p>Group membership</p>
<p><span class="math inline">\uarr</span> databases uses gossip to
spread metadata, but the data itself is spread normally.</p>
<p>E.g. Apache Cassandra, CockroachDB, Consul</p>
<h4 data-number="0.9.1.5" id="failure-detection"><span
class="header-section-number">0.9.1.5</span> Failure detection</h4>
<p>Adding a heartbeat bits to each message sent by the node with a
counter. Later anyone can check when was the last time it was heard from
that node.</p>
<h2 data-number="0.10" id="finding-data-among-many-unknown-peers"><span
class="header-section-number">0.10</span> Finding data among (many,
unknown) peers</h2>
<p>May open questions:</p>
<ul>
<li>where can the data be found?</li>
<li>Does the data even exist?</li>
<li>Who knows about it?</li>
<li>How do we retrieve it?</li>
</ul>
<p>Most importantly:</p>
<ul>
<li>What can we assume about the peers and the network?</li>
</ul>
<h3 data-number="0.10.1" id="distributed-search-algorithms"><span
class="header-section-number">0.10.1</span> Distributed Search
algorithms</h3>
<p>Two families:</p>
<ul>
<li>Unstructured search:
<ul>
<li>Robust to churn, instantly adptive</li>
</ul></li>
<li>Structured search
<ul>
<li>Much more efficient many more problems</li>
</ul></li>
</ul>
<h4 data-number="0.10.1.1" id="building-gnutella"><span
class="header-section-number">0.10.1.1</span> Building Gnutella</h4>
<p>Context (1999-2008): No spotify, no Netflix No BitTorrent People
still want entertainment</p>
<p>Specifications:</p>
<ul>
<li>search any file anywhere</li>
<li>Complex queries</li>
</ul>
<p><strong>Standard, basic algorithm</strong>: What can we learn from
people - <strong>Flooding</strong></p>
<ul>
<li>Gossip searches (query)</li>
<li>Direct response (query hit)</li>
</ul>
<p>Issues: Unpredictable delays Connectivity - how does a node reply to
me? Efficiency - all nodes asee &amp; process all searches</p>
<p><strong>Optimizations</strong> Cane we not flood everyone?
<strong>Expanding-ring search</strong> - have limited number of steps
for flooding</p>
<ul>
<li>Limited flooding (TTL)</li>
<li>Increasing TTL on retry</li>
</ul>
<p>What are the trade-offs? Higher latency Asymptotically worse O(n
logn)</p>
<p>Pragmatically, it works</p>
<p><strong>Optimizations</strong> More efficient:
<strong>BubbleStorm</strong></p>
<ul>
<li>Birthday paradox - in a room bigger size, there is a 99.999% chance
that 2 people share a birthday</li>
<li>Data search &amp; storage random “meet in the middle”. Spread a file
in <span class="math inline">\sqrt{n}</span> nodes. Bubbles overlap and
there is a high chance that someone in my bubble has the file</li>
<li>If the bubble is increased by a constant (from <span
class="math inline">\sqrt{n}</span> nodes) we exponentially increase the
chance of someone having the file because of the birthday paradox.</li>
</ul>
<p>Key considerations: Asymptotically efficient <span
class="math inline">O(\sqrt{n})</span> “Mostly unstructured” - robust to
churn Tunable parameters Extremely robust/resilient - therefore it can
be applied in different systems, not only search</p>
<p><strong>Unrealistic assumption</strong> - so far we said that the
node can just reply to the source, but that’s not possible.</p>
<h2 data-number="0.11" id="ad-hoc-routing-protocols"><span
class="header-section-number">0.11</span> Ad-hoc Routing Protocols</h2>
<h4 data-number="0.11.0.1"
id="p2p-example---home-and-epfl-networks"><span
class="header-section-number">0.11.0.1</span> P2P Example - home and
EPFL networks</h4>
<p>EPFL Network &lt;- EPFL Firewall &lt;- Public internet -&gt; ISP
-&gt; home router + NAT -&gt; IP address</p>
<p>If laptop at home tries to connect to the PC at EPFL it cannot
because firewall If you try to connect to your laptop at home, you
cannot because it does not have an IP address (if there is no port
forwarding)</p>
<p>Problem: even in the wired state of routing, you will not be able to
connect to everyone simply.</p>
<h4 data-number="0.11.0.2"
id="p2p-example---ad-hoc-networks---drones"><span
class="header-section-number">0.11.0.2</span> P2P Example - ad-hoc
networks - drones</h4>
<p>Drones can go out of range.</p>
<p>Bob sent out a lot of drones and wants to communicate with all of
them. Drones find each other and set up links. However, drones move
around which causes the reconfiguration of the network. (similar to
this, a person moves with their device in EPFL)</p>
<h4 data-number="0.11.0.3" id="p2p-example---analysis"><span
class="header-section-number">0.11.0.3</span> P2P Example -
analysis</h4>
<ul>
<li>peers may not be directly accessible</li>
<li>peers may join or leave the network at arbitrary times</li>
<li>we need to route packes through the system</li>
</ul>
<p>Some differences:</p>
<ul>
<li>Churn - going offline, joining back in</li>
<li>Node mobility / network reconfiguration</li>
<li>Bandwidth</li>
<li>Protocols / Physical layer / etc.</li>
</ul>
<h3 data-number="0.11.1" id="naive-routing-dont-do-this"><span
class="header-section-number">0.11.1</span> Naive routing (don’t do
this)</h3>
<p>Nodes advertise a distance to other nodes.</p>
<p>E.g.: B -&gt; D = 1 A -&gt; D = 2 (through B or C) c -&gt; D = 1</p>
<p>If D loses connectivity to B and C. B updates to B -&gt; D = 2
(through C) C updates to C -&gt; D = 3 (through B) …. it goes on and on
This is because B and C are making decision on outdated information.</p>
<h3 data-number="0.11.2"
id="reaching-arbitrary-peers-in-a-network-aodv"><span
class="header-section-number">0.11.2</span> Reaching arbitrary peers in
a network : AODV</h3>
<p>Ad-hoc On-demand Distance Vector</p>
<p>Key idea: Flooding search for a node (e.g. E) - when we know that a
node exists. Nodes remember where the search came from. (Remember only
the first search coming through). And once the answer is there, nodes
walk back the path like in Usenet. Every node along the found path gets
a temporal path to the origin of the search as well. A-&gt;B-&gt;D-&gt;E
A&lt;-B&lt;-D&lt;-E</p>
<p>This is valid over a short time window and the idea is not to
remember for a long time.</p>
<p>It has the same problems as flooding.</p>
<p>Zigbee wireless protocol uses this.</p>
<h3 data-number="0.11.3" id="dsdv"><span
class="header-section-number">0.11.3</span> DSDV</h3>
<p>Destination-Sequenced Distance Vector</p>
<p>Key idea:</p>
<ul>
<li>Store next hop for any destination (O(n))</li>
<li>Version (“sequence”) rounting table entries</li>
</ul>
<p>Each node periodically broadcasts its existance: Flood the network,
with increasing sequence numebrs (we know which version of this flood we
are getting).</p>
<p>O(n^2) traffic, superseeded by newer protocols.
<strong>versioning</strong> idea is still on</p>
<h3 data-number="0.11.4" id="quality-factors-in-ad-hoc-routing"><span
class="header-section-number">0.11.4</span> Quality factors in ad-hoc
routing</h3>
<ul>
<li>amount of traffic during updates/creation</li>
<li>amount of traffic at rest</li>
<li>robustness to churn and movement</li>
<li>speed of convergence - the routing could be temporarily broken</li>
<li>guarantee of being loop-free</li>
</ul>
<h2 data-number="0.12" id="compact-routing-and-structured-search"><span
class="header-section-number">0.12</span> Compact routing and structured
search</h2>
<h3 data-number="0.12.1" id="general-approach"><span
class="header-section-number">0.12.1</span> General approach</h3>
<p>Build a structured <em>overlay network</em> (like a virtual LAN) It
enables significant efficiency gains</p>
<p>The price paid:</p>
<ul>
<li>more engineering effort</li>
<li>nodes will need local state (to keep the strucure AND what to do
when nodes disappear)</li>
<li>constant fight against churn</li>
<li>loss of generality</li>
</ul>
<h3 data-number="0.12.2" id="distributed-hash-table"><span
class="header-section-number">0.12.2</span> Distributed Hash Table</h3>
<p>Local hash tables need:</p>
<ul>
<li>“good” hashing function</li>
<li>Random Access memory (for constant time access)</li>
<li>Not too full</li>
</ul>
<p>Most of the time hash functions are not cryptographic (to not pay the
cost of calculating hash cryptographically)</p>
<p>Distributed hash tables considerations:</p>
<ul>
<li>what do we need from the hash functions?
<ul>
<li>Avoid collisions, not time sensitive (because of networks time
cost)</li>
<li>crypto hash functions for it to be collision resistant and well
distributed (because it will be big system)</li>
</ul></li>
<li>what are we missing?
<ul>
<li>random access memory</li>
</ul></li>
</ul>
<h4 data-number="0.12.2.1" id="chord-dht"><span
class="header-section-number">0.12.2.1</span> Chord DHT</h4>
<p>Hash into a collection of RAMs To do that we will use circular hash
ID space (e.g. SHA-256)</p>
<p>Each node has a pseudo-random hash ID (it enables us to put the nodes
somewhere in the hash value space). What goes into that ID? (ideas: IP,
MAC, time, PubK) - this has to be unique and unchanging. Only PK cannot
be faked</p>
<p>How to approximate the RAM: divide space up between the nodes Each
node owns the space to its successor</p>
<p>API: PUT(key,value) GET(key) -&gt; value/error</p>
<p>Problems:</p>
<ul>
<li>churn</li>
<li>resource allocation</li>
<li>security (malicious)</li>
<li>routing information (as in who is ahead and behinf you in this
pie)</li>
</ul>
<p><strong>Reliability</strong>: How to prevent data loss? Define a
redundancy factor r And copies are stored by “owner” node + (r-1)
successors.</p>
<p><strong>Load</strong>: What is the expected load per node?</p>
<p>Load ~ <span class="math inline">\frac{\text{# of nodes} \times
\text{# of kv pairs}}{\text{redundancy}}</span></p>
<p><strong>Performance</strong>: How do we make this O(log n)? (in
storage, network, etc)</p>
<p>Using only the successors O(1) routing table but O(n) access time</p>
<p>Binary search makes it O(log n) for both. Finger tables: Contains my
successor, 1/2 circle from me, 1/4 circle from me, 1/8 circle from me…
We are using SHA-256, so we expect to have 2^256 numbers (HUGE, and most
of this will be empty), that is why we expect log n spaces in the
routing table.</p>
<p><strong>Churn</strong>:</p>
<p>Need to handle:</p>
<ul>
<li>concurrent joining
<ul>
<li>there are challenges - e.g. a lot of nodes joining between A and B -
therefore a lot of changes</li>
</ul></li>
<li>nodes leaving (gracefully)
<ul>
<li>replicating data, changing routing tables</li>
</ul></li>
<li>nodes leaving (unresponsive)
<ul>
<li>making others successors while successor is pointing to another
value (<strong>drawing of successors pointing to next, next next,
etc</strong>)</li>
<li>because of this system is going to underperform</li>
</ul></li>
</ul>
<p>Approach:</p>
<ul>
<li>split correctness and performance (tolerate some incorrectness)</li>
<li>transient failures can be retried</li>
</ul>
<h2 data-number="0.13" id="decentralized-storage-distribution"><span
class="header-section-number">0.13</span> Decentralized Storage &amp;
Distribution</h2>
<h3 data-number="0.13.1" id="storing-data-reliably"><span
class="header-section-number">0.13.1</span> Storing data (reliably)</h3>
<p>On local machine: Storing in redundancy (RAID - redundant array of
independent discs, FEC/ECC/erasure codes) - encode the data and some
additional data such that we don’t lose it.</p>
<p>Distributed: Block-, filesystem- or object-level access (SAN, NAS,
AWS S3) - different levels of abstraction Redundancy - should all 1000
computers have a copy - no, but more than one copy Concurrency control -
locking does not scale well but is easy Sharding - keeping a subset of
the data in one place</p>
<h3 data-number="0.13.2" id="cap-theorem---reminder"><span
class="header-section-number">0.13.2</span> CAP theorem - reminder</h3>
<p>Definitions:</p>
<ul>
<li>Consistency - anyone reading will read the last write (or
error)</li>
<li>Availability - all requests get a non-error reply</li>
<li>Partition tolerance - dropped/delayed packets</li>
</ul>
<p>All of them overlap, but not all 3 of them.</p>
<p>Beyond CAP: think of availability as latency -&gt; Latency vs
consistency (how much am i willing to wait to be consistent or how
consistent do i need to be if i want to wait little time) -&gt; eventual
consistency (at some point i will be consistent)</p>
<h3 data-number="0.13.3" id="goals-and-challenges"><span
class="header-section-number">0.13.3</span> Goals and Challenges</h3>
<p>Availability - robust to churn, individual node failures, etc
(durability could also be included but also independent - how robust are
we to losing data)</p>
<p>Consistency - how do we stay in sync? weak or strong consistent?</p>
<p>Scalability, load balancing - efficiency in bandwidth and storage
space</p>
<p>Modifiability/mutability - if i want to have data that is modifiable,
how do we manage consistency; how to manage multi-writing.</p>
<p>Malicious security - eclipse (have enough keys to take away the
data), tampering and rollback attacks (serving old version of the
data)</p>
<p>InfoSec (CIA triad) - confidentiality, integrity, availability -
access control, logging, accountability</p>
<p>(Logical) data organization - “flat”? files? directories? databases?
graph?</p>
<p>(Physical) data location - where should it be stored?</p>
<h3 data-number="0.13.4" id="building-bittorrent"><span
class="header-section-number">0.13.4</span> Building BitTorrent</h3>
<h4 data-number="0.13.4.1" id="specificaiton"><span
class="header-section-number">0.13.4.1</span> Specificaiton</h4>
<p>Distribute a large, static (immutable) files:</p>
<ul>
<li>from a source node with limited bandwidth</li>
<li>to a large number of users</li>
<li>as fast as possible</li>
</ul>
<p>Scalable - 22% up- and 3% downstream of global internet traffic</p>
<p>Assume users are self-interested = don’t assume they want to help</p>
<p>How to build this? Core intuition? - turn downloaders into
uploaders</p>
<h4 data-number="0.13.4.2" id="distribution"><span
class="header-section-number">0.13.4.2</span> Distribution</h4>
<p>Source has 6 chunks of data. At any point it is uploading at most to
2 nodes. Distribute chunks to the nodes in different steps, and when all
the chunks are in the network, all nodes eventually get the full
data.</p>
<h4 data-number="0.13.4.3" id="sub-problems"><span
class="header-section-number">0.13.4.3</span> Sub-problems</h4>
<ul>
<li>Advertising a file</li>
<li>how to find peers to download from</li>
<li>verfiying integrity of large files (or parts of them) - not a
virus</li>
<li>optimizing performance</li>
<li>aligning incentives (downloaders vs uploaders)</li>
</ul>
<h5 data-number="0.13.4.3.1"
id="distribution-and-integrity-of-large-files"><span
class="header-section-number">0.13.4.3.1</span> Distribution and
integrity of (large) files</h5>
<p>A client should be able to verify: parts of file, as they are
downloaded the whole file (after download)</p>
<p>Solution: part 1 - compute hashes for parts (chunking) part 2 - hash
tree (merkle tree) - hash over the hashes building a tree (otherwise
ineficient to transfer data ie all hashes)</p>
<h5 data-number="0.13.4.3.2" id="finding-peers-bootstrapping"><span
class="header-section-number">0.13.4.3.2</span> Finding peers /
bootstrapping</h5>
<p>Two options:</p>
<ul>
<li>Trackers - server whose role is to send peers to other peers who
have the files</li>
<li>Mainline DHT (based on Kademlia) - key is the hash of the file,
value is the list of peers who are working on that file.</li>
</ul>
<p>Join the swarm and connect to ~80 peers.</p>
<h5 data-number="0.13.4.3.3" id="publishing-new-content"><span
class="header-section-number">0.13.4.3.3</span> Publishing new
content</h5>
<ol type="1">
<li>“Prepare” the file (chunks and build Merkle tree)</li>
<li>Register with a “tracker”</li>
<li>Publish a .torrent file or magnet (DHT) link</li>
</ol>
<h5 data-number="0.13.4.3.4" id="performance-and-incentives"><span
class="header-section-number">0.13.4.3.4</span> Performance and
Incentives</h5>
<p>One of the key ideas is to download rarest data blocks (“chunks”)
first - entropy maximization</p>
<p>Use Tit-For-Tat strategy (“choking” protocol) - if you’re mean to me
I am mean to you, if you’re good to me I am good to you.</p>
<ul>
<li>“chokes” punishes peers that are not uploading</li>
<li>“unchokes” peers with the highest upload rates</li>
<li>“optimistic unchoking” looks for better/bootstrapping peers</li>
</ul>
<p>Make the download rate proportional to the upload rate for each
peer.</p>
<p>BitTorrent does not take into account where (location-wise) your
peers are. And the download and upload speed are not symmetrical.</p>
<h4 data-number="0.13.4.4" id="bittorrent-inspired-solutions"><span
class="header-section-number">0.13.4.4</span> BitTorrent-inspired
solutions</h4>
<p>Servers:</p>
<ul>
<li>Twitter’s “Murder” server deployment system (went from 40min to 12s
deployment)</li>
<li>Facebook’s same thing</li>
</ul>
<p>Games:</p>
<ul>
<li>“Blizzard Downloader” - WoW, Diablo 3</li>
<li>Wargaming’s - World of Tanks, …</li>
</ul>
<p>OS:</p>
<ul>
<li>Windows Update</li>
<li>others have tried - “DebTorrent”</li>
</ul>
<h4 data-number="0.13.4.5" id="bittorrent-limits"><span
class="header-section-number">0.13.4.5</span> BitTorrent limits</h4>
<p>Why did DebTorrent fail to materialize?</p>
<ul>
<li>Not suited for small files (overhead)</li>
<li>Not suited for sharing overlapping sets of data (across
torrents)</li>
<li>Data is immutable (and not re-usable across torrents)</li>
<li>Locality of peers is ignored - ISPs do traffic-shaping</li>
</ul>
<p>For DebTorrent, both “1 huge torrent” or “1M+ small ones” =
inneficient</p>
<h3 data-number="0.13.5" id="ipfs---inter-planetary-file-system"><span
class="header-section-number">0.13.5</span> IPFS - Inter-Planetary File
System</h3>
<p>Protocol for P2P distributed file system, fully decentralized</p>
<p>Designed to address (perceived) flaws in HTTP - why do i need to
visit this exact website, link-rot, my data etc</p>
<p>Deployed at massive scale: 2023: &gt;300k nodes, millions of unique
weekly users, 100+ PiB stored</p>
<p>A decentralized file system inspired by:</p>
<ul>
<li>Kademlia DHT</li>
<li>BitTorrent (block exchange)</li>
<li>Git versioning</li>
<li>Self-certifying filesystems</li>
</ul>
<h4 data-number="0.13.5.1" id="representing-a-filesystem-in-a-dht"><span
class="header-section-number">0.13.5.1</span> Representing a filesystem
in a DHT</h4>
<p>Everything is immutable</p>
<p>All objects are self-certifying (files, links, folders, changes) -
prevents websites being exact copies of each other; the hash of data
coming from different nodes will be the same even if it’s coming from
different places. ID is computed based on object’s hash</p>
<p>Any IPFS object (file, folder) is represented in the same way:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode go"><code class="sourceCode go"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> IPFSObject <span class="kw">struct</span> <span class="op">{</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">//array of links</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  links <span class="op">[]</span>IPFSLink</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">//opaque content data</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  data <span class="op">[]</span><span class="dt">byte</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> IPFSLink <span class="kw">struct</span> <span class="op">{</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  Name <span class="dt">string</span>       <span class="co">// target&#39;s name</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  Hash Multihash    <span class="co">//... hash</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  Size <span class="dt">int</span>          <span class="co">// ... size</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h5 data-number="0.13.5.1.1" id="representig-a-file-256kb"><span
class="header-section-number">0.13.5.1.1</span> Representig a file &lt;
256kB</h5>
<p>It is a blob, and representation looks like git</p>
<h5 data-number="0.13.5.1.2" id="representing-a-file-256kb"><span
class="header-section-number">0.13.5.1.2</span> Representing a file &gt;
256kB</h5>
<p>Split it in chunks - list of smaller files</p>
<h5 data-number="0.13.5.1.3" id="representing-a-directory"><span
class="header-section-number">0.13.5.1.3</span> Representing a
directory</h5>
<p>Object that has links to files, to subdirectories. This is a directed
acyclic graph.</p>
<h5 data-number="0.13.5.1.4" id="versioning"><span
class="header-section-number">0.13.5.1.4</span> Versioning</h5>
<ul>
<li>Git-like</li>
<li>Build a mMrkle DAG</li>
<li>Build a snapshot of the current state</li>
<li>Hash of both content and its parent commit’s hash</li>
<li>Creates a Git-like log of versions</li>
</ul>
<p>Problems: How do we know the latest version? merge problems</p>
<h5 data-number="0.13.5.1.5" id="naming-mutable-data"><span
class="header-section-number">0.13.5.1.5</span> Naming (mutable)
data</h5>
<p>Objects are immutable so:</p>
<ul>
<li>use a separate namespace for mutable data</li>
<li>use mutable, signed pointers to immutable data</li>
<li>not content-addressable - advertise link on routing system (because
the system is dynamic, we need to announce it every ~4 hours)</li>
<li>built-in limit to rollback attack (since the link has an expiration
time)</li>
</ul>
<p>These are independent of the file system.</p>
<p>For naming we will use an extension that is IP Naming System: use
public key to make sure that no one else is using it</p>
<h3 data-number="0.13.6"
id="shifting-paradigm---local-first-software"><span
class="header-section-number">0.13.6</span> Shifting paradigm -
Local-First Software</h3>
<p>Git, Google Docs, Apple Notes - work offline and you (nearly) get the
full experience</p>
<p>How? Multi-versioning concurrency control - how to “merge” versions
that forked?</p>
<p>Goals:</p>
<ul>
<li>local client is first-class citizen</li>
<li>works offline</li>
<li>eventual consistency</li>
<li>ideally - can handle forks</li>
</ul>
<p>What tool - Conflic-Free Replicate Data Types (Data structure +
Algorithm + Protocol)</p>
<h3 data-number="0.13.7"
id="conflict-free-replicate-data-types-crdts"><span
class="header-section-number">0.13.7</span> Conflict-Free Replicate Data
Types (CRDTs)</h3>
<p>Various types:</p>
<ul>
<li>Values (simples approach - last write wins)</li>
<li>Counters (allow machines to count)</li>
<li>Lists</li>
<li>Text</li>
</ul>
<p>Categories: Operation-based - commutative replicated data types
(CmRDTs) State-based - convergent replicative data types (CvRDTs)</p>
<h4 data-number="0.13.7.1" id="g-counter-crdt"><span
class="header-section-number">0.13.7.1</span> G-Counter CRDT</h4>
<p>Grow-only counter - replicated across N machines</p>
<p>Add(x) - updates our local counter</p>
<p>Query() - returns the value</p>
<p>Merge(other_state) - merge’s other’s state</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GCounter(<span class="bu">object</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> _init_(<span class="va">self</span>, i, n):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.i <span class="op">=</span> i <span class="co"># server id</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.n <span class="op">=</span> n <span class="co"># number of servers</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.xs <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> n</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> add (<span class="va">self</span>, x):</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> x <span class="op">&gt;=</span> <span class="dv">0</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.xs[<span class="va">self</span>.i] <span class="op">+=</span> x</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> query(<span class="va">self</span>):</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(<span class="va">self</span>.xs)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> merge(<span class="va">self</span>, other):</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    zipped <span class="op">=</span> <span class="bu">zip</span>(<span class="va">self</span>.xs, other.xs)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.xs <span class="op">=</span> [<span class="bu">max</span>(x, y) <span class="cf">for</span> (x, y) <span class="kw">in</span> zipped]</span></code></pre></div>
<h4 data-number="0.13.7.2"
id="local-first-software---simpler-backends"><span
class="header-section-number">0.13.7.2</span> Local-First Software -
simpler backends</h4>
<p>Application becomes sequence of messages storage and sync, and
therefore it becomes way easier to deploy.</p>
<h2 data-number="0.14" id="replication-of-consensus"><span
class="header-section-number">0.14</span> Replication of Consensus</h2>
<h3 data-number="0.14.1" id="replication"><span
class="header-section-number">0.14.1</span> Replication</h3>
<p>Replicating storage or nodes in a distributed system</p>
<h4 data-number="0.14.1.1" id="storage-replication"><span
class="header-section-number">0.14.1.1</span> Storage Replication</h4>
<p>Storage-specific replication techniques assume that node stays alive,
and there is a focus on making sure that disk failures are
supported.</p>
<p>Classic storage replication techniques: e.g. disk failure -&gt; RAID
(redundant array of inexpensive disks)</p>
<ul>
<li>RAID1 - mirroring (2 copies on 2 disks)</li>
<li>RAID5 - striping with parity. (2 disks store one stripe each and
third one stores parity disk). Tolerates any <strong>single</strong>
disk failure</li>
<li>RAID6 - double parity. Tolerates 2 disk failures.</li>
</ul>
<p>Disks are passive and there is an “authority” who knows/governs the
“state of universe”</p>
<p>Replication of distributed <em>Nodes</em> - we want to replicate any
node such that when one fails, the system can work.
<strong>Problem</strong> - there is no “authority”</p>
<h3 data-number="0.14.2" id="agreement-or-consensus"><span
class="header-section-number">0.14.2</span> Agreement or Consensus</h3>
<p>There are several (n) nodes agreeing on one state (value).</p>
<p>One way to categorize consensus protocols broadly: permissioned or
permissionless (since 2008)</p>
<ul>
<li>Permissioned - algorithm assumes a well-defined, closed group of n
nodes.</li>
<li>Permissionless (Bitcoin) - makes nodes prove that they did something
- proof-of-work</li>
</ul>
<p>Narrower categorization for permissioned protocols: Crash failures
(loses power, becomes unoperational) vs Byzantine failures (a node might
be malicious or compromised)</p>
<p>Many different consistency models - <strong>How</strong>
consistent?</p>
<ul>
<li>Serialization - we want all nodes agreeing on a single history</li>
<li>Eventual consistency - nodes may disagree for a while but eventually
come to agreement</li>
</ul>
<h4 data-number="0.14.2.1" id="paxos-consensus-algorithm"><span
class="header-section-number">0.14.2.1</span> Paxos consensus
algorithm</h4>
<p>Assume that there is a set of state nodes - Acceptors. For now have 2
of them. (s1, s2) And there are clients which drive the agreement -
Proposers (alice, bob)</p>
<p><em>Case 1:</em> Assume Bob does not exist, Alice proposes state
transaction T, and the state nodes will say yes to T because they have
not heard from Bob.</p>
<ol type="1">
<li><strong>Problem</strong> - alice might not know of a failure before
it is accepted, s2 might fail before sending back yes.</li>
<li>If alice wants to tolerate f failures (f &lt; n), then it must be
able to move on after waiting for at most n-f answers.</li>
</ol>
<p><em>Case 2:</em> Now assume Alice and Bob proposes transactions T1
and T2, and now the <strong>problem</strong> is that if both wait for
just one server to answer, they might disagree (s1 yes to Alice, s2 yes
to Bob)</p>
<p>This illustrates <strong>main principle</strong>: To reach agreement
of only 1 value, we need to have a <em>majority</em> - n &gt; 2f (or n
&gt;= 2f + 1).</p>
<p>Now have 3 acceptors, and 2 clients - alice and bob. A and B propose
T1, T2. Alice transaction gets accepted by s1 and s2 first, bob’s gets
accepted by s3, and s2 replies to bob that alice won. –&gt; Server 2 is
the only disambiguating authority, and if it fails, no one knows who
won.</p>
<p>Also a problem If there are more proposers. Now have 3 acceptors, and
3 clients - alice, bob, and charlie. A, B, and C propose T1, T2 and T3.
s1 accepts A, s2 accepts B, and s3 accepts C -&gt; <strong>Fundamental
problem</strong> - no one gets a majority.</p>
<p><strong>Fundamental problem</strong> - how do you know when consensus
has been reached? each client has <span class="math inline">\le</span>
n-f observations, so it doesn’t have full picture. e.g. If i talked with
majority and got 0 yes answers, I know i failed; If i talked with
majority and got 1 yes answer, i might have succeeded. e.g. if I got f
yeses, then i might have failed. =&gt; “I don’t know”</p>
<p>if i got 0 yes, definitely failed; if i got f+1 yes, “looks like” i
succeeded.</p>
<h5 data-number="0.14.2.1.1" id="fundamental-challenges"><span
class="header-section-number">0.14.2.1.1</span> Fundamental
challenges</h5>
<ol type="1">
<li>Be able to <em>try again</em> on failure.</li>
<li>If agreement might have happened, the future tries have to be
consistent with past attempts that <em>might</em> have agreed</li>
</ol>
<p><strong>Tackling try-again</strong>: Use lock-step time - steps or
“ballot numbers” (they are logical steps not real time steps)</p>
<p>Alice convinces s1 on step 1, B on s2, C on s3, so now try again.
They start again all, but alice gets first to step 2. So alice wins.</p>
<p><strong>Tackling phases</strong>:</p>
<ol type="1">
<li>figure out if I <em>can</em> succeed</li>
<li>figure out if I <em>did</em> succeed</li>
</ol>
<p>Paxos has a time-step reservation system:</p>
<ol type="1">
<li>client asks each server to <em>reserve</em> (“prepare”) step for
me</li>
<li>only if succeeds, client asks each server to <em>record</em>
proposal.</li>
</ol>
<p>E.g. 3 servers, 1 client Alice. Alice sends a proposal “reserve step
1” to each server, waits for answers. Gets majority of the answers
“yes”, so majority moves forward to ask “record 1:T”. And since nobody
broke alice’s reservation, those recordings are successful from the
majority, so the servers knows that alice had a majority.</p>
<p>What happens when s3 dies (and s1 got another reservation from B,
which means s2 and s3 guaranteed recording of alice -&gt; s2 is the only
one left confirming this)? S1 know that alice <em>might</em> have
succeded, s2 knows that alice succeeded. Bob while reserving step 2 on
s2 sees that alice might have succeeded in step 1, and if it succeeds in
step 2, it records latest/highest prepared T (because bob is obligated
to be consistent with alice’s attempt).</p>
<p><strong>Key rule of Paxos</strong> - if it’s possible that at
previous timestep client might have succeeded, current client at current
step must carry out that previous attempt.</p>
<p>e.g. 3 servers, 2 clients Alice and bob: Alice sends a proposal
“reserve step 1” to each server, waits for answers. Gets 1 answer “yes”
from s1, Bob sees that one server might have succeeded, and sends his
reservation for step 2. Bob succeeds at s2 and s3, Bob sends record T’,
and then s3 records T’. And this depends on the majority that agrees to
have the view of overwriting or saving alice’s step.</p>
<h2 data-number="0.15" id="cryptography"><span
class="header-section-number">0.15</span> Cryptography</h2>
<p>Cryptography is not reliable unless implemented properly, and unless
used properly. And it is not a solution to all problems</p>
<ul>
<li>Shared-algorithm cryptography</li>
<li>Symmetric-key cryptography</li>
<li>public-key cryptography (encrypt with pubkey, decrypt with privkey;
sign with privkey, verify with pubkey)
<ul>
<li>interactive key exchange (Diffie-Hellman key exchange)</li>
<li>Elliptic curve key exchange (ECC)</li>
</ul></li>
<li>Cryptographic hash functions</li>
<li>Key infrastructure</li>
<li>Threshold secret sharing</li>
</ul>
<h4 data-number="0.15.0.1" id="elliptic-curve-cryptography"><span
class="header-section-number">0.15.0.1</span> Elliptic curve
cryptography</h4>
<p>is based on the algebraic structure of elliptic surves over finite
fileds.</p>
<p>Hardness (trapdoor) - hard to determine n form Q = nP, given known Q
and P, and a sufficiently large n. And computing Q is easy.</p>
<p>Smaller keys for equivalent security than traditional crypto
(e.g. 256-bit for ECC is comparable to 2048-bit RSA) -&gt; faster
operations, and smaller pubkeys -&gt; smaller crypto</p>
<p>It is used in Bitcoin to authenticate transactions and every Bitcoin
address is a cryptographic hash of ECDSA pub key. Apple uses it for
their services</p>
<p><strong>Requirement</strong> - Randomness for the ECC. Problem if it
is not being used - security of private key could be compromised. In
2010 Sony used it but used a constant instead of randomness to sign
software for PS3 and privkey was recovered In 2013 Android Bitcoin
Wallet due to k being predictable</p>
<h4 data-number="0.15.0.2" id="key-distrivution"><span
class="header-section-number">0.15.0.2</span> Key distrivution</h4>
<p>for both symmetric and asymmetric crypto key distribution is
necessary</p>
<p>Exchange of secret keys requires confidentiality Exchange of public
keys requires integrity</p>
<p>Authorities trusted to provide secret/trusworthy keys (KDC./A)</p>
<p>There is a hierarchy of trust - one of KDC/CA is not enough. Problem
- this is centralized, therefore attacker could carry out MITM
attacks.</p>
<h5 data-number="0.15.0.2.1" id="web-of-trust-wot"><span
class="header-section-number">0.15.0.2.1</span> Web Of Trust (WOT)</h5>
<p>Creating the graph where I can trust someone who is trusted by
someone I already trust. This works very well until there is a node who
trusts a lot of malicious nodes.</p>
<h4 data-number="0.15.0.3" id="threshold-secret-sharing"><span
class="header-section-number">0.15.0.3</span> Threshold secret
sharing</h4>
<p>Sharing a secrete without revealing it</p>
<p>Any encrypted data is secured with a private key.</p>
<ul>
<li>a private key is just information (a number)</li>
<li>if the key leaks, anyone can decrypt the data (regardless where it
is stored)</li>
</ul>
<p>Privacy &amp; accountabilitiy with secret-sharing, essential
idea:</p>
<ul>
<li>split the secret key among n parties</li>
<li>require only a <em>threshold</em> t of n parties to use it.</li>
</ul>
<p>Distributed key generation (DKG) - allows the group of nodes to
create their set of of public-private keys</p>
<h3 data-number="0.15.1"
id="drand-publc-verifiable-randomness-explained"><span
class="header-section-number">0.15.1</span> drand: publc, verifiable
randomness explained</h3>
<h4 data-number="0.15.1.1" id="secret-randomness"><span
class="header-section-number">0.15.1.1</span> Secret randomness</h4>
<p>We always use secret randomness to generate cryptographic material
(used in AES always)</p>
<h4 data-number="0.15.1.2" id="public-randomness"><span
class="header-section-number">0.15.1.2</span> Public randomness</h4>
<p>E.g. Lottery It is simply a random value that is meant to be
public.</p>
<p>Its goal is often to increase the trust.</p>
<h4 data-number="0.15.1.3" id="verifiable-randomness"><span
class="header-section-number">0.15.1.3</span> Verifiable randomness</h4>
<p>public randomness is cool, but we usually wnat it to allow for public
verifiability.</p>
<p>This requires many complex verfiable generating functions.</p>
<h2 data-number="0.16" id="anonymous-communication"><span
class="header-section-number">0.16</span> Anonymous Communication</h2>
<h3 data-number="0.16.1" id="who-has-eyes-to-your-internet-usage"><span
class="header-section-number">0.16.1</span> Who has eyes to your
internet usage?</h3>
<ul>
<li>ISP</li>
<li>Local network (employer’s security solution)</li>
<li>Governments</li>
<li>Parental control</li>
<li>Ads - Google, Meta, etc.</li>
<li>Platforms - Amazon, Alphabet, Tencent, Alibaba,…</li>
<li>VPN servers, proxies</li>
<li>Spyware</li>
<li>Browsers - Google, Mirosoft, Mozilla, Apple</li>
<li>DNS servers</li>
</ul>
<p>(some snooping is not that bad - deprecation of certain features)</p>
<p><strong>Hasn’t TLS/encryption solved the problem?</strong></p>
<p>Metadata says everything about somebody’s life.</p>
<p>How to determine the person on the metadata: Patterns of behaviour
(this person’s IP changes regularly), network traffic of bluetooth could
reveal the medical condition and a specific brand device.</p>
<p><strong>Why desire anonymity online?</strong></p>
<ul>
<li>Privacy (individuals), Security (business, governments)</li>
<li>Freedom of speech / journalism / activists (escaping censorship,
avoid speech being linked to oneself)</li>
<li>Avoid ad targeting, tracking</li>
<li>Bypass geo-blocking</li>
<li>Helps criminals stay out of jail</li>
<li>Helps cops investigate online crimes</li>
</ul>
<h3 data-number="0.16.2" id="threat-model"><span
class="header-section-number">0.16.2</span> Threat model</h3>
<p>Is out desire to remain anonymous a secret on its own?</p>
<p>Who are we keepking our identity from? a website, advertisers, a
platform (meta, google), a well-funded governments</p>
<p>What are their capabilities? Cookies, “Supercookies”, fingerprinting
Semi-honest nodes (“honest but curious”) Malicious nodes NSA -
Xkeyscore, Quantum &amp; FoxAcid (MITM, MOTS - Man On The Side attack)
CAC (Cyber Administration of China) - Censorship, MOTS, control over
platforms</p>
<p><strong>How?</strong> Client sends a packet to server, server
responds, NSA takes the response packet from internet backbone, tells
the router to drop the packet, and meanwhile sends the packet through
Quantum system - TAO FOXACID which sends that packet to the client.</p>
<h3 data-number="0.16.3" id="the-goal"><span
class="header-section-number">0.16.3</span> The goal</h3>
<ul>
<li>Server and receiver cannot be “linked” by a 3rd party</li>
<li>Server and receiver both remain anonymous, including to each other
(within an <em>anonymity</em> set)</li>
<li>Metadata must be unusable for traffic analysis
<ul>
<li>padding hides the size of the data (how many files could be in the
size range)</li>
<li>only few people can talk with me</li>
</ul></li>
<li>Ideally - censorship-resistant</li>
</ul>
<h3 data-number="0.16.4" id="how-to-achieve-anonymity"><span
class="header-section-number">0.16.4</span> How to achieve
anonymity</h3>
<h4 data-number="0.16.4.1" id="hop-approach"><span
class="header-section-number">0.16.4.1</span> 1-hop approach</h4>
<p>1-hop approach - Proxy / Commercial VPN - ISP can see that you are
communicating with the VPN, but they don’t know what is the end
communication</p>
<p>Advantages:</p>
<ul>
<li>shields user from website IP-based tracking</li>
<li>prevents geolocation</li>
</ul>
<p>Problems:</p>
<ul>
<li>VPN knows incoming &lt;-&gt; outgoing mapping</li>
<li>Vulnerable to traffic analysis</li>
<li>Vulnerable to hacking / coercion</li>
<li>DNS might be leaking information (as a side channel because it is
not forced to be under VPN)</li>
<li>Vulnerable to censorship</li>
</ul>
<h4 data-number="0.16.4.2" id="hop-approach-1"><span
class="header-section-number">0.16.4.2</span> 2-hop approach</h4>
<p>2-hop approach - Apple Private Relay</p>
<p>There are 2 relays: you are talking to Apple, and they talk with 3rd
party, which talks to Web.</p>
<p>Advantages:</p>
<ul>
<li>Shields user from website IP-based tracking</li>
<li>In theory, no single party sees both sender and receiver</li>
</ul>
<p>Problems:</p>
<ul>
<li>Restricted to countries allowing it</li>
<li>Apple + 3rd party jurisdiction</li>
<li>Limited to user’s geography - business of streaming media
contracts</li>
</ul>
<h4 data-number="0.16.4.3" id="mix-networks-e.g.-mixminion"><span
class="header-section-number">0.16.4.3</span> Mix networks
(e.g. Mixminion)</h4>
<p>Goal - anonymize e-mail / Usenet-like traffic</p>
<p>Key intuition - get traffic, shuffle it and send it next step. Each
node waits for certain time, mix the packets (order, identity of the
voter from the encrypted ballot), and send it to the next node. Client
splits message M in <strong>uniform</strong> chunks,
<strong>padded</strong> as needed, and <strong>encrypts</strong> each
chunk C for a path through the mix-net</p>
<p>Randomness is in the message destinations, which is used to prevent
repeat attacks or precomputed paths.</p>
<p>Works with just 1 honest mixwrs</p>
<p>Advantage provable (storng) anonymity may resist traffic analysis</p>
<p>Problem: Very slow, high-latency (hours) Few users -&gt; small
anonymity set</p>
<h4 data-number="0.16.4.4" id="tor-the-onion-router"><span
class="header-section-number">0.16.4.4</span> Tor (The Onion
Router)</h4>
<p>Can we make mix-net work at interactive speeds? -&gt; tradeoff with
robustness to traffic analysis</p>
<p>Each packet is 514 bytes</p>
<p>How do we find Tor relays? There is a Guard node - which is public,
and middle nodes are secret. There are Harcoded (10) directory
servers</p>
<p>New list of all known relays every hour - <em>how to agree on the
list?</em> -&gt; <strong>consensus</strong></p>
<p>Advantages:</p>
<ul>
<li>larger anonymity set</li>
<li>low-latency</li>
<li>usability, intercactive web</li>
<li>highly effective against weak adversaries</li>
</ul>
<p>Problems:</p>
<ul>
<li>weak to traffic analysis attacks</li>
<li>web services may block tor</li>
<li>adversary may become global passive adversaries</li>
</ul>
<h5 data-number="0.16.4.4.1" id="how-can-this-system-be-attacked"><span
class="header-section-number">0.16.4.4.1</span> How can this system be
attacked?</h5>
<p>Quantum system can intercept traffic in between client and guard
node.</p>
<p>Become a relay (lots of them) - if you can control the relays
(esp. entry and exit nodes) you can do traffic analysis. Defence -
reputation of the relay</p>
<p>There are services inside the network which makes it harder to
attack.</p>
<h4 data-number="0.16.4.5" id="garlic-routing"><span
class="header-section-number">0.16.4.5</span> Garlic routing</h4>
<p>Packaging together messages at router and disassemble at next one. So
it has mix-net properties</p>
<h4 data-number="0.16.4.6" id="dining-cryptographers-dc-net"><span
class="header-section-number">0.16.4.6</span> Dining Cryptographers
(DC-net)</h4>
<p>Different - not relay-based, information coding</p>
<p>Based on the secure multi-party computation.</p>
<p>Idea: cryptographers are having dinner and a waiter tells them the
bill has been paid. They want to find out if one of them paid OR if
someone else (the NSA) did <strong>without revealing who
paid</strong></p>
<p>Key element - secret that is shared between pairs of cryptographers.
(coin flip) My value = Left <span class="math inline">\xor</span> Right
<span class="math inline">\xor</span> (I paid) To check whether we paid
- xor all of them and if it is 1, then we paid, otherwise not.</p>
<p>Basic scenario - n^^2 messages</p>
<p>This assumes some level of communication between the
cryptographers.</p>
<p>Advantages:</p>
<ul>
<li>Provable, information theoretic anonymity</li>
<li>Security independent of relays</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Naive implementation is inefficent O(n^^2)</li>
<li>May optimixations exist and are needed</li>
</ul>
<p>Scaling by avoiding all-to-all communcation: small amount of servers
(m &lt;&lt; n), and a lot of clients. Clients communicate only with the
servers.</p>
<h2 data-number="0.17" id="sybil-attacks-and-defenses"><span
class="header-section-number">0.17</span> Sybil attacks and
defenses</h2>
<p><strong>What is it:</strong> “Sybil” is study of a patient diagnosed
with multiple personality disorder (1973).</p>
<p>Anyone can have as many electronic personas as one has time and
energy to create - The Sybil Attack</p>
<p>Fake identities:</p>
<ul>
<li>virtual nodes</li>
<li>Social media bot</li>
<li>Ballot stuffing</li>
<li>fake reviewers</li>
<li>Sockpuppets (participate in a forum with other fake personas who
agree with you)</li>
<li>Astroturfing (practice for an entity of presenting themselves to
give a different opinion - e.g. tabacco movement against public
legislators or shell “working” on renewables)</li>
</ul>
<h3 data-number="0.17.1" id="implications"><span
class="header-section-number">0.17.1</span> Implications</h3>
<p>DHTs: eclipse attacks - censor nodes, censor key-value pairs</p>
<p>Compromise threshold-based security (t-of-n): creeping compromise -
slowly increase t, n</p>
<p>Compromise consensus: force particular decisions rewrite history
equivocate (multiple histories if i tell different people different
stories - Byzantine attack)</p>
<h3 data-number="0.17.2" id="sybil-defenses"><span
class="header-section-number">0.17.2</span> Sybil defenses</h3>
<p>Permissioned systems - only select few nodes</p>
<p>Strong identity</p>
<p>Adding artificial costs</p>
<p>Social network-based - relationship between the identities</p>
<p>Proof of Personhood</p>
<h4 data-number="0.17.2.1" id="stronger-identities"><span
class="header-section-number">0.17.2.1</span> Stronger identities</h4>
<p>Sign up with phone number (e.g. WhatsApp) - buy phone numbers, buy
burner phones Sign up with credit card - fake cards, fake passports Sign
up with e-mail - me@gmail.com vs me+cs438@gmail.com ID verification -
Regularory requirement (e.g. “Know your customer” - KYC); fake ID but
derred by cost, jail, paper trail</p>
<p>Biometrics - face, fingerprints, iris, DNA. Biggest biometric
database - Aadhaar (India) - 1.38B. Mandatory database which stores an
identification number tied to biometric. China - collects DNA, and has a
database. Common Identity Repository (EU) - 350M - put all of the data
together (problems with privacy) Dpt. of Homeland Security (US) - 270M
(on average saw everyone 4 times)</p>
<p><strong>Weaknesses</strong>:</p>
<ul>
<li>Privacy
<ul>
<li>needs centralized database</li>
<li>DB encoding: password will be stored as a hash, meanwhile biometric
info needs to be stored in plain. Sybil resistance - verify that the new
registered fingerprint does not exist in the database already.</li>
</ul></li>
<li>Forgeability
<ul>
<li>Fake “fingerprints” - from a photo it is possible to forge
fingerprints</li>
<li>Fake “iris”</li>
<li>Biometric synthesis - synthesize realistic data, means trusting the
ML model.</li>
</ul></li>
</ul>
<h4 data-number="0.17.2.2" id="artificial-costs"><span
class="header-section-number">0.17.2.2</span> Artificial costs</h4>
<p>Key idea - increase the cost to Sybil identities</p>
<ul>
<li>Proof-of-work (bitcoin approach)</li>
<li>CAPTCHA (Turing tests)</li>
<li>Threshold validation</li>
<li>Proof-of-stake (put money on others’ trust - if i am misbehaving i
will lose this money)</li>
<li>Proof-of-space/storage</li>
</ul>
<h5 data-number="0.17.2.2.1" id="proof-of-work"><span
class="header-section-number">0.17.2.2.1</span> Proof-of-work</h5>
<p>first used as anti-spam popularized by Bitcoin</p>
<p>It is a crypto puzzle: <span class="math inline">H(data, nonce) =
000...000xxxxxxxxx</span> -&gt; find the <strong>nonce</strong> 0s are
Proof-of-work threshold, and you need 2^^n hashes</p>
<p>This does not prevent an attack, just increases its costs Also, it is
not efficient and not environmentally friendly</p>
<p>It is more than a 1000x worse than other ideas from energy
perspective.</p>
<h5 data-number="0.17.2.2.2" id="proof-of-stake"><span
class="header-section-number">0.17.2.2.2</span> Proof-of-stake</h5>
<p>Etherium</p>
<p>Nodes must stake money to participate in consensus Randomized
validators, likelyhood based on stake. If validators don’t agree, if you
misbehave, you get punished by loss of stake Plutocracy: more money -
more stake (problem for small cryptocurrencies)</p>
<h5 data-number="0.17.2.2.3" id="socialtrust-network-defenses"><span
class="header-section-number">0.17.2.2.3</span> Social/Trust network
defenses</h5>
<ul>
<li>PDP “Web of Trust” model
<ul>
<li>Alternate to PKI</li>
<li>“Key signing” parties</li>
<li>“Alice” -&gt; Key A, “Bob” -&gt; Key B</li>
</ul></li>
<li>PKI/Client-side TLS certificates
<ul>
<li>It could be company-managed in a IoT environment</li>
<li>Email-challenge</li>
<li>not great in Sybil denfense perspective</li>
</ul></li>
<li>Generic
<ul>
<li>SybilGuard</li>
<li>SybilLimit</li>
<li>SybilRank</li>
</ul></li>
<li>App-specific
<ul>
<li>SumUp…</li>
</ul></li>
</ul>
<p>Assumptions that these systems are making:</p>
<ul>
<li>Social graph</li>
<li>Edges denote “trust”</li>
<li>Honest region is well-connected</li>
<li>There exists a “Sybil region” scenario, which has only few edges to
the honest region, therefore attack edges are expensive and attack edges
are rare/few.</li>
</ul>
<p>SumUp idea: Random walk in the graph - chances that i go out of
well-connected (honest) area is very low. Assign voting rights to the
end node Repeat Majority of the voting rights stays in the honest
region, even though there could be.</p>
<p><strong>Weaknesses</strong>:</p>
<ul>
<li>basics: privacy, performance</li>
<li>re-thinking the “movie plot threat” - why go into these things, when
they are so complicated
<ul>
<li>crow-sourcing - get the majority through financial incentives,
botnet</li>
<li>sparse infiltration - every single region is 1 node</li>
<li>small-scale attack</li>
</ul></li>
</ul>
<h5 data-number="0.17.2.2.4" id="sybils-on-facebook"><span
class="header-section-number">0.17.2.2.4</span> Sybils on Facebook</h5>
<p>We’re Facebook and trying to detect fake accounts:</p>
<p>AI, look for usage patterns - IP could be an indication (uzbekistant
IP but accutely interested in Swiss politics), volume of usage reporting
- ineficient, not necessarily correct connectivity - 1) who contacted
who - new account reaching out to a lot of people, 2) who are you
connected to who - similar age/usage</p>
<p>If these detections are public, the adversaries are just going to
change approach so most of the time it is kept secret.</p>
<h5 data-number="0.17.2.2.5" id="proof-of-personhood"><span
class="header-section-number">0.17.2.2.5</span> Proof-of-Personhood</h5>
<p>Key intuition - link identity to “being a physical person”</p>
<p>Goals:</p>
<p>inclusion - low cost to participation (permissionless) equality- one
person, one vote (strictly) security - against identity theft/loss and
Sybils privacy - no ID, no biometrics, etc.</p>
<p>Approaches: pseudonum parties Encointer - Co-located physical bodies
- person can be at one place at one time. Idena - “Flip” tests (Turing
tests) - make a story out of pictures that makes sense. And it also
prepares a flip test for others Humanity DAO - DAO/curated list Many
others - Upala, BrightID, Good</p>
<h2 data-number="0.18" id="review-of-consensus"><span
class="header-section-number">0.18</span> Review of Consensus</h2>
<h3 data-number="0.18.1" id="logical-clocks"><span
class="header-section-number">0.18.1</span> Logical clocks</h3>
<p>Lamport clock - A caused B -&gt; C(A) &lt; C(B) Each message contains
the logical time, receiving updates the local clock</p>
<p>Vector clock - C(A) &lt; C(B) -&gt; A caused B Similar to G-Counter
CRDT, one counter per node.</p>
<p>Threshold logical clock - specialized for threshold applications</p>
<h4 data-number="0.18.1.1" id="threshold-logical-clock"><span
class="header-section-number">0.18.1.1</span> Threshold logical
clock</h4>
<p>When a consensus is reached -&gt; broadcast logical clock
advance.</p>
<p>Then a threshold (quorum) of clock advances has been received -&gt;
move to the next box, even if we haven’t witnessed the consensus</p>
<h2 data-number="0.19" id="byzantine-problems"><span
class="header-section-number">0.19</span> Byzantine problems</h2>
<h3 data-number="0.19.1" id="byzantine-generals-problem"><span
class="header-section-number">0.19.1</span> Byzantine generals
problem</h3>
<p>Some generals surround the castle, and the goal is to take the
castle. They will win if they coordinate correctly - either attack or
retreat.</p>
<p>Generals or messangers might be treacherous.</p>
<p><strong>Failure model</strong>:</p>
<ul>
<li>arbitrary failures</li>
<li>general (=process) may be malicious</li>
<li>Generals may collude</li>
<li>Network may be malicoius</li>
<li>system may present conflicting info</li>
<li>computations may be incorrect</li>
</ul>
<p><strong>Fault</strong>: underlying defect:</p>
<ul>
<li>active - injects errors in the system</li>
<li>passive - latent</li>
</ul>
<p><strong>Failure</strong>: system no producing the desired result
-&gt; 1 + fault(s) made the system useless</p>
<p><strong>Fault-tolerance</strong>: building reliability out of
unreliable components</p>
<p><strong>Redundancy</strong>: fundamental principle to build
fault-tolerant systems</p>
<h3 data-number="0.19.2" id="byzantine-faults---causes"><span
class="header-section-number">0.19.2</span> Byzantine faults -
Causes</h3>
<p>Malicious actors (hacking), software bug, hardware failure</p>
<p>What kind of hardware failure -&gt; network</p>
<h3 data-number="0.19.3" id="bft-consensus"><span
class="header-section-number">0.19.3</span> BFT Consensus</h3>
<p>Key properties: Safety - all nodes agree on a (single) decision
Liveness - eventually something is decided</p>
<p>Paxos &gt;= 2f + 1</p>
<p>Why does it not work for BFT?:</p>
<p>Byzantine model: Malicious node “X” Malicious network</p>
<p>Delay the network long enough such that 2/3 acceptors receives
proposal. Other proposer does the same, but only one acceptor node is
overlapping. Then attack could be carried out by the overlapping node
and break safety - 2 different values were agreed on.</p>
<p>Therefore 2f + 1 is not strong enough.</p>
<p>BFT: n &gt;= 3f + 1 No matter what there will be at least 1 honest
node in the intersection. (even though there is no assumption about
who’s honest)</p>
<p>How to decide on n? - cost analysis</p>
<p>Sometimes people will accept Byzantine faults because the cost of the
chance of introducing a bug with the implementation of BFT.</p>
<h2 data-number="0.20"
id="permissionless-consensus-bitcoin-and-proof-of-work"><span
class="header-section-number">0.20</span> Permissionless consensus
(Bitcoin and Proof-of-work)</h2>
<h3 data-number="0.20.1" id="bitcoin---key-ideas"><span
class="header-section-number">0.20.1</span> Bitcoin - key ideas</h3>
<p>Proof-of-work:</p>
<ul>
<li>“miners” solve computational puzzles (hash with N leading zeros)
=&gt; Computational power = Hash rate (H/s)</li>
<li>Puzzle difficulty is adjusted to keep block rate (roughly) constant
- around 10min. It compensates for changes in mining power.</li>
</ul>
<p>10min - ensures that everyone has received a block n, before there is
a chance for anyone to mine block n+1.</p>
<h3 data-number="0.20.2" id="bitcoin-assumptions"><span
class="header-section-number">0.20.2</span> Bitcoin assumptions</h3>
<p>Threshold assumption - majority of mining power is honest (you cannot
corrupt more than 50%). This means it is independent fo the number of
nodes</p>
<p>Keep the heaviest chain (that has consumed the most computational
power). This is because of the network partitions, give weight to the
network that has done more work. transient safety violations -
e.g. forks, reversed transactions are OK. Eventually forks will be
resolved (based on the expended work) &lt;- All of this is highly
probabilistic</p>
<p>Probabilistic finality - 6 blocks (1h) - instead of saying “we have
the transaction, it’s effective now”; Bitcoin waits for 6 blocks, which
comes from probability of a fork happening.</p>
<p>Economic incentive compatibility - bitcoin gives economic incetives
to miners</p>
<p>Safety assumption - assuming that messages arrive in very short time
- <strong>synchronicity</strong></p>
</body>
</html>
